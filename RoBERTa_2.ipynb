{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WV2VL3c_30ei"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "import torch\n",
        "from transformers import BertModel, BertTokenizerFast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YelXxWu30ek"
      },
      "outputs": [],
      "source": [
        "weight = 'bert-base-uncased'\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "max_len = 35"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkA1uPWqAmUA"
      },
      "outputs": [],
      "source": [
        "weight = 'bert-base-uncased'\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "max_len = 35\n",
        "import json\n",
        "\n",
        "train_path = '/content/drive/MyDrive/ner/datas/Election-Trec/train.json'\n",
        "# train_path = '../datas/daily life/train.json'\n",
        "test_path = '/content/drive/MyDrive/ner/datas/Election-Trec/test.json'\n",
        "# test_path = '../datas/daily life/test.json'\n",
        "\n",
        "train_file = json.load(open(train_path,'r',encoding='utf-8'))\n",
        "test_file = json.load(open(test_path, 'r', encoding='utf-8'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwhPsxYX30el"
      },
      "source": [
        "#### load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1YYHvA-30em"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "train_path = '/content/drive/MyDrive/ner/datas/Election-Trec/train.json'\n",
        "# train_path = '../datas/daily life/train.json'\n",
        "test_path = '/content/drive/MyDrive/ner/datas/Election-Trec/test.json'\n",
        "# test_path = '../datas/daily life/test.json'\n",
        "\n",
        "train_file = json.load(open(train_path,'r',encoding='utf-8'))\n",
        "test_file = json.load(open(test_path, 'r', encoding='utf-8'))\n",
        "# Append all words, eye-tracking signals, EEG signals and tags from training json to list\n",
        "train_sens, train_tags = [],[]\n",
        "train_Feature = []\n",
        "train_word_nums = []\n",
        "\n",
        "sens = ''\n",
        "nums = 0\n",
        "for key in train_file.keys():\n",
        "    tags = []\n",
        "    features = []\n",
        "    items = train_file[key]\n",
        "    sens = ''\n",
        "    nums = 0\n",
        "    for item in items:\n",
        "        sens += item[0]\n",
        "        sens += ' '\n",
        "        features.append(item[1:-1])               # ET+EEG: [1: -1]\n",
        "        tags.append(item[-1])\n",
        "        nums += 1\n",
        "    train_sens.append(sens.strip())\n",
        "    train_word_nums.append(nums)\n",
        "    train_Feature.append(features)\n",
        "    train_tags.append(tags)\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(weight)\n",
        "label_to_ids = {'none': 0, 'B': 1, 'I': 2, 'E': 3, 'S': 4, \"O\": 5}\n",
        "# label_to_ids = {'O': 0, 'B': 1, 'I': 2, 'E': 3, 'S': 4}\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, texts, old_features, tags):\n",
        "        self.texts = texts\n",
        "        self.tags = tags\n",
        "        self.old_features = old_features\n",
        "\n",
        "        self.labels = []\n",
        "        self.tokens = []\n",
        "        self.features = []\n",
        "\n",
        "        self.input_ids = None\n",
        "        self.attention_masks = None\n",
        "\n",
        "    def encode(self):\n",
        "        for i in tqdm(range(len(self.texts))):\n",
        "          text = self.texts[i]\n",
        "          tag = self.tags[i]\n",
        "          feature = self.old_features[i]\n",
        "          tags, tokens, features = align_label(text, tag, feature)\n",
        "          self.labels.append(tags)\n",
        "          self.tokens.append(tokens)\n",
        "          self.features.append(features)\n",
        "\n",
        "        self.features = np.array(self.features,float)\n",
        "        self.inputs = tokenizer(self.texts, max_length=max_len, add_special_tokens=True, padding='max_length', truncation=True, return_tensors='pt')\n",
        "        self.input_ids = self.inputs['input_ids']\n",
        "        self.attention_masks = self.inputs['attention_mask']\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx,:], self.attention_masks[idx,:], self.tokens[idx], torch.tensor(self.features[idx],dtype=torch.float32), torch.tensor(self.labels[idx])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "\n",
        "label_all_tokens = True\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def align_label(text, labels, features):\n",
        "    input = tokenizer(text, max_length=max_len, add_special_tokens=True, padding='max_length', truncation=True, return_tensors='pt')\n",
        "    word_ids = input.word_ids()\n",
        "    input_ids = input['input_ids']\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "\n",
        "    previous_word_idx = None\n",
        "    new_labels, new_features = [], []\n",
        "    no_features = [0 for _ in range(1, 26)]\n",
        "\n",
        "    for word_idx in word_ids:\n",
        "        if word_idx is None:\n",
        "            new_labels.append('none')\n",
        "            new_features.append(no_features)\n",
        "        elif word_idx != previous_word_idx:\n",
        "            try:\n",
        "                new_labels.append(labels[word_idx])\n",
        "                new_features.append(features[word_idx])\n",
        "            except:\n",
        "                new_labels.append('none')\n",
        "                new_features.append(no_features)\n",
        "        else:\n",
        "            try:\n",
        "                new_labels.append(labels[word_idx] if label_all_tokens else 'none')\n",
        "                new_features.append(features[word_idx] if label_all_tokens else no_features)\n",
        "            except:\n",
        "                new_labels.append('none')\n",
        "                new_features.append(no_features)\n",
        "        previous_word_idx = word_idx\n",
        "\n",
        "    label_ids = [label_to_ids[label] for label in new_labels]\n",
        "    return label_ids, tokens, new_features\n",
        "\n",
        "train_dataset = MyDataset(train_sens, train_Feature, train_tags)\n",
        "train_dataset.encode()\n",
        "\n",
        "\n",
        "test_dataset = MyDataset(test_sens, test_Feature, test_tags)\n",
        "test_dataset.encode()\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=128)\n",
        "test_dataloader = DataLoader(test_dataset, shuffle=True, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TA5RBljv30en"
      },
      "outputs": [],
      "source": [
        "# Append all words, eye-tracking signals, EEG signals and tags from training json to list\n",
        "train_sens, train_tags = [],[]\n",
        "train_Feature = []\n",
        "train_word_nums = []\n",
        "\n",
        "sens = ''\n",
        "nums = 0\n",
        "for key in train_file.keys():\n",
        "    tags = []\n",
        "    features = []\n",
        "    items = train_file[key]\n",
        "    sens = ''\n",
        "    nums = 0\n",
        "    for item in items:\n",
        "        sens += item[0]\n",
        "        sens += ' '\n",
        "        features.append(item[1:-1])               # ET+EEG: [1: -1]\n",
        "        tags.append(item[-1])\n",
        "        nums += 1\n",
        "    train_sens.append(sens.strip())\n",
        "    train_word_nums.append(nums)\n",
        "    train_Feature.append(features)\n",
        "    train_tags.append(tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGwyUNAB34v4",
        "outputId": "387ba773-832f-4cf9-e8af-12e28b634ce6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbD357xA30eo"
      },
      "outputs": [],
      "source": [
        "# Append all words, eye-tracking signals, EEG signals and tags from testing json to list\n",
        "test_sens, test_tags = [],[]\n",
        "test_Feature = []\n",
        "test_word_nums = []\n",
        "\n",
        "sens = ''\n",
        "nums = 0\n",
        "for key in test_file.keys():\n",
        "    tags = []\n",
        "    features = []\n",
        "    items = test_file[key]\n",
        "    sens = ''\n",
        "    nums = 0\n",
        "    for item in items:\n",
        "        sens += item[0]\n",
        "        sens += ' '\n",
        "        features.append(item[1:-1])                # ET+EEG: [1: -1]\n",
        "        tags.append(item[-1])\n",
        "        nums += 1\n",
        "    test_sens.append(sens.strip())\n",
        "    test_word_nums.append(nums)\n",
        "    test_Feature.append(features)\n",
        "    test_tags.append(tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MySdNpjj30eo"
      },
      "outputs": [],
      "source": [
        "len(test_sens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mED9TvYz30eq"
      },
      "source": [
        "#### build dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1reUtm530eq"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejyw3ik330er"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained(weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dtYleMZ30er"
      },
      "outputs": [],
      "source": [
        "label_to_ids = {'none': 0, 'B': 1, 'I': 2, 'E': 3, 'S': 4, \"O\": 5}\n",
        "# label_to_ids = {'O': 0, 'B': 1, 'I': 2, 'E': 3, 'S': 4}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGeQuPBT30es"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, texts, old_features, tags):\n",
        "        self.texts = texts\n",
        "        self.tags = tags\n",
        "        self.old_features = old_features\n",
        "\n",
        "        self.labels = []\n",
        "        self.tokens = []\n",
        "        self.features = []\n",
        "\n",
        "        self.input_ids = None\n",
        "        self.attention_masks = None\n",
        "\n",
        "    def encode(self):\n",
        "        for i in tqdm(range(len(self.texts))):\n",
        "          text = self.texts[i]\n",
        "          tag = self.tags[i]\n",
        "          feature = self.old_features[i]\n",
        "          tags, tokens, features = align_label(text, tag, feature)\n",
        "          self.labels.append(tags)\n",
        "          self.tokens.append(tokens)\n",
        "          self.features.append(features)\n",
        "\n",
        "        self.features = np.array(self.features,float)\n",
        "        self.inputs = tokenizer(self.texts, max_length=max_len, add_special_tokens=True, padding='max_length', truncation=True, return_tensors='pt')\n",
        "        self.input_ids = self.inputs['input_ids']\n",
        "        self.attention_masks = self.inputs['attention_mask']\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx,:], self.attention_masks[idx,:], self.tokens[idx], torch.tensor(self.features[idx],dtype=torch.float32), torch.tensor(self.labels[idx])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAyLAo9S30es"
      },
      "outputs": [],
      "source": [
        "label_all_tokens = True\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def align_label(text, labels, features):\n",
        "    input = tokenizer(text, max_length=max_len, add_special_tokens=True, padding='max_length', truncation=True, return_tensors='pt')\n",
        "    word_ids = input.word_ids()\n",
        "    input_ids = input['input_ids']\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "\n",
        "    previous_word_idx = None\n",
        "    new_labels, new_features = [], []\n",
        "    no_features = [0 for _ in range(1, 26)]\n",
        "\n",
        "    for word_idx in word_ids:\n",
        "        if word_idx is None:\n",
        "            new_labels.append('none')\n",
        "            new_features.append(no_features)\n",
        "        elif word_idx != previous_word_idx:\n",
        "            try:\n",
        "                new_labels.append(labels[word_idx])\n",
        "                new_features.append(features[word_idx])\n",
        "            except:\n",
        "                new_labels.append('none')\n",
        "                new_features.append(no_features)\n",
        "        else:\n",
        "            try:\n",
        "                new_labels.append(labels[word_idx] if label_all_tokens else 'none')\n",
        "                new_features.append(features[word_idx] if label_all_tokens else no_features)\n",
        "            except:\n",
        "                new_labels.append('none')\n",
        "                new_features.append(no_features)\n",
        "        previous_word_idx = word_idx\n",
        "\n",
        "    label_ids = [label_to_ids[label] for label in new_labels]\n",
        "    return label_ids, tokens, new_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F057RX2D30es"
      },
      "outputs": [],
      "source": [
        "train_dataset = MyDataset(train_sens, train_Feature, train_tags)\n",
        "train_dataset.encode()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGOLh8us30et"
      },
      "outputs": [],
      "source": [
        "test_dataset = MyDataset(test_sens, test_Feature, test_tags)\n",
        "test_dataset.encode()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDYdOycO30et"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=128)\n",
        "test_dataloader = DataLoader(test_dataset, shuffle=True, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPc5rcNR30et"
      },
      "source": [
        "#### construct model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WTcSQ3q30et"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class BertNerModel(nn.Module):\n",
        "    def __init__(self,num_labels):\n",
        "        super(BertNerModel,self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained(weight)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(768+25,num_labels)\n",
        "\n",
        "    def forward(self,input_ids,attention_mask,extra_features,token_type_ids=None):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "\n",
        "        pooled_output = outputs[0]\n",
        "        bert_outputs = self.dropout(pooled_output)\n",
        "\n",
        "        outputs = torch.concat((bert_outputs,extra_features[:,:,:]),-1)\n",
        "        # outputs = bert_outputs\n",
        "        outputs = self.classifier(outputs)\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR5hWCKz30et"
      },
      "source": [
        "#### evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HM_fiH6x30et"
      },
      "outputs": [],
      "source": [
        "def TagConvert(raw_tags, words_set, poss=None):\n",
        "    true_tags = []\n",
        "    for i in range(raw_tags.shape[0]):\n",
        "      kw_list = []\n",
        "      nkw_list = \"\"\n",
        "      for j in range(len(raw_tags[i])):\n",
        "          item = raw_tags[i][j]\n",
        "          if item == 0:\n",
        "              continue\n",
        "          if poss !=None and j in poss[i]:\n",
        "              continue\n",
        "          # if item == 5:\n",
        "          #     continue\n",
        "          if item == 4:\n",
        "              kw_list.append(str(words_set[j][i]))\n",
        "          if item == 1:\n",
        "              nkw_list += str(words_set[j][i])\n",
        "          if item == 2:\n",
        "              nkw_list += \" \"\n",
        "              nkw_list += str(words_set[j][i])\n",
        "          if item == 3:\n",
        "              nkw_list += \" \"\n",
        "              nkw_list += str(words_set[j][i])\n",
        "              kw_list.append(nkw_list)\n",
        "              nkw_list = \"\"\n",
        "\n",
        "      true_tags.append(kw_list)\n",
        "    return true_tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeaDWi2O30eu"
      },
      "outputs": [],
      "source": [
        "def evaluate(predict_data, target_data, topk=3):\n",
        "  TRUE_COUNT, PRED_COUNT, GOLD_COUNT = 0.0, 0.0, 0.0\n",
        "  for index, words in enumerate(predict_data):\n",
        "      y_pred, y_true = None, target_data[index]\n",
        "\n",
        "      if type(predict_data) == str:\n",
        "          words = sorted(words.items(), key=lambda item: (-item[1], item[0]))\n",
        "          y_pred = [i[0] for i in words]\n",
        "      elif type(predict_data) == list:\n",
        "          y_pred = words\n",
        "\n",
        "      y_pred = y_pred[0: topk]\n",
        "      TRUE_NUM = len(set(y_pred) & set(y_true))\n",
        "      TRUE_COUNT += TRUE_NUM\n",
        "      PRED_COUNT += len(y_pred)\n",
        "      GOLD_COUNT += len(y_true)\n",
        "  # compute P\n",
        "  if PRED_COUNT != 0:\n",
        "      p = (TRUE_COUNT / PRED_COUNT)\n",
        "  else:\n",
        "      p = 0\n",
        "  # compute R\n",
        "  if GOLD_COUNT != 0:\n",
        "      r = (TRUE_COUNT / GOLD_COUNT)\n",
        "  else:\n",
        "      r = 0\n",
        "  # compute F1\n",
        "  if (r + p) != 0:\n",
        "      f1 = ((2 * r * p) / (r + p))\n",
        "  else:\n",
        "      f1 = 0\n",
        "\n",
        "  p = round(p * 100, 2)\n",
        "  r = round(r * 100, 2)\n",
        "  f1 = round(f1 * 100, 2)\n",
        "\n",
        "  return p, r, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIW3PQMt30eu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_f1(y_pred, y_true):\n",
        "    # flatten and convert to numpy array\n",
        "    y_true = y_true.view(-1)\n",
        "    y_pred = y_pred.view(-1)\n",
        "    y_true = y_true.detach().cpu().numpy()\n",
        "    y_pred = y_pred.detach().cpu().numpy()\n",
        "\n",
        "    mask = np.where(y_true != 0)\n",
        "\n",
        "    y_true = y_true[mask]\n",
        "    y_pred = y_pred[mask]\n",
        "\n",
        "    return y_pred, y_true"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBZSKd6v30ev"
      },
      "source": [
        "#### start training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9P5Vdcx30ev"
      },
      "outputs": [],
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam, AdamW\n",
        "\n",
        "model = BertNerModel(num_labels=6)\n",
        "model = model.to(device)\n",
        "\n",
        "optim = AdamW(model.parameters(),lr=5e-5,weight_decay=1e-2)\n",
        "loss_fn = CrossEntropyLoss(reduction='none', ignore_index=0)\n",
        "loss_fn = loss_fn.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8pYVkAo30ev"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phuv-BHn30ev"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "epochs = 5\n",
        "best_f1 = 0.0\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    loss_value = 0.0\n",
        "    model.train()\n",
        "    label_true, label_pred = [], []\n",
        "    for i,batch in enumerate(train_dataloader):\n",
        "        optim.zero_grad()\n",
        "        input_ids, attention_masks, _, features, tags = batch\n",
        "        pred_tags = model(input_ids.to(device), attention_masks.to(device), features.to(device))\n",
        "\n",
        "        loss = loss_fn(pred_tags.permute(0,2,1),tags.to(device))\n",
        "        loss = loss.mean()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "        pred_tags = F.softmax(pred_tags,dim=-1)\n",
        "        pred_tags = torch.argmax(pred_tags,dim=-1)\n",
        "\n",
        "        y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "        label_true.extend(y_true)\n",
        "        label_pred.extend(y_pred)\n",
        "\n",
        "        loss_value += loss.item()\n",
        "\n",
        "    label_train_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "\n",
        "    model.eval()\n",
        "    kw_true, kw_pred = [], []\n",
        "    label_true, label_pred = [],[]\n",
        "    for i,batch in enumerate(test_dataloader):\n",
        "      input_ids, attention_masks, tokens, features, tags = batch\n",
        "      with torch.no_grad():\n",
        "          for module in model.modules():\n",
        "              if isinstance(module, nn.Dropout):\n",
        "                  module.p = 0\n",
        "                  module.train(False)\n",
        "          pred_tags = model(input_ids.to(device), attention_masks.to(device), features.to(device))\n",
        "          pred_tags = F.softmax(pred_tags,dim=-1)\n",
        "          pred_tags = torch.argmax(pred_tags,dim=-1)\n",
        "\n",
        "      y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "      label_true.extend(y_true)\n",
        "      label_pred.extend(y_pred)\n",
        "\n",
        "      # more balance evaluate\n",
        "      poss = []\n",
        "      for i in range(len(tags)):\n",
        "          pos = []\n",
        "          for j in range(len(tags[i])):\n",
        "              if tags[i][j] == 0:\n",
        "                  pos.append(j)\n",
        "          poss.append(pos)\n",
        "\n",
        "      kw_true.extend(TagConvert(tags,tokens))\n",
        "      kw_pred.extend(TagConvert(pred_tags,tokens,poss))\n",
        "\n",
        "    label_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "    P, R, F1 = evaluate(kw_true, kw_pred)\n",
        "\n",
        "    if F1 > best_f1:\n",
        "        best_f1 = F1\n",
        "        torch.save(model.state_dict(),'./pretrain_pt/bert.pt')\n",
        "\n",
        "    print(\"epoch{}:  loss:{:.2f}   train_f1_value:{:.2f}  test_f1_value:{:.2f}  kw_f1_value:{:.2f}\".format(\n",
        "        epoch+1, loss_value / len(train_dataloader), label_train_f1, label_f1, F1\n",
        "    ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bwu5-I-X30ew"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9IInQlq30ew"
      },
      "source": [
        "#### inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8SxBZts30ew"
      },
      "outputs": [],
      "source": [
        "model = BertNerModel(num_labels=6)\n",
        "model.load_state_dict(torch.load('./pretrain_pt/bert.pt'))\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gm9qo5EK30ew"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1XRRnHu30ew"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "model.eval()\n",
        "kw_true, kw_pred = [], []\n",
        "label_true, label_pred = [],[]\n",
        "for i,batch in enumerate(test_dataloader):\n",
        "    input_ids, attention_masks, tokens, extra_features, tags = batch\n",
        "    with torch.no_grad():\n",
        "        for module in model.modules():\n",
        "            if isinstance(module, nn.Dropout):\n",
        "                module.p = 0\n",
        "                module.train(False)\n",
        "        #pred_tags = model(input_ids.to(device), attention_masks.to(device))\n",
        "        pred_tags = model(input_ids.to(device), attention_masks.to(device), extra_features.to(device))\n",
        "        pred_tags = F.softmax(pred_tags,dim=-1)\n",
        "        pred_tags = torch.argmax(pred_tags,dim=-1)\n",
        "\n",
        "    y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "    label_true.extend(y_true)\n",
        "    label_pred.extend(y_pred)\n",
        "\n",
        "    # more balance evaluate\n",
        "    poss = []\n",
        "    for i in range(len(tags)):\n",
        "        pos = []\n",
        "        for j in range(len(tags[i])):\n",
        "            if tags[i][j] == 0:\n",
        "                pos.append(j)\n",
        "        poss.append(pos)\n",
        "\n",
        "    kw_true.extend(TagConvert(tags,tokens))\n",
        "    kw_pred.extend(TagConvert(pred_tags,tokens,poss))\n",
        "\n",
        "label_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "P, R, F1 = evaluate(kw_true, kw_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6krJATmu30ew"
      },
      "outputs": [],
      "source": [
        "print(P)\n",
        "print(R)\n",
        "print(F1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDqanUap30ex"
      },
      "outputs": [],
      "source": [
        "##############################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2Csn5Nh30ex"
      },
      "outputs": [],
      "source": [
        "fs_num = 25  # 定义额外特征的数量"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maUzbiVv30ez"
      },
      "outputs": [],
      "source": [
        "################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mchBSUE-30e7"
      },
      "outputs": [],
      "source": [
        "class SoftAttention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(SoftAttention, self).__init__()\n",
        "        self.attention_weights = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        attention_scores = self.attention_weights(hidden_states)  # [batch_size, seq_len, 1]\n",
        "        attention_weights = torch.softmax(attention_scores, dim=1)  # [batch_size, seq_len, 1]\n",
        "        context_vector = torch.sum(attention_weights * hidden_states, dim=1)  # [batch_size, hidden_dim]\n",
        "        return context_vector, attention_weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEONvBvj30e8"
      },
      "outputs": [],
      "source": [
        "class BertNerModelWithAttention(nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super(BertNerModelWithAttention, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(weight)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.attention = SoftAttention(768)\n",
        "        self.classifier = nn.Linear(768 + 25, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, extra_features, token_type_ids=None):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        sequence_output = outputs[0]  # [batch_size, seq_len, hidden_dim]\n",
        "        sequence_output = self.dropout(sequence_output)\n",
        "\n",
        "        context_vector, attention_weights = self.attention(sequence_output)  # [batch_size, hidden_dim]\n",
        "\n",
        "        # 扩展 context_vector 以匹配 extra_features 的维度\n",
        "        context_vector = context_vector.unsqueeze(1).expand(-1, extra_features.size(1), -1)  # [batch_size, seq_len, hidden_dim]\n",
        "\n",
        "        combined_output = torch.cat((context_vector, extra_features), dim=-1)  # [batch_size, seq_len, hidden_dim + 25]\n",
        "        logits = self.classifier(combined_output)  # [batch_size, seq_len, num_labels]\n",
        "\n",
        "        return logits, attention_weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pnFbxQJ30e8"
      },
      "outputs": [],
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import AdamW\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# model = BertNerModelWithSoftAttention(num_labels=6)\n",
        "# model = model.to(device)\n",
        "\n",
        "\n",
        "model = BertNerModelWithAttention(num_labels=6)\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "#optim = AdamW(model.parameters(), lr=5e-5, weight_decay=1e-2)\n",
        "optim = AdamW(model.parameters(), lr=1e-5, weight_decay=1e-2)  # 尝试降低学习率\n",
        "\n",
        "loss_fn = CrossEntropyLoss(reduction='none', ignore_index=0)\n",
        "loss_fn = loss_fn.to(device)\n",
        "\n",
        "epochs = 5\n",
        "best_f1 = 0.0\n",
        "num_labels = 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYa8tQMX30e8"
      },
      "outputs": [],
      "source": [
        "# 训练模型\n",
        "import torch.nn.functional as F\n",
        "\n",
        "epochs = 20\n",
        "best_f1 = 0.0\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    loss_value = 0.0\n",
        "    model.train()\n",
        "    label_true, label_pred = [], []\n",
        "    for i, batch in enumerate(train_dataloader):\n",
        "        optim.zero_grad()\n",
        "        input_ids, attention_masks, _, features, tags = batch\n",
        "        pred_tags, _ = model(input_ids.to(device), attention_masks.to(device), features.to(device))\n",
        "\n",
        "        loss = loss_fn(pred_tags.permute(0, 2, 1), tags.to(device))\n",
        "        loss = loss.mean()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "        pred_tags = F.softmax(pred_tags, dim=-1)\n",
        "        pred_tags = torch.argmax(pred_tags, dim=-1)\n",
        "\n",
        "        y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "        label_true.extend(y_true)\n",
        "        label_pred.extend(y_pred)\n",
        "\n",
        "        loss_value += loss.item()\n",
        "\n",
        "    label_train_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "\n",
        "    model.eval()\n",
        "    kw_true, kw_pred = [], []\n",
        "    label_true, label_pred = [], []\n",
        "    for i, batch in enumerate(test_dataloader):\n",
        "        input_ids, attention_masks, tokens, features, tags = batch\n",
        "        with torch.no_grad():\n",
        "            for module in model.modules():\n",
        "                if isinstance(module, nn.Dropout):\n",
        "                    module.p = 0\n",
        "                    module.train(False)\n",
        "            pred_tags, _ = model(input_ids.to(device), attention_masks.to(device), features.to(device))\n",
        "            pred_tags = F.softmax(pred_tags, dim=-1)\n",
        "            pred_tags = torch.argmax(pred_tags, dim=-1)\n",
        "\n",
        "        y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "        label_true.extend(y_true)\n",
        "        label_pred.extend(y_pred)\n",
        "\n",
        "        poss = []\n",
        "        for i in range(len(tags)):\n",
        "            pos = []\n",
        "            for j in range(len(tags[i])):\n",
        "                if tags[i][j] == 0:\n",
        "                    pos.append(j)\n",
        "            poss.append(pos)\n",
        "\n",
        "        kw_true.extend(TagConvert(tags, tokens))\n",
        "        kw_pred.extend(TagConvert(pred_tags, tokens, poss))\n",
        "\n",
        "    label_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "    P, R, F1 = evaluate(kw_true, kw_pred)\n",
        "\n",
        "    if F1 > best_f1:\n",
        "        best_f1 = F1\n",
        "        torch.save(model.state_dict(), './pretrain_pt/bert_with_attention.pt')\n",
        "\n",
        "    print(\"epoch{}:  loss:{:.2f}   train_f1_value:{:.2f}  test_f1_value:{:.2f}  kw_f1_value:{:.2f}\".format(\n",
        "        epoch + 1, loss_value / len(train_dataloader), label_train_f1, label_f1, F1\n",
        "    ))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYDTIhyM30e9"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class WordAttention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(WordAttention, self).__init__()\n",
        "        self.attention_weights = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        attention_scores = self.attention_weights(hidden_states)  # [batch_size, seq_len, 1]\n",
        "        attention_weights = torch.softmax(attention_scores, dim=1)  # [batch_size, seq_len, 1]\n",
        "        context_vector = torch.sum(attention_weights * hidden_states, dim=1)  # [batch_size, hidden_dim]\n",
        "        return context_vector, attention_weights\n",
        "\n",
        "class SentenceAttention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(SentenceAttention, self).__init__()\n",
        "        self.attention_weights = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        attention_scores = self.attention_weights(hidden_states)  # [batch_size, num_sentences, 1]\n",
        "        attention_weights = torch.softmax(attention_scores, dim=1)  # [batch_size, num_sentences, 1]\n",
        "        context_vector = torch.sum(attention_weights * hidden_states, dim=1)  # [batch_size, hidden_dim]\n",
        "        return context_vector, attention_weights\n",
        "\n",
        "class BertNerModelWithHierarchicalAttention(nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super(BertNerModelWithHierarchicalAttention, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(weight)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.word_attention = WordAttention(768)\n",
        "        self.sentence_attention = SentenceAttention(768 + 25)\n",
        "        self.classifier = nn.Linear(768 + 25, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, extra_features, token_type_ids=None):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        sequence_output = outputs[0]  # [batch_size, seq_len, hidden_dim]\n",
        "        sequence_output = self.dropout(sequence_output)\n",
        "\n",
        "        # Word-level attention\n",
        "        word_context_vector, word_attention_weights = self.word_attention(sequence_output)  # [batch_size, hidden_dim]\n",
        "\n",
        "        # Expand word context vector to match extra features' dimensions\n",
        "        word_context_vector = word_context_vector.unsqueeze(1).expand(-1, extra_features.size(1), -1)  # [batch_size, seq_len, hidden_dim]\n",
        "\n",
        "        combined_output = torch.cat((word_context_vector, extra_features), dim=-1)  # [batch_size, seq_len, hidden_dim + 25]\n",
        "\n",
        "        # Sentence-level attention\n",
        "        sentence_context_vector, sentence_attention_weights = self.sentence_attention(combined_output)  # [batch_size, hidden_dim + 25]\n",
        "\n",
        "        # Expand sentence context vector to match sequence length\n",
        "        sentence_context_vector = sentence_context_vector.unsqueeze(1).expand(-1, input_ids.size(1), -1)  # [batch_size, seq_len, hidden_dim + 25]\n",
        "\n",
        "        logits = self.classifier(sentence_context_vector)  # [batch_size, seq_len, num_labels]\n",
        "\n",
        "        return logits, word_attention_weights, sentence_attention_weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgRDvqoW30e9"
      },
      "outputs": [],
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import AdamW\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model = BertNerModelWithHierarchicalAttention(num_labels=6)\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "#optim = AdamW(model.parameters(), lr=5e-5, weight_decay=1e-2)\n",
        "optim = AdamW(model.parameters(), lr=1e-5, weight_decay=1e-2)  # 尝试降低学习率\n",
        "\n",
        "loss_fn = CrossEntropyLoss(reduction='none', ignore_index=0)\n",
        "loss_fn = loss_fn.to(device)\n",
        "\n",
        "epochs = 5\n",
        "best_f1 = 0.0\n",
        "num_labels = 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hG1YK7ch30e9"
      },
      "outputs": [],
      "source": [
        "# Training code\n",
        "import torch.nn.functional as F\n",
        "\n",
        "epochs = 5\n",
        "best_f1 = 0.0\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    loss_value = 0.0\n",
        "    model.train()\n",
        "    label_true, label_pred = [], []\n",
        "    for i, batch in enumerate(train_dataloader):\n",
        "        optim.zero_grad()\n",
        "        input_ids, attention_masks, _, features, tags = batch\n",
        "        pred_tags, word_attention_weights, sentence_attention_weights = model(input_ids.to(device), attention_masks.to(device), features.to(device))\n",
        "\n",
        "        loss = loss_fn(pred_tags.permute(0, 2, 1), tags.to(device))\n",
        "        loss = loss.mean()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "        pred_tags = F.softmax(pred_tags, dim=-1)\n",
        "        pred_tags = torch.argmax(pred_tags, dim=-1)\n",
        "\n",
        "        y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "        label_true.extend(y_true)\n",
        "        label_pred.extend(y_pred)\n",
        "\n",
        "    label_train_f1 = f1_score(label_true, label_pred, average='macro') * 100\n",
        "\n",
        "    model.eval()\n",
        "    kw_true, kw_pred = [], []\n",
        "    label_true, label_pred = [], []\n",
        "    for i, batch in enumerate(test_dataloader):\n",
        "        input_ids, attention_masks, tokens, features, tags = batch\n",
        "        with torch.no_grad():\n",
        "            for module in model.modules():\n",
        "                if isinstance(module, nn.Dropout):\n",
        "                    module.p = 0\n",
        "                    module.train(False)\n",
        "            pred_tags, word_attention_weights, sentence_attention_weights = model(input_ids.to(device), attention_masks.to(device), features.to(device))\n",
        "            pred_tags = F.softmax(pred_tags, dim=-1)\n",
        "            pred_tags = torch.argmax(pred_tags, dim=-1)\n",
        "\n",
        "        y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "        label_true.extend(y_true)\n",
        "        label_pred.extend(y_pred)\n",
        "\n",
        "        poss = []\n",
        "        for i in range(len(tags)):\n",
        "            pos = []\n",
        "            for j in range(len(tags[i])):\n",
        "                if tags[i][j] == 0:\n",
        "                    pos.append(j)\n",
        "            poss.append(pos)\n",
        "\n",
        "        kw_true.extend(TagConvert(tags, tokens))\n",
        "        kw_pred.extend(TagConvert(pred_tags, tokens, poss))\n",
        "\n",
        "    label_f1 = f1_score(label_true, label_pred, average='macro') * 100\n",
        "    P, R, F1 = evaluate(kw_true, kw_pred)\n",
        "\n",
        "    if F1 > best_f1:\n",
        "        best_f1 = F1\n",
        "        torch.save(model.state_dict(), './pretrain_pt/bert_with_hierarchical_attention.pt')\n",
        "\n",
        "    print(\"epoch{}:  loss:{:.2f}   train_f1_value:{:.2f}%  test_f1_value:{:.2f}%  kw_f1_value:{:.2f}%\".format(\n",
        "        epoch + 1, loss_value / len(train_dataloader), label_train_f1, label_f1, F1\n",
        "    ))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tan6xw7c30e-"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "kw_true, kw_pred = [], []\n",
        "label_true, label_pred = [], []\n",
        "for i, batch in enumerate(test_dataloader):\n",
        "    input_ids, attention_masks, tokens, extra_features, tags = batch\n",
        "    with torch.no_grad():\n",
        "        for module in model.modules():\n",
        "            if isinstance(module, nn.Dropout):\n",
        "                module.p = 0\n",
        "                module.train(False)\n",
        "        pred_tags, word_attention_weights, sentence_attention_weights = model(input_ids.to(device), attention_masks.to(device), extra_features.to(device))\n",
        "        pred_tags = F.softmax(pred_tags, dim=-1)\n",
        "        pred_tags = torch.argmax(pred_tags, dim=-1)\n",
        "\n",
        "    y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "    label_true.extend(y_true)\n",
        "    label_pred.extend(y_pred)\n",
        "\n",
        "    poss = []\n",
        "    for i in range(len(tags)):\n",
        "        pos = []\n",
        "        for j in range(len(tags[i])):\n",
        "            if tags[i][j] == 0:\n",
        "                pos.append(j)\n",
        "        poss.append(pos)\n",
        "\n",
        "    kw_true.extend(TagConvert(tags, tokens))\n",
        "    kw_pred.extend(TagConvert(pred_tags, tokens, poss))\n",
        "\n",
        "label_f1 = f1_score(label_true, label_pred, average='macro') * 100\n",
        "P, R, F1 = evaluate(kw_true, kw_pred)\n",
        "print(P, R, F1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHZ99Yh030e_"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "epochs = 5\n",
        "best_f1 = 0.0\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    loss_value = 0.0\n",
        "    model.train()\n",
        "    label_true, label_pred = [], []\n",
        "    for i, batch in enumerate(train_dataloader):\n",
        "        optim.zero_grad()\n",
        "        input_ids, attention_masks, _, features, tags = batch\n",
        "        pred_tags = model(input_ids.to(device), attention_masks.to(device), features.to(device))\n",
        "\n",
        "        loss = loss_fn(pred_tags.permute(0, 2, 1), tags.to(device))\n",
        "        loss = loss.mean()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "        pred_tags = F.softmax(pred_tags, dim=-1)\n",
        "        pred_tags = torch.argmax(pred_tags, dim=-1)\n",
        "\n",
        "        y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "        label_true.extend(y_true)\n",
        "        label_pred.extend(y_pred)\n",
        "\n",
        "        loss_value += loss.item()\n",
        "\n",
        "    label_train_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "\n",
        "    model.eval()\n",
        "    kw_true, kw_pred = [], []\n",
        "    label_true, label_pred = [], []\n",
        "    for i, batch in enumerate(test_dataloader):\n",
        "        input_ids, attention_masks, tokens, features, tags = batch\n",
        "        with torch.no_grad():\n",
        "            for module in model.modules():\n",
        "                if isinstance(module, nn.Dropout):\n",
        "                    module.p = 0\n",
        "                    module.train(False)\n",
        "            pred_tags = model(input_ids.to(device), attention_masks.to(device), features.to(device))\n",
        "            pred_tags = F.softmax(pred_tags, dim=-1)\n",
        "            pred_tags = torch.argmax(pred_tags, dim=-1)\n",
        "\n",
        "        y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "        label_true.extend(y_true)\n",
        "        label_pred.extend(y_pred)\n",
        "\n",
        "        # more balance evaluate\n",
        "        poss = []\n",
        "        for i in range(len(tags)):\n",
        "            pos = []\n",
        "            for j in range(len(tags[i])):\n",
        "                if tags[i][j] == 0:\n",
        "                    pos.append(j)\n",
        "            poss.append(pos)\n",
        "\n",
        "        kw_true.extend(TagConvert(tags, tokens))\n",
        "        kw_pred.extend(TagConvert(pred_tags, tokens, poss))\n",
        "\n",
        "    label_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "    P, R, F1 = evaluate(kw_true, kw_pred)\n",
        "\n",
        "    if F1 > best_f1:\n",
        "        best_f1 = F1\n",
        "        torch.save(model.state_dict(), './pretrain_pt/bert_SAtten.pt')\n",
        "\n",
        "    print(\"epoch{}:  loss:{:.2f}   train_f1_value:{:.2f}  test_f1_value:{:.2f}  kw_f1_value:{:.2f}\".format(\n",
        "        epoch + 1, loss_value / len(train_dataloader), label_train_f1, label_f1, F1\n",
        "    ))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24MB4iUA30fC"
      },
      "outputs": [],
      "source": [
        "model = BertNerModel(num_labels=6)\n",
        "model.load_state_dict(torch.load('./pretrain_pt/bert_SAtten.pt'))\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGBm2Tzk30fD"
      },
      "outputs": [],
      "source": [
        "# print(P)\n",
        "# print(R)\n",
        "# print(F1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwPf1PkS30fD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import f1_score\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 加载最佳模型权重\n",
        "model.load_state_dict(torch.load('./pretrain_pt/bert_SAtten.pt'))\n",
        "model.eval()\n",
        "\n",
        "def inference_and_evaluate(test_dataloader, model, device):\n",
        "    kw_true, kw_pred = [], []\n",
        "    label_true, label_pred = [], []\n",
        "\n",
        "    for i, batch in enumerate(test_dataloader):\n",
        "        input_ids, attention_masks, tokens, features, tags = batch\n",
        "        with torch.no_grad():\n",
        "            for module in model.modules():\n",
        "                if isinstance(module, nn.Dropout):\n",
        "                    module.p = 0\n",
        "                    module.train(False)\n",
        "            pred_tags = model(input_ids.to(device), attention_masks.to(device), features.to(device))\n",
        "            pred_tags = F.softmax(pred_tags, dim=-1)\n",
        "            pred_tags = torch.argmax(pred_tags, dim=-1)\n",
        "\n",
        "        y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "        label_true.extend(y_true)\n",
        "        label_pred.extend(y_pred)\n",
        "\n",
        "        # more balance evaluate\n",
        "        poss = []\n",
        "        for i in range(len(tags)):\n",
        "            pos = []\n",
        "            for j in range(len(tags[i])):\n",
        "                if tags[i][j] == 0:\n",
        "                    pos.append(j)\n",
        "            poss.append(pos)\n",
        "\n",
        "        kw_true.extend(TagConvert(tags, tokens))\n",
        "        kw_pred.extend(TagConvert(pred_tags, tokens, poss))\n",
        "\n",
        "    label_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "    P, R, F1 = evaluate(kw_true, kw_pred)\n",
        "\n",
        "    return label_f1, P, R, F1\n",
        "\n",
        "# 调用推理和评价函数\n",
        "label_f1, P, R, F1 = inference_and_evaluate(test_dataloader, model, device)\n",
        "\n",
        "print(f\"Label F1 Score: {label_f1:.2f}\")\n",
        "print(f\"Precision: {P:.2f}\")\n",
        "print(f\"Recall: {R:.2f}\")\n",
        "print(f\"F1 Score: {F1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "INXfaAZq30fD"
      },
      "source": [
        " ###定义词级别和句子级别的注意力层"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxDHcJc830fD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "rrplSHar30fF"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "83QbfSkn30fF"
      },
      "source": [
        "层注意力 2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wk_NcvFx30fF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertModel\n",
        "from sklearn.metrics import f1_score\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5CWnG3h30fF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertModel\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim, regularizer=None):\n",
        "        super(Attention, self).__init__()\n",
        "        self.context = nn.Parameter(torch.FloatTensor(hidden_dim, 1) * 0.01)\n",
        "        nn.init.normal_(self.context, mean=0.0, std=0.05)\n",
        "        self.regularizer = regularizer\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        attention_in = torch.exp(torch.squeeze(torch.matmul(x, self.context), -1))\n",
        "        if mask is not None:\n",
        "            attention_in = attention_in * mask.float()\n",
        "        attention = attention_in / torch.unsqueeze(torch.sum(attention_in, -1), -1)\n",
        "        weighted_sum = torch.bmm(attention.unsqueeze(1), x).squeeze(1)\n",
        "        return weighted_sum\n",
        "\n",
        "class BertHANModel(nn.Module):\n",
        "    def __init__(self, num_labels, hidden_dim=768):\n",
        "        super(BertHANModel, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.word_attention = Attention(hidden_dim)\n",
        "        self.sentence_attention = Attention(hidden_dim)\n",
        "        self.classifier = nn.Linear(hidden_dim, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, sentence_ids):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        sequence_output = outputs[0]  # shape: (batch_size, seq_length, hidden_dim)\n",
        "        mask = (sentence_ids != 0).float()\n",
        "        word_attention_output = self.word_attention(sequence_output, mask)\n",
        "        sentence_attention_output = self.sentence_attention(word_attention_output, mask)\n",
        "        logits = self.classifier(sentence_attention_output)\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_PqOsFm30fG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = BertHANModel(num_labels=6)\n",
        "model = model.to(device)\n",
        "\n",
        "optim = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss(reduction='none', ignore_index=0)\n",
        "loss_fn = loss_fn.to(device)\n",
        "\n",
        "scaler = GradScaler()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3MC2vqG30fG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "from transformers import BertModel\n",
        "from torch import nn\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(Attention, self).__init__()\n",
        "        self.context = nn.Parameter(torch.FloatTensor(hidden_dim, 1))\n",
        "        nn.init.xavier_uniform_(self.context)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        attention_in = torch.tanh(torch.matmul(x, self.context))\n",
        "        attention_in = torch.squeeze(attention_in, -1)\n",
        "        if mask is not None:\n",
        "            attention_in = attention_in * mask.float()\n",
        "        attention_weights = F.softmax(attention_in, dim=-1)\n",
        "        weighted_sum = torch.bmm(attention_weights.unsqueeze(1), x).squeeze(1)\n",
        "        return weighted_sum\n",
        "\n",
        "class BertHANModel(nn.Module):\n",
        "    def __init__(self, num_labels, hidden_dim=768, rnn_dim=256):\n",
        "        super(BertHANModel, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.word_attention = Attention(hidden_dim)\n",
        "        self.rnn = nn.GRU(hidden_dim, rnn_dim, batch_first=True, bidirectional=True)\n",
        "        self.sentence_attention = Attention(rnn_dim * 2)\n",
        "        self.classifier = nn.Linear(rnn_dim * 2, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        bert_outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        sequence_output = bert_outputs[0]  # shape: (batch_size, seq_length, hidden_dim)\n",
        "\n",
        "        # Word-level attention\n",
        "        word_attention_output = self.word_attention(sequence_output)\n",
        "\n",
        "        # Sentence-level GRU\n",
        "        rnn_output, _ = self.rnn(word_attention_output.unsqueeze(1))\n",
        "\n",
        "        # Sentence-level attention\n",
        "        sentence_attention_output = self.sentence_attention(rnn_output)\n",
        "\n",
        "        logits = self.classifier(sentence_attention_output).unsqueeze(1)  # shape: (batch_size, 1, num_labels)\n",
        "        return logits.expand(-1, sequence_output.size(1), -1)  # shape: (batch_size, seq_length, num_labels)\n",
        "\n",
        "def calculate_f1(y_pred, y_true):\n",
        "    y_true = y_true.view(-1)\n",
        "    y_pred = y_pred.view(-1)\n",
        "    y_true = y_true.detach().cpu().numpy()\n",
        "    y_pred = y_pred.detach().cpu().numpy()\n",
        "    mask = np.where(y_true != 0)\n",
        "    y_true = y_true[mask]\n",
        "    y_pred = y_pred[mask]\n",
        "    return y_pred, y_true\n",
        "\n",
        "def TagConvert(raw_tags, words_set, poss=None):\n",
        "    true_tags = []\n",
        "    for i in range(raw_tags.shape[0]):\n",
        "        kw_list = []\n",
        "        nkw_list = \"\"\n",
        "        for j in range(len(raw_tags[i])):\n",
        "            item = raw_tags[i][j]\n",
        "            if item == 0:\n",
        "                continue\n",
        "            if poss != None and j in poss[i]:\n",
        "                continue\n",
        "            if item == 4:\n",
        "                kw_list.append(str(words_set[j][i]))\n",
        "            if item == 1:\n",
        "                nkw_list += str(words_set[j][i])\n",
        "            if item == 2:\n",
        "                nkw_list += \" \"\n",
        "                nkw_list += str(words_set[j][i])\n",
        "            if item == 3:\n",
        "                nkw_list += \" \"\n",
        "                nkw_list += str(words_set[j][i])\n",
        "                kw_list.append(nkw_list)\n",
        "                nkw_list = \"\"\n",
        "        true_tags.append(kw_list)\n",
        "    return true_tags\n",
        "\n",
        "def evaluate(predict_data, target_data, topk=3):\n",
        "    TRUE_COUNT, PRED_COUNT, GOLD_COUNT = 0.0, 0.0, 0.0\n",
        "    for index, words in enumerate(predict_data):\n",
        "        y_pred, y_true = None, target_data[index]\n",
        "        if type(predict_data) == str:\n",
        "            words = sorted(words.items(), key=lambda item: (-item[1], item[0]))\n",
        "            y_pred = [i[0] for i in words]\n",
        "        elif type(predict_data) == list:\n",
        "            y_pred = words\n",
        "        y_pred = y_pred[0: topk]\n",
        "        TRUE_NUM = len(set(y_pred) & set(y_true))\n",
        "        TRUE_COUNT += TRUE_NUM\n",
        "        PRED_COUNT += len(y_pred)\n",
        "        GOLD_COUNT += len(y_true)\n",
        "    if PRED_COUNT != 0:\n",
        "        p = (TRUE_COUNT / PRED_COUNT)\n",
        "    else:\n",
        "        p = 0\n",
        "    if GOLD_COUNT != 0:\n",
        "        r = (TRUE_COUNT / GOLD_COUNT)\n",
        "    else:\n",
        "        r = 0\n",
        "    if (r + p) != 0:\n",
        "        f1 = ((2 * r * p) / (r + p))\n",
        "    else:\n",
        "        f1 = 0\n",
        "    p = round(p * 100, 2)\n",
        "    r = round(r * 100, 2)\n",
        "    f1 = round(f1 * 100, 2)\n",
        "    return p, r, f1\n",
        "\n",
        "# 假设已经定义了数据集和数据加载器\n",
        "# train_dataloader = ...\n",
        "# test_dataloader = ...\n",
        "\n",
        "# 训练和评估\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = BertHANModel(num_labels=6)\n",
        "model = model.to(device)\n",
        "optim = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss(reduction='none', ignore_index=0)\n",
        "loss_fn = loss_fn.to(device)\n",
        "\n",
        "epochs = 5\n",
        "best_f1 = 0.0\n",
        "scaler = GradScaler()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    loss_value = 0.0\n",
        "    model.train()\n",
        "    label_true, label_pred = [], []\n",
        "    for i, batch in enumerate(train_dataloader):\n",
        "        optim.zero_grad()\n",
        "\n",
        "        input_ids = batch[0].to(device)\n",
        "        attention_masks = batch[1].to(device)\n",
        "        tags = batch[4].to(device)\n",
        "\n",
        "        with autocast():\n",
        "            pred_tags = model(input_ids, attention_masks)\n",
        "\n",
        "            # 展平 pred_tags 和 tags 以匹配形状\n",
        "            pred_tags = pred_tags.reshape(-1, pred_tags.size(-1))\n",
        "            tags = tags.reshape(-1)\n",
        "\n",
        "            #print(f\"pred_tags shape: {pred_tags.shape}, tags shape: {tags.shape}\")\n",
        "\n",
        "            loss = loss_fn(pred_tags, tags)\n",
        "            loss = loss.mean()\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optim)\n",
        "        scaler.update()\n",
        "\n",
        "        pred_tags = F.softmax(pred_tags, dim=-1)\n",
        "        pred_tags = torch.argmax(pred_tags, dim=-1)\n",
        "        y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "        label_true.extend(y_true)\n",
        "        label_pred.extend(y_pred)\n",
        "        loss_value += loss.item()\n",
        "\n",
        "    label_train_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "\n",
        "    model.eval()\n",
        "    kw_true, kw_pred = [], []\n",
        "    label_true, label_pred = [], []\n",
        "    for i, batch in enumerate(test_dataloader):\n",
        "        input_ids = batch[0].to(device)\n",
        "        attention_masks = batch[1].to(device)\n",
        "        tokens = batch[2]  # tokens 不是 Tensor，直接使用\n",
        "        tags = batch[4].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for module in model.modules():\n",
        "                if isinstance(module, nn.Dropout):\n",
        "                    module.p = 0\n",
        "                    module.train(False)\n",
        "            with autocast():\n",
        "                pred_tags = model(input_ids, attention_masks)\n",
        "                pred_tags = F.softmax(pred_tags, dim=-1)\n",
        "                pred_tags = torch.argmax(pred_tags, dim=-1)\n",
        "\n",
        "        y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "        label_true.extend(y_true)\n",
        "        label_pred.extend(y_pred)\n",
        "\n",
        "        poss = []\n",
        "        for i in range(len(tags)):\n",
        "            pos = []\n",
        "            for j in range(len(tags[i])):\n",
        "                if tags[i][j] == 0:\n",
        "                    pos.append(j)\n",
        "            poss.append(pos)\n",
        "\n",
        "        kw_true.extend(TagConvert(tags, tokens))\n",
        "        kw_pred.extend(TagConvert(pred_tags, tokens, poss))\n",
        "\n",
        "    label_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "    P, R, F1 = evaluate(kw_true, kw_pred)\n",
        "\n",
        "    if F1 > best_f1:\n",
        "        best_f1 = F1\n",
        "        torch.save(model.state_dict(), './pretrain_pt/bert_HAtten.pt')\n",
        "\n",
        "    print(\"epoch{}:  loss:{:.2f}   train_f1_value:{:.2f}  test_f1_value:{:.2f}  kw_f1_value:{:.2f}\".format(\n",
        "        epoch + 1, loss_value / len(train_dataloader), label_train_f1, label_f1, F1\n",
        "    ))\n",
        "\n",
        "    torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vv5VsYgA30fI"
      },
      "outputs": [],
      "source": [
        "def load_model(model_path, num_labels):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = BertHANModel(num_labels=num_labels)\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "def calculate_f1(y_pred, y_true):\n",
        "    y_true = y_true.view(-1)\n",
        "    y_pred = y_pred.view(-1)\n",
        "    y_true = y_true.detach().cpu().numpy()\n",
        "    y_pred = y_pred.detach().cpu().numpy()\n",
        "    mask = np.where(y_true != 0)\n",
        "    y_true = y_true[mask]\n",
        "    y_pred = y_pred[mask]\n",
        "    return y_pred, y_true\n",
        "\n",
        "def TagConvert(raw_tags, words_set, poss=None):\n",
        "    true_tags = []\n",
        "    for i in range(raw_tags.shape[0]):\n",
        "        kw_list = []\n",
        "        nkw_list = \"\"\n",
        "        for j in range(len(raw_tags[i])):\n",
        "            item = raw_tags[i][j]\n",
        "            if item == 0:\n",
        "                continue\n",
        "            if poss != None and j in poss[i]:\n",
        "                continue\n",
        "            if item == 4:\n",
        "                kw_list.append(str(words_set[j][i]))\n",
        "            if item == 1:\n",
        "                nkw_list += str(words_set[j][i])\n",
        "            if item == 2:\n",
        "                nkw_list += \" \"\n",
        "                nkw_list += str(words_set[j][i])\n",
        "            if item == 3:\n",
        "                nkw_list += \" \"\n",
        "                nkw_list += str(words_set[j][i])\n",
        "                kw_list.append(nkw_list)\n",
        "                nkw_list = \"\"\n",
        "        true_tags.append(kw_list)\n",
        "    return true_tags\n",
        "\n",
        "def evaluate(predict_data, target_data, topk=3):\n",
        "    TRUE_COUNT, PRED_COUNT, GOLD_COUNT = 0.0, 0.0, 0.0\n",
        "    for index, words in enumerate(predict_data):\n",
        "        y_pred, y_true = None, target_data[index]\n",
        "        if type(predict_data) == str:\n",
        "            words = sorted(words.items(), key=lambda item: (-item[1], item[0]))\n",
        "            y_pred = [i[0] for i in words]\n",
        "        elif type(predict_data) == list:\n",
        "            y_pred = words\n",
        "        y_pred = y_pred[0: topk]\n",
        "        TRUE_NUM = len(set(y_pred) & set(y_true))\n",
        "        TRUE_COUNT += TRUE_NUM\n",
        "        PRED_COUNT += len(y_pred)\n",
        "        GOLD_COUNT += len(y_true)\n",
        "    if PRED_COUNT != 0:\n",
        "        p = (TRUE_COUNT / PRED_COUNT)\n",
        "    else:\n",
        "        p = 0\n",
        "    if GOLD_COUNT != 0:\n",
        "        r = (TRUE_COUNT / GOLD_COUNT)\n",
        "    else:\n",
        "        r = 0\n",
        "    if (r + p) != 0:\n",
        "        f1 = ((2 * r * p) / (r + p))\n",
        "    else:\n",
        "        f1 = 0\n",
        "    p = round(p * 100, 2)\n",
        "    r = round(r * 100, 2)\n",
        "    f1 = round(f1 * 100, 2)\n",
        "    return p, r, f1\n",
        "\n",
        "def predict_and_evaluate(model, dataloader):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    label_true, label_pred = [], []\n",
        "    kw_true, kw_pred = [], []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_masks = batch[1].to(device)\n",
        "            tokens = batch[2]\n",
        "            tags = batch[4].to(device)\n",
        "\n",
        "            pred_tags = model(input_ids, attention_masks)\n",
        "            pred_tags = torch.argmax(pred_tags, dim=-1)\n",
        "\n",
        "            y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "            label_true.extend(y_true)\n",
        "            label_pred.extend(y_pred)\n",
        "\n",
        "            poss = []\n",
        "            for i in range(len(tags)):\n",
        "                pos = []\n",
        "                for j in range(len(tags[i])):\n",
        "                    if tags[i][j] == 0:\n",
        "                        pos.append(j)\n",
        "                poss.append(pos)\n",
        "            kw_true.extend(TagConvert(tags, tokens))\n",
        "            kw_pred.extend(TagConvert(pred_tags, tokens, poss))\n",
        "\n",
        "    label_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "    P, R, F1 = evaluate(kw_true, kw_pred)\n",
        "    return label_f1, P, R, F1\n",
        "\n",
        "# 加载模型\n",
        "model_path = './pretrain_pt/bert_HAtten.pt'\n",
        "num_labels = 6\n",
        "model = load_model(model_path, num_labels)\n",
        "\n",
        "# 假设 test_dataloader 已经定义好\n",
        "label_f1, P, R, F1 = predict_and_evaluate(model, test_dataloader)\n",
        "\n",
        "print(f\"label_f1: {label_f1:.2f}, Precision: {P:.2f}, Recall: {R:.2f}, F1: {F1:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rc65AZDF0E_C"
      },
      "source": [
        "#####其它模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "S7FCLYyZfOMX"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "train_path = '/content/drive/MyDrive/ner/datas/General-Twitter/train.json'\n",
        "test_path = '/content/drive/MyDrive/ner/datas/General-Twitter/test.json'\n",
        "\n",
        "\n",
        "# 加载训练和测试数据\n",
        "with open(train_path, 'r', encoding='utf-8') as f:\n",
        "    train_file = json.load(f)\n",
        "\n",
        "with open(test_path, 'r', encoding='utf-8') as f:\n",
        "    test_file = json.load(f)\n",
        "\n",
        "# 预处理训练数据\n",
        "train_sens, train_tags, train_Feature = [], [], []\n",
        "train_word_nums = []\n",
        "\n",
        "for key in train_file.keys():\n",
        "    items = train_file[key]\n",
        "    sens = ''\n",
        "    tags = []\n",
        "    features = []\n",
        "    nums = 0\n",
        "\n",
        "    for item in items:\n",
        "        sens += item[0] + ' '\n",
        "        features.append(item[1:-1])  # 取出ET和EEG特征\n",
        "        tags.append(item[-1])  # 最后一个是标签\n",
        "        nums += 1\n",
        "\n",
        "    train_sens.append(sens.strip())\n",
        "    train_Feature.append(features)\n",
        "    train_tags.append(tags)\n",
        "    train_word_nums.append(nums)\n",
        "\n",
        "# 预处理测试数据\n",
        "test_sens, test_tags, test_Feature = [], [], []\n",
        "test_word_nums = []\n",
        "\n",
        "for key in test_file.keys():\n",
        "    items = test_file[key]\n",
        "    sens = ''\n",
        "    tags = []\n",
        "    features = []\n",
        "    nums = 0\n",
        "\n",
        "    for item in items:\n",
        "        sens += item[0] + ' '\n",
        "        features.append(item[1:-1])  # 取出ET和EEG特征\n",
        "        tags.append(item[-1])  # 最后一个是标签\n",
        "        nums += 1\n",
        "\n",
        "    test_sens.append(sens.strip())\n",
        "    test_Feature.append(features)\n",
        "    test_tags.append(tags)\n",
        "    test_word_nums.append(nums)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NzX7X_7bfQTK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306,
          "referenced_widgets": [
            "88ea6fa2fc59446487090f4fdbb1d61b",
            "9dced3351ebd4627a58079e67a736eb1",
            "51dc9d285d5148cebde1efe209041132",
            "96ac6a6130e24e11a1258886042320a9",
            "c0b9ffa5f2ee4810831c1b9fdfab8d63",
            "c1d55e15a1244e179e0119285cfb501a",
            "de8463e50b794ad9a8994b5be60ee935",
            "d8d36725e2b842a190ee22a751fbb924",
            "e765214895ba4b029c93736b2e58892b",
            "8dde3aa8019348a2a6bc540b0e57cad5",
            "edfa3e1136f64118a6e76991e40cd58b",
            "167092269cb840efbe4e95a2000b5703",
            "31211574145a4138ac5d1ae6f89f74ba",
            "eab63c32415d4b8882560321f537675a",
            "f9692b7561f043588a0d2773c2c06c46",
            "05120dc176154475887db24de2d833b7",
            "7d44aae3f4d74a4a853a92cac240aadd",
            "e030d32be4514c9f8f033fd9341a931b",
            "76922e969dee4cb4bbe2272192700d4b",
            "6748e2edc43546c9b93ddcc2f4b9e03a",
            "8508fd67fa9c4c6d8637ae3436c4ceaa",
            "86421260503d4e13b27eb16d905256bf",
            "d5e08b3680b64d8d815112e3e50e89c5",
            "ddb8f0f154ff4821a0188e7b1337cd71",
            "f1f8ff1c1100476db331d58f5c0a90cc",
            "04fbc0fe65ad4348babaa94bf1234993",
            "61efd7e27f764c8fb6579d66ba37586c",
            "363a827e8f764cdc84b2aeee90209d10",
            "e9849f79dc084d78ac50870f1d4b5dbc",
            "57d0b05ecd4b4e3f895b1367642b25ba",
            "6a5c470b037f4a3a91c40e51cc4a7b47",
            "ab8f3b41e9d143e59fe64f11bf873892",
            "28cee84eb92045799e36f12ed7b817b7",
            "0dd9c1414816484b979b2b298be3711d",
            "c79bc7abcde540feb7682ab0cfe658fb",
            "6c99e78fba514e4ea655b197048688da",
            "9d0c8e336b2b40baa5d4c48c3f559e36",
            "962e13b3dfe546539f8f13e2c697f354",
            "4ecc3ff8a10f4a4589ece3947785da0e",
            "40b0f3a59c6540c3832a6a40bb036a5d",
            "d0e8bdc300fd4066af7996910c9232ea",
            "9c7a5a8284734a649f03aac8a0fdbddd",
            "16081b36090f4120b452a9ac959e182f",
            "d657b178cb6440889a348af0b99cf260",
            "7599fab0f50449d08c13062ec37421bb",
            "23d908040fa24bed82604e9dd8d3ac1f",
            "3e3dcd7a924240dcbca6c5489dbd93be",
            "1f3971f0d4e740728969930e76c9b180",
            "e19f7ab338ab407da4bcd7e2aa05815f",
            "bb3734c2c36b409c9ac59e88c9fcc2cb",
            "80546119670a4839af711a34542f6cbd",
            "bf235ab9d6d8417d889d6797c75f2e6a",
            "b6648c0469d744c09648b7fa44cb7eb3",
            "6851f615bd094ec196f83164ff418515",
            "d65345ed86494d11a3be0b308907bfca"
          ]
        },
        "outputId": "f06b1db2-2557-487b-9aee-6b755bc6fea7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88ea6fa2fc59446487090f4fdbb1d61b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "167092269cb840efbe4e95a2000b5703"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5e08b3680b64d8d815112e3e50e89c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0dd9c1414816484b979b2b298be3711d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7599fab0f50449d08c13062ec37421bb"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import RobertaTokenizerFast\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 加载tokenizer\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n",
        "max_len = 128  # 设置最大序列长度\n",
        "\n",
        "label_to_ids = {'none': 0, 'B': 1, 'I': 2, 'E': 3, 'S': 4, \"O\": 5}\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, texts, old_features, tags):\n",
        "        self.texts = texts\n",
        "        self.tags = tags\n",
        "        self.old_features = old_features\n",
        "\n",
        "        self.labels = []\n",
        "        self.tokens = []\n",
        "        self.features = []\n",
        "\n",
        "        self.input_ids = None\n",
        "        self.attention_masks = None\n",
        "\n",
        "    def encode(self):\n",
        "        for i in tqdm(range(len(self.texts))):\n",
        "            text = self.texts[i]\n",
        "            tag = self.tags[i]\n",
        "            feature = self.old_features[i]\n",
        "            tags, tokens, features = align_label(text, tag, feature)\n",
        "            self.labels.append(tags)\n",
        "            self.tokens.append(tokens)\n",
        "            self.features.append(features)\n",
        "\n",
        "        self.features = np.array(self.features, float)\n",
        "        self.inputs = tokenizer(self.texts, max_length=max_len, add_special_tokens=True, padding='max_length', truncation=True, return_tensors='pt')\n",
        "        self.input_ids = self.inputs['input_ids']\n",
        "        self.attention_masks = self.inputs['attention_mask']\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx, :], self.attention_masks[idx, :], self.tokens[idx], torch.tensor(self.features[idx], dtype=torch.float32), torch.tensor(self.labels[idx])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mGUNOy02fUxF"
      },
      "outputs": [],
      "source": [
        "def align_label(text, labels, features):\n",
        "    input = tokenizer(text, max_length=max_len, add_special_tokens=True, padding='max_length', truncation=True, return_tensors='pt')\n",
        "    word_ids = input.word_ids()\n",
        "    input_ids = input['input_ids']\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "\n",
        "    previous_word_idx = None\n",
        "    new_labels, new_features = [], []\n",
        "    no_features = [0 for _ in range(1, 26)]  # 根据特征数量调整\n",
        "\n",
        "    for word_idx in word_ids:\n",
        "        if word_idx is None:\n",
        "            new_labels.append('none')\n",
        "            new_features.append(no_features)\n",
        "        elif word_idx != previous_word_idx:\n",
        "            try:\n",
        "                new_labels.append(labels[word_idx])\n",
        "                new_features.append(features[word_idx])\n",
        "            except:\n",
        "                new_labels.append('none')\n",
        "                new_features.append(no_features)\n",
        "        else:\n",
        "            try:\n",
        "                new_labels.append(labels[word_idx] if label_all_tokens else 'none')\n",
        "                new_features.append(features[word_idx] if label_all_tokens else no_features)\n",
        "            except:\n",
        "                new_labels.append('none')\n",
        "                new_features.append(no_features)\n",
        "        previous_word_idx = word_idx\n",
        "\n",
        "    label_ids = [label_to_ids[label] for label in new_labels]\n",
        "    return label_ids, tokens, new_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lVjAsMC5BVh8"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8Q73w0wfagL",
        "outputId": "ab3f48c1-7462-4286-d4d8-ce398ebc4f7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 78760/78760 [00:52<00:00, 1500.18it/s]\n",
            "100%|██████████| 33755/33755 [00:21<00:00, 1556.89it/s]\n"
          ]
        }
      ],
      "source": [
        "# 创建数据集对象\n",
        "train_dataset = MyDataset(train_sens, train_Feature, train_tags)\n",
        "train_dataset.encode()\n",
        "\n",
        "test_dataset = MyDataset(test_sens, test_Feature, test_tags)\n",
        "test_dataset.encode()\n",
        "\n",
        "# 数据加载器\n",
        "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=128)\n",
        "test_dataloader = DataLoader(test_dataset, shuffle=True, batch_size=128)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "9d34d55ef0ef418d8b8bcecd37aa7764",
            "650cc13d810a46bc99c2d44b470eea5a",
            "246ec5d639f749519e301ada046371a3",
            "00e7e29874454a0db0354108ca082ce4",
            "c27c4b6024e349c290ab6ea96c003854",
            "15426628ecf1485d8887354d723cfd8f",
            "46bc624d9494433997e978592ceac1fe",
            "3e89079c7c214b828a9690007691cfff",
            "27301c9bdac945db8b3278a50688e220",
            "775aa6aa5d1744c4b320b9c26a810132",
            "4c7d30477ba94c03ab41425ca4e1d076"
          ]
        },
        "id": "cheRiv5MWJOa",
        "outputId": "2a67e62e-5b19-4de1-f22e-4e4cd17eba85"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d34d55ef0ef418d8b8bcecd37aa7764"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import RobertaTokenizerFast, RobertaForTokenClassification\n",
        "\n",
        "# 加载预训练的tokenizer和模型\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n",
        "model = RobertaForTokenClassification.from_pretrained(\"roberta-base\", num_labels=len(label_to_ids))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnlAIDFsWQoe"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from transformers import RobertaModel\n",
        "\n",
        "class RobertaNerModel(nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super(RobertaNerModel, self).__init__()\n",
        "        # 加载预训练的RoBERTa模型\n",
        "        self.bert = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(768 + 25, num_labels)  # 假设你有25个额外特征\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, extra_features, token_type_ids=None):\n",
        "        # 前向传播\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        pooled_output = outputs.last_hidden_state  # 获取RoBERTa的最后一层隐藏状态\n",
        "        #print(\"Pooled output shape:\", pooled_output.shape)\n",
        "\n",
        "        bert_outputs = self.dropout(pooled_output)\n",
        "        outputs = torch.concat((bert_outputs, extra_features), -1)  # 拼接额外特征\n",
        "        outputs = self.classifier(outputs)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7Lty9QGWc6e"
      },
      "outputs": [],
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader, epochs=3, lr=2e-5):\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    model = model.to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # 将数据加载到GPU\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            extra_features = batch[3].to(device)\n",
        "            labels = batch[4].to(device)\n",
        "\n",
        "            # 输出输入数据的形状\n",
        "\n",
        "\n",
        "            try:\n",
        "                # 模型前向传播\n",
        "                outputs = model(input_ids, attention_mask, extra_features)\n",
        "\n",
        "\n",
        "                # 计算损失\n",
        "                loss = loss_fn(outputs.view(-1, outputs.shape[-1]), labels.view(-1))\n",
        "                total_loss += loss.item()\n",
        "                #print(f\"Loss at step {step+1}: {loss.item()}\")\n",
        "\n",
        "                # 反向传播\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "\n",
        "            except RuntimeError as e:\n",
        "                print(f\"Runtime error at step {step+1}: {str(e)}\")\n",
        "                print(\"Skipping this batch...\")\n",
        "                continue\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "        print(f\"Epoch {epoch + 1}, Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # 验证模型\n",
        "        evaluate(model, val_dataloader)\n",
        "\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    model.eval()\n",
        "    eval_loss = 0\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    correct_preds, total_preds = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            extra_features = batch[3].to(device)\n",
        "            labels = batch[4].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask, extra_features)\n",
        "            loss = loss_fn(outputs.view(-1, outputs.shape[-1]), labels.view(-1))\n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=-1)\n",
        "\n",
        "            all_preds.extend(preds.view(-1).cpu().numpy())\n",
        "            all_labels.extend(labels.view(-1).cpu().numpy())\n",
        "\n",
        "            correct_preds += (preds == labels).sum().item()\n",
        "            total_preds += labels.numel()\n",
        "\n",
        "    avg_eval_loss = eval_loss / len(val_dataloader)\n",
        "    accuracy = correct_preds / total_preds\n",
        "\n",
        "    # 计算 P, R, F1\n",
        "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"Validation Loss: {avg_eval_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oPoVRVu5Wfgj"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# 将数据集划分为训练集和验证集\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=64)\n",
        "val_dataloader = DataLoader(val_dataset, shuffle=True, batch_size=64)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "k3-SLK7Kf86S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "687c35c6-9573-42c8-ddb6-69a79f7b2ea9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ],
      "source": [
        "print(len(label_to_ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGdAy9NFftee",
        "outputId": "10d7491b-f462-4c97-ea09-d277c2a2e4a4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Training Loss: 0.0279\n",
            "Validation Loss: 0.0140, Accuracy: 0.9953\n",
            "Precision: 0.8943, Recall: 0.8554, F1 Score: 0.8736\n",
            "Epoch 2, Training Loss: 0.0118\n",
            "Validation Loss: 0.0119, Accuracy: 0.9960\n",
            "Precision: 0.8895, Recall: 0.8942, F1 Score: 0.8916\n",
            "Epoch 3, Training Loss: 0.0082\n",
            "Validation Loss: 0.0117, Accuracy: 0.9964\n",
            "Precision: 0.9067, Recall: 0.8957, F1 Score: 0.9011\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = RobertaNerModel(num_labels=len(label_to_ids))\n",
        "\n",
        "# 开始训练模型\n",
        "train(model, train_dataloader, val_dataloader, epochs=3, lr=2e-5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6LnSszn9265_"
      },
      "outputs": [],
      "source": [
        "def test(model, test_dataloader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    correct_preds, total_preds = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            extra_features = batch[3].to(device)\n",
        "            labels = batch[4].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask, extra_features)\n",
        "            loss = loss_fn(outputs.view(-1, outputs.shape[-1]), labels.view(-1))\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=-1)\n",
        "\n",
        "            all_preds.extend(preds.view(-1).cpu().numpy())\n",
        "            all_labels.extend(labels.view(-1).cpu().numpy())\n",
        "\n",
        "            correct_preds += (preds == labels).sum().item()\n",
        "            total_preds += labels.numel()\n",
        "\n",
        "    avg_test_loss = test_loss / len(test_dataloader)\n",
        "    accuracy = correct_preds / total_preds\n",
        "\n",
        "    # 计算 P, R, F1\n",
        "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"Test Loss: {avg_test_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    return avg_test_loss, accuracy, precision, recall, f1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3xKsYBIi28Z6",
        "outputId": "ba6728ac-d170-4f96-ba31-3af045959fd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.0118, Accuracy: 0.9964\n",
            "Precision: 0.9059, Recall: 0.8957, F1 Score: 0.9008\n"
          ]
        }
      ],
      "source": [
        "# 假设已经定义了 test_dataloader\n",
        "# test_dataloader = ...\n",
        "\n",
        "# 在测试集上评估模型\n",
        "test_loss, test_accuracy, test_precision, test_recall, test_f1 = test(model, test_dataloader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmUBkgZ9C6Jm"
      },
      "outputs": [],
      "source": [
        "##############################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQ223iKbCfMP",
        "outputId": "7cd4cdec-29d6-411b-df39-5c456395b277"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Training Loss: 0.0808\n",
            "Validation Loss: 0.0286, Accuracy: 0.9909\n",
            "Precision: 0.8189, Recall: 0.6978, F1 Score: 0.7484\n",
            "Epoch 2, Training Loss: 0.0272\n",
            "Validation Loss: 0.0213, Accuracy: 0.9929\n",
            "Precision: 0.8198, Recall: 0.7971, F1 Score: 0.8078\n",
            "Epoch 3, Training Loss: 0.0224\n",
            "Validation Loss: 0.0202, Accuracy: 0.9933\n",
            "Precision: 0.8284, Recall: 0.8093, F1 Score: 0.8183\n",
            "Test Loss: 0.0205, Accuracy: 0.9933\n",
            "Precision: 0.8327, Recall: 0.8094, F1 Score: 0.8205\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "from transformers import RobertaModel\n",
        "\n",
        "class RobertaNerModel(nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super(RobertaNerModel, self).__init__()\n",
        "        # 加载预训练的RoBERTa模型\n",
        "        self.bert = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(768 + 17, num_labels)  # 假设你有25个额外特征\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, extra_features, token_type_ids=None):\n",
        "        # 前向传播\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        pooled_output = outputs.last_hidden_state  # 获取RoBERTa的最后一层隐藏状态\n",
        "        #print(\"Pooled output shape:\", pooled_output.shape)\n",
        "\n",
        "        bert_outputs = self.dropout(pooled_output)\n",
        "        eeg_features = extra_features[:, :, :17]  # [batch_size, seq_len, 8]\n",
        "\n",
        "        outputs = torch.concat((bert_outputs, eeg_features), -1)  # 拼接额外特征\n",
        "\n",
        "        outputs = self.classifier(outputs)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader, epochs=3, lr=2e-5):\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    model = model.to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # 将数据加载到GPU\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            extra_features = batch[3].to(device)\n",
        "            labels = batch[4].to(device)\n",
        "\n",
        "            # 输出输入数据的形状\n",
        "\n",
        "\n",
        "            try:\n",
        "                # 模型前向传播\n",
        "                outputs = model(input_ids, attention_mask, extra_features)\n",
        "\n",
        "\n",
        "                # 计算损失\n",
        "                loss = loss_fn(outputs.view(-1, outputs.shape[-1]), labels.view(-1))\n",
        "                total_loss += loss.item()\n",
        "                #print(f\"Loss at step {step+1}: {loss.item()}\")\n",
        "\n",
        "                # 反向传播\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "\n",
        "            except RuntimeError as e:\n",
        "                print(f\"Runtime error at step {step+1}: {str(e)}\")\n",
        "                print(\"Skipping this batch...\")\n",
        "                continue\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "        print(f\"Epoch {epoch + 1}, Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # 验证模型\n",
        "        evaluate(model, val_dataloader)\n",
        "\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    model.eval()\n",
        "    eval_loss = 0\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    correct_preds, total_preds = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            extra_features = batch[3].to(device)\n",
        "            labels = batch[4].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask, extra_features)\n",
        "            loss = loss_fn(outputs.view(-1, outputs.shape[-1]), labels.view(-1))\n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=-1)\n",
        "\n",
        "            all_preds.extend(preds.view(-1).cpu().numpy())\n",
        "            all_labels.extend(labels.view(-1).cpu().numpy())\n",
        "\n",
        "            correct_preds += (preds == labels).sum().item()\n",
        "            total_preds += labels.numel()\n",
        "\n",
        "    avg_eval_loss = eval_loss / len(val_dataloader)\n",
        "    accuracy = correct_preds / total_preds\n",
        "\n",
        "    # 计算 P, R, F1\n",
        "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"Validation Loss: {avg_eval_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# 将数据集划分为训练集和验证集\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=128)\n",
        "val_dataloader = DataLoader(val_dataset, shuffle=True, batch_size=128)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = RobertaNerModel(num_labels=len(label_to_ids))\n",
        "\n",
        "# 开始训练模型\n",
        "train(model, train_dataloader, val_dataloader, epochs=3, lr=2e-5)\n",
        "def test(model, test_dataloader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    correct_preds, total_preds = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            extra_features = batch[3].to(device)\n",
        "            labels = batch[4].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask, extra_features)\n",
        "            loss = loss_fn(outputs.view(-1, outputs.shape[-1]), labels.view(-1))\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=-1)\n",
        "\n",
        "            all_preds.extend(preds.view(-1).cpu().numpy())\n",
        "            all_labels.extend(labels.view(-1).cpu().numpy())\n",
        "\n",
        "            correct_preds += (preds == labels).sum().item()\n",
        "            total_preds += labels.numel()\n",
        "\n",
        "    avg_test_loss = test_loss / len(test_dataloader)\n",
        "    accuracy = correct_preds / total_preds\n",
        "\n",
        "    # 计算 P, R, F1\n",
        "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"Test Loss: {avg_test_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    return avg_test_loss, accuracy, precision, recall, f1\n",
        "# 假设已经定义了 test_dataloader\n",
        "# test_dataloader = ...\n",
        "\n",
        "# 在测试集上评估模型\n",
        "test_loss, test_accuracy, test_precision, test_recall, test_f1 = test(model, test_dataloader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPLpOjz-27qt",
        "outputId": "2fedc470-494c-4155-f3c4-1eaa449dd933"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.0204, Accuracy: 0.9933\n",
            "Precision: 0.8327, Recall: 0.8094, F1 Score: 0.8205\n"
          ]
        }
      ],
      "source": [
        "def test(model, test_dataloader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    correct_preds, total_preds = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            extra_features = batch[3].to(device)\n",
        "            labels = batch[4].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask, extra_features)\n",
        "            loss = loss_fn(outputs.view(-1, outputs.shape[-1]), labels.view(-1))\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=-1)\n",
        "\n",
        "            all_preds.extend(preds.view(-1).cpu().numpy())\n",
        "            all_labels.extend(labels.view(-1).cpu().numpy())\n",
        "\n",
        "            correct_preds += (preds == labels).sum().item()\n",
        "            total_preds += labels.numel()\n",
        "\n",
        "    avg_test_loss = test_loss / len(test_dataloader)\n",
        "    accuracy = correct_preds / total_preds\n",
        "\n",
        "    # 计算 P, R, F1\n",
        "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"Test Loss: {avg_test_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    return avg_test_loss, accuracy, precision, recall, f1\n",
        "# 假设已经定义了 test_dataloader\n",
        "# test_dataloader = ...\n",
        "\n",
        "# 在测试集上评估模型\n",
        "test_loss, test_accuracy, test_precision, test_recall, test_f1 = test(model, test_dataloader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "798NtoOwapLR",
        "outputId": "ef6ad6b3-61a3-4c6c-cf10-0be4296dbea9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Training Loss: 0.1164\n",
            "Validation Loss: 0.0425, Accuracy: 0.9864\n",
            "Precision: 0.6724, Recall: 0.5935, F1 Score: 0.5710\n",
            "Epoch 2, Training Loss: 0.0371\n",
            "Validation Loss: 0.0275, Accuracy: 0.9909\n",
            "Precision: 0.7729, Recall: 0.7418, F1 Score: 0.7554\n",
            "Epoch 3, Training Loss: 0.0290\n",
            "Validation Loss: 0.0255, Accuracy: 0.9918\n",
            "Precision: 0.7880, Recall: 0.7718, F1 Score: 0.7793\n",
            "Test Loss: 0.0254, Accuracy: 0.9918\n",
            "Precision: 0.7923, Recall: 0.7755, F1 Score: 0.7834\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "from transformers import RobertaModel\n",
        "\n",
        "class RobertaNerModel(nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super(RobertaNerModel, self).__init__()\n",
        "        # 加载预训练的RoBERTa模型\n",
        "        self.bert = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(768 + 8, num_labels)  # 假设你有25个额外特征\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, extra_features, token_type_ids=None):\n",
        "        # 前向传播\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        pooled_output = outputs.last_hidden_state  # 获取RoBERTa的最后一层隐藏状态\n",
        "        #print(\"Pooled output shape:\", pooled_output.shape)\n",
        "\n",
        "        bert_outputs = self.dropout(pooled_output)\n",
        "        eeg_features = extra_features[:, :,-8:]  # [batch_size, seq_len, 8]\n",
        "\n",
        "        outputs = torch.concat((bert_outputs, eeg_features), -1)  # 拼接额外特征\n",
        "\n",
        "        outputs = self.classifier(outputs)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader, epochs=3, lr=2e-5):\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    model = model.to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # 将数据加载到GPU\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            extra_features = batch[3].to(device)\n",
        "            labels = batch[4].to(device)\n",
        "\n",
        "            # 输出输入数据的形状\n",
        "\n",
        "\n",
        "            try:\n",
        "                # 模型前向传播\n",
        "                outputs = model(input_ids, attention_mask, extra_features)\n",
        "\n",
        "\n",
        "                # 计算损失\n",
        "                loss = loss_fn(outputs.view(-1, outputs.shape[-1]), labels.view(-1))\n",
        "                total_loss += loss.item()\n",
        "                #print(f\"Loss at step {step+1}: {loss.item()}\")\n",
        "\n",
        "                # 反向传播\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "\n",
        "            except RuntimeError as e:\n",
        "                print(f\"Runtime error at step {step+1}: {str(e)}\")\n",
        "                print(\"Skipping this batch...\")\n",
        "                continue\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "        print(f\"Epoch {epoch + 1}, Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # 验证模型\n",
        "        evaluate(model, val_dataloader)\n",
        "\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    model.eval()\n",
        "    eval_loss = 0\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    correct_preds, total_preds = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            extra_features = batch[3].to(device)\n",
        "            labels = batch[4].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask, extra_features)\n",
        "            loss = loss_fn(outputs.view(-1, outputs.shape[-1]), labels.view(-1))\n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=-1)\n",
        "\n",
        "            all_preds.extend(preds.view(-1).cpu().numpy())\n",
        "            all_labels.extend(labels.view(-1).cpu().numpy())\n",
        "\n",
        "            correct_preds += (preds == labels).sum().item()\n",
        "            total_preds += labels.numel()\n",
        "\n",
        "    avg_eval_loss = eval_loss / len(val_dataloader)\n",
        "    accuracy = correct_preds / total_preds\n",
        "\n",
        "    # 计算 P, R, F1\n",
        "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"Validation Loss: {avg_eval_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# 将数据集划分为训练集和验证集\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=128)\n",
        "val_dataloader = DataLoader(val_dataset, shuffle=True, batch_size=128)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = RobertaNerModel(num_labels=len(label_to_ids))\n",
        "\n",
        "# 开始训练模型\n",
        "train(model, train_dataloader, val_dataloader, epochs=3, lr=2e-5)\n",
        "def test(model, test_dataloader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    correct_preds, total_preds = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            extra_features = batch[3].to(device)\n",
        "            labels = batch[4].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask, extra_features)\n",
        "            loss = loss_fn(outputs.view(-1, outputs.shape[-1]), labels.view(-1))\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=-1)\n",
        "\n",
        "            all_preds.extend(preds.view(-1).cpu().numpy())\n",
        "            all_labels.extend(labels.view(-1).cpu().numpy())\n",
        "\n",
        "            correct_preds += (preds == labels).sum().item()\n",
        "            total_preds += labels.numel()\n",
        "\n",
        "    avg_test_loss = test_loss / len(test_dataloader)\n",
        "    accuracy = correct_preds / total_preds\n",
        "\n",
        "    # 计算 P, R, F1\n",
        "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"Test Loss: {avg_test_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    return avg_test_loss, accuracy, precision, recall, f1\n",
        "# 假设已经定义了 test_dataloader\n",
        "# test_dataloader = ...\n",
        "\n",
        "# 在测试集上评估模型\n",
        "test_loss, test_accuracy, test_precision, test_recall, test_f1 = test(model, test_dataloader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXqfsRT93D1a",
        "outputId": "90e82ab4-149e-4a18-b8a4-827be01026b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.0254, Accuracy: 0.9918\n",
            "Precision: 0.7923, Recall: 0.7755, F1 Score: 0.7834\n"
          ]
        }
      ],
      "source": [
        "def test(model, test_dataloader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    correct_preds, total_preds = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            extra_features = batch[3].to(device)\n",
        "            labels = batch[4].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask, extra_features)\n",
        "            loss = loss_fn(outputs.view(-1, outputs.shape[-1]), labels.view(-1))\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=-1)\n",
        "\n",
        "            all_preds.extend(preds.view(-1).cpu().numpy())\n",
        "            all_labels.extend(labels.view(-1).cpu().numpy())\n",
        "\n",
        "            correct_preds += (preds == labels).sum().item()\n",
        "            total_preds += labels.numel()\n",
        "\n",
        "    avg_test_loss = test_loss / len(test_dataloader)\n",
        "    accuracy = correct_preds / total_preds\n",
        "\n",
        "    # 计算 P, R, F1\n",
        "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"Test Loss: {avg_test_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    return avg_test_loss, accuracy, precision, recall, f1\n",
        "# 假设已经定义了 test_dataloader\n",
        "# test_dataloader = ...\n",
        "\n",
        "# 在测试集上评估模型\n",
        "test_loss, test_accuracy, test_precision, test_recall, test_f1 = test(model, test_dataloader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CB0PzwCIMQLa"
      },
      "source": [
        "#####不同EEG组合"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from sklearn.metrics import f1_score\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "optim = AdamW(model.parameters(), lr=5e-5, weight_decay=1e-2)\n",
        "loss_fn = CrossEntropyLoss(reduction='none', ignore_index=0)\n",
        "loss_fn = loss_fn.to(device)\n",
        "\n",
        "def calculate_f1(y_pred, y_true):\n",
        "    y_true = y_true.view(-1)\n",
        "    y_pred = y_pred.view(-1)\n",
        "    y_true = y_true.detach().cpu().numpy()\n",
        "    y_pred = y_pred.detach().cpu().numpy()\n",
        "\n",
        "    mask = np.where(y_true != 0)\n",
        "\n",
        "    y_true = y_true[mask]\n",
        "    y_pred = y_pred[mask]\n",
        "\n",
        "    return y_pred, y_true\n",
        "\n",
        "def TagConvert(raw_tags, words_set, poss=None):\n",
        "    true_tags = []\n",
        "    for i in range(raw_tags.shape[0]):\n",
        "        kw_list = []\n",
        "        nkw_list = \"\"\n",
        "        for j in range(len(raw_tags[i])):\n",
        "            item = raw_tags[i][j]\n",
        "            if item == 0:\n",
        "                continue\n",
        "            if poss != None and j in poss[i]:\n",
        "                continue\n",
        "            if item == 4:\n",
        "                kw_list.append(str(words_set[j][i]))\n",
        "            if item == 1:\n",
        "                nkw_list += str(words_set[j][i])\n",
        "            if item == 2:\n",
        "                nkw_list += \" \"\n",
        "                nkw_list += str(words_set[j][i])\n",
        "            if item == 3:\n",
        "                nkw_list += \" \"\n",
        "                nkw_list += str(words_set[j][i])\n",
        "                kw_list.append(nkw_list)\n",
        "                nkw_list = \"\"\n",
        "\n",
        "        true_tags.append(kw_list)\n",
        "    return true_tags\n",
        "\n",
        "def evaluate(predict_data, target_data, topk=3):\n",
        "    TRUE_COUNT, PRED_COUNT, GOLD_COUNT = 0.0, 0.0, 0.0\n",
        "    for index, words in enumerate(predict_data):\n",
        "        y_pred, y_true = None, target_data[index]\n",
        "\n",
        "        if type(predict_data) == str:\n",
        "            words = sorted(words.items(), key=lambda item: (-item[1], item[0]))\n",
        "            y_pred = [i[0] for i in words]\n",
        "        elif type(predict_data) == list:\n",
        "            y_pred = words\n",
        "\n",
        "        y_pred = y_pred[0: topk]\n",
        "        TRUE_NUM = len(set(y_pred) & set(y_true))\n",
        "        TRUE_COUNT += TRUE_NUM\n",
        "        PRED_COUNT += len(y_pred)\n",
        "        GOLD_COUNT += len(y_true)\n",
        "    if PRED_COUNT != 0:\n",
        "        p = (TRUE_COUNT / PRED_COUNT)\n",
        "    else:\n",
        "        p = 0\n",
        "    if GOLD_COUNT != 0:\n",
        "        r = (TRUE_COUNT / GOLD_COUNT)\n",
        "    else:\n",
        "        r = 0\n",
        "    if (r + p) != 0:\n",
        "        f1 = ((2 * r * p) / (r + p))\n",
        "    else:\n",
        "        f1 = 0\n",
        "\n",
        "    p = round(p * 100, 2)\n",
        "    r = round(r * 100, 2)\n",
        "    f1 = round(f1 * 100, 2)\n",
        "\n",
        "    return p, r, f1"
      ],
      "metadata": {
        "id": "6FJNegVf_LDe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "from transformers import RobertaModel\n",
        "from torch import nn\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "\n",
        "\n",
        "# 定义 RobertaNerModel\n",
        "class RobertaNerModel(nn.Module):\n",
        "    def __init__(self, num_labels, hidden_dim=768, eeg_dim=8):\n",
        "        super(RobertaNerModel, self).__init__()\n",
        "        self.roberta = RobertaModel.from_pretrained('roberta-base')\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(hidden_dim + eeg_dim, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, extra_features):\n",
        "        roberta_outputs = self.roberta(input_ids, attention_mask=attention_mask)\n",
        "        sequence_output = roberta_outputs[0]  # shape: (batch_size, seq_length, hidden_dim)\n",
        "\n",
        "        # 拼接特征\n",
        "        combined_output = torch.cat((sequence_output, extra_features), dim=-1)  # [batch_size, seq_len, hidden_dim + eeg_dim]\n",
        "        combined_output = self.dropout(combined_output)\n",
        "\n",
        "        logits = self.classifier(combined_output)  # shape: (batch_size, seq_len, num_labels)\n",
        "\n",
        "        return logits\n",
        "\n",
        "# 根据 EEG 组合标签获取相应的维度索引\n",
        "def get_eeg_dim(combo):\n",
        "    mappings = {\n",
        "        'EEG1': (0, 1),\n",
        "        'EEG2': (1, 2),\n",
        "        'EEG3': (2, 3),\n",
        "        'EEG4': (3, 4),\n",
        "        'EEG5': (4, 5),\n",
        "        'EEG6': (5, 6),\n",
        "        'EEG7': (6, 7),\n",
        "        'EEG8': (7, 8),\n",
        "        'EEG1.2': (0, 2),\n",
        "        'EEG2.3': (1, 3),\n",
        "        'EEG3.4': (2, 4),\n",
        "        'EEG4.5': (3, 5),\n",
        "        'EEG5.6': (4, 6),\n",
        "        'EEG6.7': (5, 7),\n",
        "        'EEG7.8': (6, 8),\n",
        "    }\n",
        "    return mappings[combo]\n",
        "\n",
        "# 训练和评估函数\n",
        "def train_and_evaluate(eeg_combo):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    eeg_start, eeg_end = get_eeg_dim(eeg_combo)\n",
        "    eeg_dim = eeg_end - eeg_start\n",
        "\n",
        "    model = RobertaNerModel(num_labels=6, eeg_dim=eeg_dim)\n",
        "    model = model.to(device)\n",
        "    optim = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=1e-2)\n",
        "    loss_fn = nn.CrossEntropyLoss(reduction='none', ignore_index=0)\n",
        "    loss_fn = loss_fn.to(device)\n",
        "\n",
        "    epochs = 2\n",
        "    best_f1 = 0.0\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        loss_value = 0.0\n",
        "        model.train()\n",
        "        label_true, label_pred = [], []\n",
        "        for i, batch in enumerate(train_dataloader):\n",
        "            optim.zero_grad()\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_masks = batch[1].to(device)\n",
        "            features = batch[3][:, :, eeg_start:eeg_end].to(device)\n",
        "            tags = batch[4].to(device)\n",
        "\n",
        "            with autocast():\n",
        "                pred_tags = model(input_ids, attention_masks, features)\n",
        "\n",
        "                # 展平 pred_tags 和 tags 以匹配形状\n",
        "                pred_tags = pred_tags.reshape(-1, pred_tags.size(-1))\n",
        "                tags = tags.reshape(-1)\n",
        "\n",
        "                loss = loss_fn(pred_tags, tags)\n",
        "                loss = loss.mean()\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optim)\n",
        "            scaler.update()\n",
        "\n",
        "            pred_tags = F.softmax(pred_tags, dim=-1)\n",
        "            pred_tags = torch.argmax(pred_tags, dim=-1)\n",
        "            y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "            label_true.extend(y_true)\n",
        "            label_pred.extend(y_pred)\n",
        "            loss_value += loss.item()\n",
        "\n",
        "        label_train_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "\n",
        "        model.eval()\n",
        "        kw_true, kw_pred = [], []\n",
        "        label_true, label_pred = [], []\n",
        "        for i, batch in enumerate(test_dataloader):\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_masks = batch[1].to(device)\n",
        "            tokens = batch[2]  # tokens 不是 Tensor，直接使用\n",
        "            features = batch[3][:, :, eeg_start:eeg_end].to(device)\n",
        "            tags = batch[4].to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for module in model.modules():\n",
        "                    if isinstance(module, nn.Dropout):\n",
        "                        module.p = 0\n",
        "                        module.train(False)\n",
        "                with autocast():\n",
        "                    pred_tags = model(input_ids, attention_masks, features)\n",
        "                    pred_tags = F.softmax(pred_tags, dim=-1)\n",
        "                    pred_tags = torch.argmax(pred_tags, dim=-1)\n",
        "\n",
        "            y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "            label_true.extend(y_true)\n",
        "            label_pred.extend(y_pred)\n",
        "\n",
        "            poss = []\n",
        "            for i in range(len(tags)):\n",
        "                pos = []\n",
        "                for j in range(len(tags[i])):\n",
        "                    if tags[i][j] == 0:\n",
        "                        pos.append(j)\n",
        "                poss.append(pos)\n",
        "\n",
        "            kw_true.extend(TagConvert(tags, tokens))\n",
        "            kw_pred.extend(TagConvert(pred_tags, tokens, poss))\n",
        "\n",
        "        label_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "        P, R, F1 = evaluate(kw_true, kw_pred)\n",
        "\n",
        "        # if F1 > best_f1:\n",
        "        #     best_f1 = F1\n",
        "        #     torch.save(model.state_dict(), f'/content/drive/MyDrive/ner/pretrain_pt/roberta_HAtten_{eeg_combo}.pt')\n",
        "\n",
        "        print(f\"epoch {epoch + 1}: loss: {loss_value / len(train_dataloader):.2f} train_f1: {label_train_f1:.2f} test_f1: {label_f1:.2f} kw_f1: {F1:.2f}\")\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return P, R, F1\n",
        "\n",
        "# 使用不同的 EEG 组合进行训练和评估\n",
        "eeg_combos = ['EEG1', 'EEG2', 'EEG3', 'EEG4', 'EEG5', 'EEG6', 'EEG7', 'EEG8',\n",
        "              'EEG1.2', 'EEG2.3', 'EEG3.4', 'EEG4.5', 'EEG5.6', 'EEG6.7', 'EEG7.8']\n",
        "\n",
        "for eeg_combo in eeg_combos:\n",
        "    print(f\"Training with EEG combo: {eeg_combo}\")\n",
        "    P, R, F1 = train_and_evaluate(eeg_combo)\n",
        "    print(f\"EEG combo: {eeg_combo} - Precision: {P:.2f}, Recall: {R:.2f}, F1 Score: {F1:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kM08ljw0-w6s",
        "outputId": "d63fa64c-7211-420d-b5c9-408f3b4a4060"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with EEG combo: EEG1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.02 train_f1: 0.61 test_f1: 0.85 kw_f1: 77.67\n",
            "epoch 2: loss: 0.01 train_f1: 0.90 test_f1: 0.88 kw_f1: 81.23\n",
            "EEG combo: EEG1 - Precision: 78.88, Recall: 83.73, F1 Score: 81.23\n",
            "Training with EEG combo: EEG2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.02 train_f1: 0.64 test_f1: 0.86 kw_f1: 77.89\n",
            "epoch 2: loss: 0.01 train_f1: 0.90 test_f1: 0.88 kw_f1: 81.08\n",
            "EEG combo: EEG2 - Precision: 79.43, Recall: 82.80, F1 Score: 81.08\n",
            "Training with EEG combo: EEG3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.02 train_f1: 0.62 test_f1: 0.85 kw_f1: 77.49\n",
            "epoch 2: loss: 0.01 train_f1: 0.90 test_f1: 0.88 kw_f1: 81.11\n",
            "EEG combo: EEG3 - Precision: 79.55, Recall: 82.72, F1 Score: 81.11\n",
            "Training with EEG combo: EEG4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.02 train_f1: 0.63 test_f1: 0.85 kw_f1: 78.10\n",
            "epoch 2: loss: 0.01 train_f1: 0.90 test_f1: 0.87 kw_f1: 80.31\n",
            "EEG combo: EEG4 - Precision: 81.64, Recall: 79.02, F1 Score: 80.31\n",
            "Training with EEG combo: EEG5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.02 train_f1: 0.63 test_f1: 0.84 kw_f1: 76.21\n",
            "epoch 2: loss: 0.01 train_f1: 0.90 test_f1: 0.88 kw_f1: 81.72\n",
            "EEG combo: EEG5 - Precision: 79.81, Recall: 83.72, F1 Score: 81.72\n",
            "Training with EEG combo: EEG6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.02 train_f1: 0.63 test_f1: 0.84 kw_f1: 77.16\n",
            "epoch 2: loss: 0.01 train_f1: 0.90 test_f1: 0.87 kw_f1: 80.58\n",
            "EEG combo: EEG6 - Precision: 79.31, Recall: 81.88, F1 Score: 80.58\n",
            "Training with EEG combo: EEG7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.02 train_f1: 0.63 test_f1: 0.86 kw_f1: 78.77\n",
            "epoch 2: loss: 0.01 train_f1: 0.90 test_f1: 0.88 kw_f1: 81.32\n",
            "EEG combo: EEG7 - Precision: 79.43, Recall: 83.31, F1 Score: 81.32\n",
            "Training with EEG combo: EEG8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.02 train_f1: 0.63 test_f1: 0.86 kw_f1: 78.00\n",
            "epoch 2: loss: 0.01 train_f1: 0.90 test_f1: 0.88 kw_f1: 82.27\n",
            "EEG combo: EEG8 - Precision: 79.70, Recall: 85.02, F1 Score: 82.27\n",
            "Training with EEG combo: EEG1.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.02 train_f1: 0.64 test_f1: 0.85 kw_f1: 77.65\n",
            "epoch 2: loss: 0.01 train_f1: 0.90 test_f1: 0.88 kw_f1: 81.95\n",
            "EEG combo: EEG1.2 - Precision: 78.07, Recall: 86.24, F1 Score: 81.95\n",
            "Training with EEG combo: EEG2.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.02 train_f1: 0.75 test_f1: 0.85 kw_f1: 77.85\n",
            "epoch 2: loss: 0.01 train_f1: 0.90 test_f1: 0.88 kw_f1: 81.57\n",
            "EEG combo: EEG2.3 - Precision: 79.99, Recall: 83.23, F1 Score: 81.57\n",
            "Training with EEG combo: EEG3.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.02 train_f1: 0.64 test_f1: 0.85 kw_f1: 77.89\n",
            "epoch 2: loss: 0.01 train_f1: 0.90 test_f1: 0.88 kw_f1: 81.53\n",
            "EEG combo: EEG3.4 - Precision: 81.31, Recall: 81.75, F1 Score: 81.53\n",
            "Training with EEG combo: EEG4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.02 train_f1: 0.62 test_f1: 0.85 kw_f1: 77.85\n",
            "epoch 2: loss: 0.01 train_f1: 0.90 test_f1: 0.88 kw_f1: 81.75\n",
            "EEG combo: EEG4.5 - Precision: 78.52, Recall: 85.27, F1 Score: 81.75\n",
            "Training with EEG combo: EEG5.6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.02 train_f1: 0.63 test_f1: 0.85 kw_f1: 78.06\n",
            "epoch 2: loss: 0.01 train_f1: 0.90 test_f1: 0.88 kw_f1: 81.45\n",
            "EEG combo: EEG5.6 - Precision: 79.55, Recall: 83.43, F1 Score: 81.45\n",
            "Training with EEG combo: EEG6.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.02 train_f1: 0.62 test_f1: 0.86 kw_f1: 78.19\n",
            "epoch 2: loss: 0.01 train_f1: 0.90 test_f1: 0.87 kw_f1: 81.51\n",
            "EEG combo: EEG6.7 - Precision: 79.62, Recall: 83.48, F1 Score: 81.51\n",
            "Training with EEG combo: EEG7.8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.02 train_f1: 0.63 test_f1: 0.85 kw_f1: 76.90\n",
            "epoch 2: loss: 0.01 train_f1: 0.90 test_f1: 0.88 kw_f1: 80.92\n",
            "EEG combo: EEG7.8 - Precision: 78.61, Recall: 83.36, F1 Score: 80.92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5o66KaByEt5"
      },
      "outputs": [],
      "source": [
        "#########################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGzczALaa3rk",
        "outputId": "bbfb7fbd-6f67-4a3a-8c5a-29e875470e09"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Training Loss: 0.1248\n",
            "Validation Loss: 0.0414, Accuracy: 0.9877\n",
            "Precision: 0.7661, Recall: 0.5404, F1 Score: 0.5758\n",
            "Epoch 2, Training Loss: 0.0372\n",
            "Validation Loss: 0.0294, Accuracy: 0.9902\n",
            "Precision: 0.7596, Recall: 0.7484, F1 Score: 0.7529\n",
            "Epoch 3, Training Loss: 0.0299\n",
            "Validation Loss: 0.0266, Accuracy: 0.9911\n",
            "Precision: 0.7859, Recall: 0.7640, F1 Score: 0.7745\n",
            "Test Loss: 0.0264, Accuracy: 0.9913\n",
            "Precision: 0.7854, Recall: 0.7665, F1 Score: 0.7756\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "from transformers import RobertaModel\n",
        "\n",
        "class RobertaNerModel(nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super(RobertaNerModel, self).__init__()\n",
        "        # 加载预训练的RoBERTa模型\n",
        "        self.bert = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(768 , num_labels)  # 假设你有25个额外特征\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, extra_features, token_type_ids=None):\n",
        "        # 前向传播\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        pooled_output = outputs.last_hidden_state  # 获取RoBERTa的最后一层隐藏状态\n",
        "        #print(\"Pooled output shape:\", pooled_output.shape)\n",
        "\n",
        "        bert_outputs = self.dropout(pooled_output)\n",
        "        # eeg_features = extra_features[:, :,-8:]  # [batch_size, seq_len, 8]\n",
        "\n",
        "        # outputs = torch.concat((bert_outputs, eeg_features), -1)  # 拼接额外特征\n",
        "\n",
        "        outputs = self.classifier(bert_outputs)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader, epochs=3, lr=2e-5):\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    model = model.to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # 将数据加载到GPU\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            extra_features = batch[3].to(device)\n",
        "            labels = batch[4].to(device)\n",
        "\n",
        "            # 输出输入数据的形状\n",
        "\n",
        "\n",
        "            try:\n",
        "                # 模型前向传播\n",
        "                outputs = model(input_ids, attention_mask, extra_features)\n",
        "\n",
        "\n",
        "                # 计算损失\n",
        "                loss = loss_fn(outputs.view(-1, outputs.shape[-1]), labels.view(-1))\n",
        "                total_loss += loss.item()\n",
        "                #print(f\"Loss at step {step+1}: {loss.item()}\")\n",
        "\n",
        "                # 反向传播\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "\n",
        "            except RuntimeError as e:\n",
        "                print(f\"Runtime error at step {step+1}: {str(e)}\")\n",
        "                print(\"Skipping this batch...\")\n",
        "                continue\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "        print(f\"Epoch {epoch + 1}, Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # 验证模型\n",
        "        evaluate(model, val_dataloader)\n",
        "\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    model.eval()\n",
        "    eval_loss = 0\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    correct_preds, total_preds = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            extra_features = batch[3].to(device)\n",
        "            labels = batch[4].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask, extra_features)\n",
        "            loss = loss_fn(outputs.view(-1, outputs.shape[-1]), labels.view(-1))\n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=-1)\n",
        "\n",
        "            all_preds.extend(preds.view(-1).cpu().numpy())\n",
        "            all_labels.extend(labels.view(-1).cpu().numpy())\n",
        "\n",
        "            correct_preds += (preds == labels).sum().item()\n",
        "            total_preds += labels.numel()\n",
        "\n",
        "    avg_eval_loss = eval_loss / len(val_dataloader)\n",
        "    accuracy = correct_preds / total_preds\n",
        "\n",
        "    # 计算 P, R, F1\n",
        "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"Validation Loss: {avg_eval_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# 将数据集划分为训练集和验证集\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=128)\n",
        "val_dataloader = DataLoader(val_dataset, shuffle=True, batch_size=128)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = RobertaNerModel(num_labels=len(label_to_ids))\n",
        "\n",
        "# 开始训练模型\n",
        "train(model, train_dataloader, val_dataloader, epochs=3, lr=2e-5)\n",
        "def test(model, test_dataloader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    correct_preds, total_preds = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            extra_features = batch[3].to(device)\n",
        "            labels = batch[4].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask, extra_features)\n",
        "            loss = loss_fn(outputs.view(-1, outputs.shape[-1]), labels.view(-1))\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=-1)\n",
        "\n",
        "            all_preds.extend(preds.view(-1).cpu().numpy())\n",
        "            all_labels.extend(labels.view(-1).cpu().numpy())\n",
        "\n",
        "            correct_preds += (preds == labels).sum().item()\n",
        "            total_preds += labels.numel()\n",
        "\n",
        "    avg_test_loss = test_loss / len(test_dataloader)\n",
        "    accuracy = correct_preds / total_preds\n",
        "\n",
        "    # 计算 P, R, F1\n",
        "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"Test Loss: {avg_test_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    return avg_test_loss, accuracy, precision, recall, f1\n",
        "# 假设已经定义了 test_dataloader\n",
        "# test_dataloader = ...\n",
        "\n",
        "# 在测试集上评估模型\n",
        "test_loss, test_accuracy, test_precision, test_recall, test_f1 = test(model, test_dataloader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeL9JclP3G8p",
        "outputId": "e7920c4d-cc3c-4448-90f2-adb0e6d8429b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.0264, Accuracy: 0.9913\n",
            "Precision: 0.7854, Recall: 0.7665, F1 Score: 0.7756\n"
          ]
        }
      ],
      "source": [
        "def test(model, test_dataloader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    correct_preds, total_preds = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            extra_features = batch[3].to(device)\n",
        "            labels = batch[4].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask, extra_features)\n",
        "            loss = loss_fn(outputs.view(-1, outputs.shape[-1]), labels.view(-1))\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=-1)\n",
        "\n",
        "            all_preds.extend(preds.view(-1).cpu().numpy())\n",
        "            all_labels.extend(labels.view(-1).cpu().numpy())\n",
        "\n",
        "            correct_preds += (preds == labels).sum().item()\n",
        "            total_preds += labels.numel()\n",
        "\n",
        "    avg_test_loss = test_loss / len(test_dataloader)\n",
        "    accuracy = correct_preds / total_preds\n",
        "\n",
        "    # 计算 P, R, F1\n",
        "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"Test Loss: {avg_test_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    return avg_test_loss, accuracy, precision, recall, f1\n",
        "# 假设已经定义了 test_dataloader\n",
        "# test_dataloader = ...\n",
        "\n",
        "# 在测试集上评估模型\n",
        "test_loss, test_accuracy, test_precision, test_recall, test_f1 = test(model, test_dataloader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdHHM6wc0_BN"
      },
      "source": [
        "################结束"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "88ea6fa2fc59446487090f4fdbb1d61b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9dced3351ebd4627a58079e67a736eb1",
              "IPY_MODEL_51dc9d285d5148cebde1efe209041132",
              "IPY_MODEL_96ac6a6130e24e11a1258886042320a9"
            ],
            "layout": "IPY_MODEL_c0b9ffa5f2ee4810831c1b9fdfab8d63"
          }
        },
        "9dced3351ebd4627a58079e67a736eb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1d55e15a1244e179e0119285cfb501a",
            "placeholder": "​",
            "style": "IPY_MODEL_de8463e50b794ad9a8994b5be60ee935",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "51dc9d285d5148cebde1efe209041132": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8d36725e2b842a190ee22a751fbb924",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e765214895ba4b029c93736b2e58892b",
            "value": 25
          }
        },
        "96ac6a6130e24e11a1258886042320a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8dde3aa8019348a2a6bc540b0e57cad5",
            "placeholder": "​",
            "style": "IPY_MODEL_edfa3e1136f64118a6e76991e40cd58b",
            "value": " 25.0/25.0 [00:00&lt;00:00, 2.00kB/s]"
          }
        },
        "c0b9ffa5f2ee4810831c1b9fdfab8d63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1d55e15a1244e179e0119285cfb501a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de8463e50b794ad9a8994b5be60ee935": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8d36725e2b842a190ee22a751fbb924": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e765214895ba4b029c93736b2e58892b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8dde3aa8019348a2a6bc540b0e57cad5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edfa3e1136f64118a6e76991e40cd58b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "167092269cb840efbe4e95a2000b5703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31211574145a4138ac5d1ae6f89f74ba",
              "IPY_MODEL_eab63c32415d4b8882560321f537675a",
              "IPY_MODEL_f9692b7561f043588a0d2773c2c06c46"
            ],
            "layout": "IPY_MODEL_05120dc176154475887db24de2d833b7"
          }
        },
        "31211574145a4138ac5d1ae6f89f74ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d44aae3f4d74a4a853a92cac240aadd",
            "placeholder": "​",
            "style": "IPY_MODEL_e030d32be4514c9f8f033fd9341a931b",
            "value": "vocab.json: 100%"
          }
        },
        "eab63c32415d4b8882560321f537675a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76922e969dee4cb4bbe2272192700d4b",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6748e2edc43546c9b93ddcc2f4b9e03a",
            "value": 898823
          }
        },
        "f9692b7561f043588a0d2773c2c06c46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8508fd67fa9c4c6d8637ae3436c4ceaa",
            "placeholder": "​",
            "style": "IPY_MODEL_86421260503d4e13b27eb16d905256bf",
            "value": " 899k/899k [00:00&lt;00:00, 1.01MB/s]"
          }
        },
        "05120dc176154475887db24de2d833b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d44aae3f4d74a4a853a92cac240aadd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e030d32be4514c9f8f033fd9341a931b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76922e969dee4cb4bbe2272192700d4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6748e2edc43546c9b93ddcc2f4b9e03a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8508fd67fa9c4c6d8637ae3436c4ceaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86421260503d4e13b27eb16d905256bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5e08b3680b64d8d815112e3e50e89c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ddb8f0f154ff4821a0188e7b1337cd71",
              "IPY_MODEL_f1f8ff1c1100476db331d58f5c0a90cc",
              "IPY_MODEL_04fbc0fe65ad4348babaa94bf1234993"
            ],
            "layout": "IPY_MODEL_61efd7e27f764c8fb6579d66ba37586c"
          }
        },
        "ddb8f0f154ff4821a0188e7b1337cd71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_363a827e8f764cdc84b2aeee90209d10",
            "placeholder": "​",
            "style": "IPY_MODEL_e9849f79dc084d78ac50870f1d4b5dbc",
            "value": "merges.txt: 100%"
          }
        },
        "f1f8ff1c1100476db331d58f5c0a90cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57d0b05ecd4b4e3f895b1367642b25ba",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6a5c470b037f4a3a91c40e51cc4a7b47",
            "value": 456318
          }
        },
        "04fbc0fe65ad4348babaa94bf1234993": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab8f3b41e9d143e59fe64f11bf873892",
            "placeholder": "​",
            "style": "IPY_MODEL_28cee84eb92045799e36f12ed7b817b7",
            "value": " 456k/456k [00:00&lt;00:00, 717kB/s]"
          }
        },
        "61efd7e27f764c8fb6579d66ba37586c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "363a827e8f764cdc84b2aeee90209d10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9849f79dc084d78ac50870f1d4b5dbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57d0b05ecd4b4e3f895b1367642b25ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a5c470b037f4a3a91c40e51cc4a7b47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab8f3b41e9d143e59fe64f11bf873892": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28cee84eb92045799e36f12ed7b817b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0dd9c1414816484b979b2b298be3711d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c79bc7abcde540feb7682ab0cfe658fb",
              "IPY_MODEL_6c99e78fba514e4ea655b197048688da",
              "IPY_MODEL_9d0c8e336b2b40baa5d4c48c3f559e36"
            ],
            "layout": "IPY_MODEL_962e13b3dfe546539f8f13e2c697f354"
          }
        },
        "c79bc7abcde540feb7682ab0cfe658fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ecc3ff8a10f4a4589ece3947785da0e",
            "placeholder": "​",
            "style": "IPY_MODEL_40b0f3a59c6540c3832a6a40bb036a5d",
            "value": "tokenizer.json: 100%"
          }
        },
        "6c99e78fba514e4ea655b197048688da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0e8bdc300fd4066af7996910c9232ea",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9c7a5a8284734a649f03aac8a0fdbddd",
            "value": 1355863
          }
        },
        "9d0c8e336b2b40baa5d4c48c3f559e36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16081b36090f4120b452a9ac959e182f",
            "placeholder": "​",
            "style": "IPY_MODEL_d657b178cb6440889a348af0b99cf260",
            "value": " 1.36M/1.36M [00:01&lt;00:00, 1.28MB/s]"
          }
        },
        "962e13b3dfe546539f8f13e2c697f354": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ecc3ff8a10f4a4589ece3947785da0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40b0f3a59c6540c3832a6a40bb036a5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0e8bdc300fd4066af7996910c9232ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c7a5a8284734a649f03aac8a0fdbddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "16081b36090f4120b452a9ac959e182f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d657b178cb6440889a348af0b99cf260": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7599fab0f50449d08c13062ec37421bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23d908040fa24bed82604e9dd8d3ac1f",
              "IPY_MODEL_3e3dcd7a924240dcbca6c5489dbd93be",
              "IPY_MODEL_1f3971f0d4e740728969930e76c9b180"
            ],
            "layout": "IPY_MODEL_e19f7ab338ab407da4bcd7e2aa05815f"
          }
        },
        "23d908040fa24bed82604e9dd8d3ac1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb3734c2c36b409c9ac59e88c9fcc2cb",
            "placeholder": "​",
            "style": "IPY_MODEL_80546119670a4839af711a34542f6cbd",
            "value": "config.json: 100%"
          }
        },
        "3e3dcd7a924240dcbca6c5489dbd93be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf235ab9d6d8417d889d6797c75f2e6a",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b6648c0469d744c09648b7fa44cb7eb3",
            "value": 481
          }
        },
        "1f3971f0d4e740728969930e76c9b180": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6851f615bd094ec196f83164ff418515",
            "placeholder": "​",
            "style": "IPY_MODEL_d65345ed86494d11a3be0b308907bfca",
            "value": " 481/481 [00:00&lt;00:00, 36.7kB/s]"
          }
        },
        "e19f7ab338ab407da4bcd7e2aa05815f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb3734c2c36b409c9ac59e88c9fcc2cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80546119670a4839af711a34542f6cbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf235ab9d6d8417d889d6797c75f2e6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6648c0469d744c09648b7fa44cb7eb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6851f615bd094ec196f83164ff418515": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d65345ed86494d11a3be0b308907bfca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d34d55ef0ef418d8b8bcecd37aa7764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_650cc13d810a46bc99c2d44b470eea5a",
              "IPY_MODEL_246ec5d639f749519e301ada046371a3",
              "IPY_MODEL_00e7e29874454a0db0354108ca082ce4"
            ],
            "layout": "IPY_MODEL_c27c4b6024e349c290ab6ea96c003854"
          }
        },
        "650cc13d810a46bc99c2d44b470eea5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15426628ecf1485d8887354d723cfd8f",
            "placeholder": "​",
            "style": "IPY_MODEL_46bc624d9494433997e978592ceac1fe",
            "value": "model.safetensors: 100%"
          }
        },
        "246ec5d639f749519e301ada046371a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e89079c7c214b828a9690007691cfff",
            "max": 498818054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_27301c9bdac945db8b3278a50688e220",
            "value": 498818054
          }
        },
        "00e7e29874454a0db0354108ca082ce4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_775aa6aa5d1744c4b320b9c26a810132",
            "placeholder": "​",
            "style": "IPY_MODEL_4c7d30477ba94c03ab41425ca4e1d076",
            "value": " 499M/499M [00:01&lt;00:00, 355MB/s]"
          }
        },
        "c27c4b6024e349c290ab6ea96c003854": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15426628ecf1485d8887354d723cfd8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46bc624d9494433997e978592ceac1fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e89079c7c214b828a9690007691cfff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27301c9bdac945db8b3278a50688e220": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "775aa6aa5d1744c4b320b9c26a810132": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c7d30477ba94c03ab41425ca4e1d076": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}