{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "V9AjhssVCBYZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "只需要执行start training之前代码，然后执行EGG不同组合代码"
      ],
      "metadata": {
        "id": "lPI6mTue__U7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZLsd9WZo_31J"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shWyTmV3CBYa"
      },
      "source": [
        "#### load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "source": [
        "import transformers\n",
        "import torch\n",
        "from transformers import BertModel, BertTokenizerFast"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "hivERBZfCBYb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "source": [
        "weight = 'bert-base-uncased'\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "max_len = 35"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "QsIpNKr6CBYc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "y6b9lmrHCBYd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0UCq98J4CBYd"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "\n",
        "train_path = '/content/drive/MyDrive/ner/datas/General-Twitter/train.json'\n",
        "test_path = '/content/drive/MyDrive/ner/datas/General-Twitter/test.json'\n",
        "train_file = json.load(open(train_path,'r',encoding='utf-8'))\n",
        "test_file = json.load(open(test_path, 'r', encoding='utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7UI6bKGHGu5",
        "outputId": "5ee7374e-0bc3-4dd9-dd74-2a75093a4939"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FQycftaaCBYd"
      },
      "outputs": [],
      "source": [
        "# Append all words, eye-tracking signals, EEG signals and tags from training json to list\n",
        "train_sens, train_tags = [],[]\n",
        "train_Feature = []\n",
        "train_word_nums = []\n",
        "\n",
        "sens = ''\n",
        "nums = 0\n",
        "for key in train_file.keys():\n",
        "    tags = []\n",
        "    features = []\n",
        "    items = train_file[key]\n",
        "    sens = ''\n",
        "    nums = 0\n",
        "    for item in items:\n",
        "        sens += item[0]\n",
        "        sens += ' '\n",
        "        features.append(item[1:-1])               # ET+EEG: [1: -1]\n",
        "        tags.append(item[-1])\n",
        "        nums += 1\n",
        "    train_sens.append(sens.strip())\n",
        "    train_word_nums.append(nums)\n",
        "    train_Feature.append(features)\n",
        "    train_tags.append(tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iVgSI1QgCBYe"
      },
      "outputs": [],
      "source": [
        "# Append all words, eye-tracking signals, EEG signals and tags from testing json to list\n",
        "test_sens, test_tags = [],[]\n",
        "test_Feature = []\n",
        "test_word_nums = []\n",
        "\n",
        "sens = ''\n",
        "nums = 0\n",
        "for key in test_file.keys():\n",
        "    tags = []\n",
        "    features = []\n",
        "    items = test_file[key]\n",
        "    sens = ''\n",
        "    nums = 0\n",
        "    for item in items:\n",
        "        sens += item[0]\n",
        "        sens += ' '\n",
        "        features.append(item[1:-1])                # ET+EEG: [1: -1]\n",
        "        tags.append(item[-1])\n",
        "        nums += 1\n",
        "    test_sens.append(sens.strip())\n",
        "    test_word_nums.append(nums)\n",
        "    test_Feature.append(features)\n",
        "    test_tags.append(tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2vjI4VsCBYe",
        "outputId": "3216d34d-41a7-48d6-d2e5-038b9851145f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33755"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "len(test_sens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxFYjwlZCBYf"
      },
      "source": [
        "#### build dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gOlrGF4oCBYf"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274,
          "referenced_widgets": [
            "945b98f99ede48ecb3aca429df5da57e",
            "360758de4b93457ebbf180823e870062",
            "4027763e947c4b34b94c03a2e6f2206a",
            "c3dccc6931494ee098cb94f9a506ef67",
            "96776ed4b3664a5199f05deca2e5cd41",
            "90adcf69ca68454bbae6264746f2fe3f",
            "af25c31158524dc5b9879e8e4036dc26",
            "b4e6e03a78354ef0b5ab792083c94520",
            "6ecbe78157a44ecd97ad51a4784af224",
            "dc47f2a155c84369914dde7e7d4edf08",
            "540cd3e641ae4870b703dc88b7b92a27",
            "c15521aec7d64dbcb80f33082bb1a5dd",
            "b1ba10ec06d2405aa3dab05f610e4c52",
            "039a5fd5f9304ca3a326513ca3883546",
            "18031af146b74f538bd65fb8f7d7ed9a",
            "248859323fa34af89ddbfad52dc70be2",
            "42b737d16c954242bdc770b6121e6d4a",
            "f3c41eeca33c472db5a476ca5d558802",
            "19c28ea5e428451bbf526787ddea8f71",
            "23a44a7e5f4c4467b37b12745a973407",
            "b3dac01bfe2d4aa48f2fb92dacbe3bfc",
            "1b3d7ea36c394184aca348775a6864d5",
            "81d7805874804829825d50a7110d94a7",
            "9b689e41d39747339b9ea8bc3b407d25",
            "28f899e1c7ed48dab5a586d3dcec3b24",
            "c7be6a223e9a45248db8fa1449f1b3a1",
            "25b238cae5634089aa41334d480d3076",
            "58302cb84195455f9dfc76619121256c",
            "5355e1ba66034d0d9cd65e055ed43f17",
            "0255df3e4aa44369ad3ddc1d70517cc8",
            "fce4c0fca41e4aeaa21a259c781ff8b5",
            "5113aa0374fc48bab5caf8153ecb1b64",
            "ca61bf2e1a854163b40ce33009729d62",
            "a7e981cad9be42b89dd6666a34dc4a66",
            "ebdda8bf02174e38b974abed47926294",
            "5cf99467cd6e4467922e44ccc68445bc",
            "48e3ad9de87c4877bd2d4d78abf4d9a3",
            "74789379eeef407fa217fb7f28575ab1",
            "7ed3345c3749498b96303007e234698d",
            "fdc0623c4b3946ea90ff797c9326c838",
            "01893e988b754e12a84238b5807379b1",
            "3378d101e6ca43889ef2eb928b30cf4e",
            "58f0d6e3b01b4e95a9935e7fc738bd27",
            "b614196c78b741749c2bc32a50418a90"
          ]
        },
        "id": "ASM6-HnQCBYf",
        "outputId": "54280fe0-633e-4ed0-ecfc-4d76acd4bf0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "945b98f99ede48ecb3aca429df5da57e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c15521aec7d64dbcb80f33082bb1a5dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "81d7805874804829825d50a7110d94a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a7e981cad9be42b89dd6666a34dc4a66"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained(weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "u5pb60D5CBYg"
      },
      "outputs": [],
      "source": [
        "label_to_ids = {'none': 0, 'B': 1, 'I': 2, 'E': 3, 'S': 4, \"O\": 5}\n",
        "# label_to_ids = {'O': 0, 'B': 1, 'I': 2, 'E': 3, 'S': 4}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ToV8eWk7CBYg"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, texts, old_features, tags):\n",
        "        self.texts = texts\n",
        "        self.tags = tags\n",
        "        self.old_features = old_features\n",
        "\n",
        "        self.labels = []\n",
        "        self.tokens = []\n",
        "        self.features = []\n",
        "\n",
        "        self.input_ids = None\n",
        "        self.attention_masks = None\n",
        "\n",
        "    def encode(self):\n",
        "        for i in tqdm(range(len(self.texts))):\n",
        "          text = self.texts[i]\n",
        "          tag = self.tags[i]\n",
        "          feature = self.old_features[i]\n",
        "          tags, tokens, features = align_label(text, tag, feature)\n",
        "          self.labels.append(tags)\n",
        "          self.tokens.append(tokens)\n",
        "          self.features.append(features)\n",
        "\n",
        "        self.features = np.array(self.features,float)\n",
        "        self.inputs = tokenizer(self.texts, max_length=max_len, add_special_tokens=True, padding='max_length', truncation=True, return_tensors='pt')\n",
        "        self.input_ids = self.inputs['input_ids']\n",
        "        self.attention_masks = self.inputs['attention_mask']\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx,:], self.attention_masks[idx,:], self.tokens[idx], torch.tensor(self.features[idx],dtype=torch.float32), torch.tensor(self.labels[idx])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [],
      "source": [
        "label_all_tokens = True\n",
        "\n",
        "\n",
        "\n",
        "def align_label(text, labels, features):\n",
        "    input = tokenizer(text, max_length=max_len, add_special_tokens=True, padding='max_length', truncation=True, return_tensors='pt')\n",
        "    word_ids = input.word_ids()\n",
        "    input_ids = input['input_ids']\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "\n",
        "    previous_word_idx = None\n",
        "    new_labels, new_features = [], []\n",
        "    no_features = [0 for _ in range(1, 26)]\n",
        "\n",
        "    for word_idx in word_ids:\n",
        "        if word_idx is None:\n",
        "            new_labels.append('none')\n",
        "            new_features.append(no_features)\n",
        "        elif word_idx != previous_word_idx:\n",
        "            try:\n",
        "                new_labels.append(labels[word_idx])\n",
        "                new_features.append(features[word_idx])\n",
        "            except:\n",
        "                new_labels.append('none')\n",
        "                new_features.append(no_features)\n",
        "        else:\n",
        "            try:\n",
        "                new_labels.append(labels[word_idx] if label_all_tokens else 'none')\n",
        "                new_features.append(features[word_idx] if label_all_tokens else no_features)\n",
        "            except:\n",
        "                new_labels.append('none')\n",
        "                new_features.append(no_features)\n",
        "        previous_word_idx = word_idx\n",
        "\n",
        "    label_ids = [label_to_ids[label] for label in new_labels]\n",
        "    return label_ids, tokens, new_features\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "OJ_HkiBwCBYg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "om6L7dR3CBYg",
        "outputId": "5373d1df-0b27-43c1-be85-0e9cf8ce2d69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 78760/78760 [00:39<00:00, 1984.59it/s]\n"
          ]
        }
      ],
      "source": [
        "train_dataset = MyDataset(train_sens, train_Feature, train_tags)\n",
        "train_dataset.encode()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UE2ad7PCBYh",
        "outputId": "d8cdc2a2-1473-497e-aedf-2a80795622bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33755/33755 [00:28<00:00, 1180.90it/s]\n"
          ]
        }
      ],
      "source": [
        "test_dataset = MyDataset(test_sens, test_Feature, test_tags)\n",
        "test_dataset.encode()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ItkC1bL-CBYh"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=128)\n",
        "test_dataloader = DataLoader(test_dataset, shuffle=True, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsP4K3m5CBYh"
      },
      "source": [
        "#### construct bert  model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mG5BkpegCBYh"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class BertNerModel(nn.Module):\n",
        "    def __init__(self,num_labels):\n",
        "        super(BertNerModel,self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained(weight)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(768+8,num_labels)\n",
        "\n",
        "    def forward(self,input_ids,attention_mask,extra_features,token_type_ids=None):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "\n",
        "        pooled_output = outputs[0]\n",
        "        bert_outputs = self.dropout(pooled_output)\n",
        "        EGG = extra_features[:, :, -8:]\n",
        "        outputs = torch.concat((bert_outputs,EGG),-1)\n",
        "        # print(bert_outputs.shape)\n",
        "        # print(EGG.shape)\n",
        "        # print(outputs.shape)\n",
        "\n",
        "        # outputs = bert_outputs\n",
        "        outputs = self.classifier(outputs)\n",
        "\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LLSoMmaCBYh"
      },
      "source": [
        "#### evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "D_Kda87kCBYh"
      },
      "outputs": [],
      "source": [
        "def TagConvert(raw_tags, words_set, poss=None):\n",
        "    true_tags = []\n",
        "    for i in range(raw_tags.shape[0]):\n",
        "      kw_list = []\n",
        "      nkw_list = \"\"\n",
        "      for j in range(len(raw_tags[i])):\n",
        "          item = raw_tags[i][j]\n",
        "          if item == 0:\n",
        "              continue\n",
        "          if poss !=None and j in poss[i]:\n",
        "              continue\n",
        "          # if item == 5:\n",
        "          #     continue\n",
        "          if item == 4:\n",
        "              kw_list.append(str(words_set[j][i]))\n",
        "          if item == 1:\n",
        "              nkw_list += str(words_set[j][i])\n",
        "          if item == 2:\n",
        "              nkw_list += \" \"\n",
        "              nkw_list += str(words_set[j][i])\n",
        "          if item == 3:\n",
        "              nkw_list += \" \"\n",
        "              nkw_list += str(words_set[j][i])\n",
        "              kw_list.append(nkw_list)\n",
        "              nkw_list = \"\"\n",
        "\n",
        "      true_tags.append(kw_list)\n",
        "    return true_tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "smz-IIy6CBYi"
      },
      "outputs": [],
      "source": [
        "def evaluate(predict_data, target_data, topk=3):\n",
        "  TRUE_COUNT, PRED_COUNT, GOLD_COUNT = 0.0, 0.0, 0.0\n",
        "  for index, words in enumerate(predict_data):\n",
        "      y_pred, y_true = None, target_data[index]\n",
        "\n",
        "      if type(predict_data) == str:\n",
        "          words = sorted(words.items(), key=lambda item: (-item[1], item[0]))\n",
        "          y_pred = [i[0] for i in words]\n",
        "      elif type(predict_data) == list:\n",
        "          y_pred = words\n",
        "\n",
        "      y_pred = y_pred[0: topk]\n",
        "      TRUE_NUM = len(set(y_pred) & set(y_true))\n",
        "      TRUE_COUNT += TRUE_NUM\n",
        "      PRED_COUNT += len(y_pred)\n",
        "      GOLD_COUNT += len(y_true)\n",
        "  # compute P\n",
        "  if PRED_COUNT != 0:\n",
        "      p = (TRUE_COUNT / PRED_COUNT)\n",
        "  else:\n",
        "      p = 0\n",
        "  # compute R\n",
        "  if GOLD_COUNT != 0:\n",
        "      r = (TRUE_COUNT / GOLD_COUNT)\n",
        "  else:\n",
        "      r = 0\n",
        "  # compute F1\n",
        "  if (r + p) != 0:\n",
        "      f1 = ((2 * r * p) / (r + p))\n",
        "  else:\n",
        "      f1 = 0\n",
        "\n",
        "  p = round(p * 100, 2)\n",
        "  r = round(r * 100, 2)\n",
        "  f1 = round(f1 * 100, 2)\n",
        "\n",
        "  return p, r, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "EF70Ap6rCBYi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_f1(y_pred, y_true):\n",
        "    # flatten and convert to numpy array\n",
        "    y_true = y_true.view(-1)\n",
        "    y_pred = y_pred.view(-1)\n",
        "    y_true = y_true.detach().cpu().numpy()\n",
        "    y_pred = y_pred.detach().cpu().numpy()\n",
        "\n",
        "    mask = np.where(y_true != 0)\n",
        "\n",
        "    y_true = y_true[mask]\n",
        "    y_pred = y_pred[mask]\n",
        "\n",
        "    return y_pred, y_true"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xKZt3yaCBYi"
      },
      "source": [
        "#### start training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9urmITuCBYi",
        "outputId": "3578e7c3-5bb6-4184-fb53-f27d08e025cc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
          ]
        }
      ],
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam, AdamW\n",
        "\n",
        "model = BertNerModel(num_labels=6)\n",
        "model = model.to(device)\n",
        "\n",
        "optim = AdamW(model.parameters(),lr=5e-5,weight_decay=1e-2)\n",
        "loss_fn = CrossEntropyLoss(reduction='none', ignore_index=0)\n",
        "loss_fn = loss_fn.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4g9i8u4CBYi",
        "outputId": "9c7f78ab-261f-478b-b4f9-3434f10163cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sDT-k0ACBYj",
        "outputId": "ff88d336-903a-4045-e5ad-cedb44d81f13"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 1/5 [38:06<2:32:27, 2286.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch1:  loss:0.20   train_f1_value:0.26  test_f1_value:0.53  kw_f1_value:59.86\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 2/5 [1:16:06<1:54:14, 2284.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch2:  loss:0.10   train_f1_value:0.63  test_f1_value:0.67  kw_f1_value:68.35\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 3/5 [1:53:44<1:15:53, 2276.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch3:  loss:0.05   train_f1_value:0.81  test_f1_value:0.69  kw_f1_value:71.90\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 4/5 [2:31:34<37:54, 2274.67s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch4:  loss:0.03   train_f1_value:0.89  test_f1_value:0.69  kw_f1_value:71.31\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [3:09:32<00:00, 2274.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch5:  loss:0.02   train_f1_value:0.93  test_f1_value:0.70  kw_f1_value:71.54\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "epochs = 5\n",
        "best_f1 = 0.0\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    loss_value = 0.0\n",
        "    model.train()\n",
        "    label_true, label_pred = [], []\n",
        "    for i,batch in enumerate(train_dataloader):\n",
        "        optim.zero_grad()\n",
        "        input_ids, attention_masks, _, features, tags = batch\n",
        "        pred_tags = model(input_ids.to(device), attention_masks.to(device), features.to(device))\n",
        "\n",
        "        loss = loss_fn(pred_tags.permute(0,2,1),tags.to(device))\n",
        "        loss = loss.mean()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "        pred_tags = F.softmax(pred_tags,dim=-1)\n",
        "        pred_tags = torch.argmax(pred_tags,dim=-1)\n",
        "\n",
        "        y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "        label_true.extend(y_true)\n",
        "        label_pred.extend(y_pred)\n",
        "\n",
        "        loss_value += loss.item()\n",
        "\n",
        "    label_train_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "\n",
        "    model.eval()\n",
        "    kw_true, kw_pred = [], []\n",
        "    label_true, label_pred = [],[]\n",
        "    for i,batch in enumerate(test_dataloader):\n",
        "      input_ids, attention_masks, tokens, features, tags = batch\n",
        "      with torch.no_grad():\n",
        "          for module in model.modules():\n",
        "              if isinstance(module, nn.Dropout):\n",
        "                  module.p = 0\n",
        "                  module.train(False)\n",
        "          pred_tags = model(input_ids.to(device), attention_masks.to(device), features.to(device))\n",
        "          pred_tags = F.softmax(pred_tags,dim=-1)\n",
        "          pred_tags = torch.argmax(pred_tags,dim=-1)\n",
        "\n",
        "      y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "      label_true.extend(y_true)\n",
        "      label_pred.extend(y_pred)\n",
        "\n",
        "      # more balance evaluate\n",
        "      poss = []\n",
        "      for i in range(len(tags)):\n",
        "          pos = []\n",
        "          for j in range(len(tags[i])):\n",
        "              if tags[i][j] == 0:\n",
        "                  pos.append(j)\n",
        "          poss.append(pos)\n",
        "\n",
        "      kw_true.extend(TagConvert(tags,tokens))\n",
        "      kw_pred.extend(TagConvert(pred_tags,tokens,poss))\n",
        "\n",
        "    label_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "    P, R, F1 = evaluate(kw_true, kw_pred)\n",
        "\n",
        "    if F1 > best_f1:\n",
        "        best_f1 = F1\n",
        "        torch.save(model.state_dict(),'./pretrain_pt/bert_EGG.pt')\n",
        "\n",
        "    print(\"epoch{}:  loss:{:.2f}   train_f1_value:{:.2f}  test_f1_value:{:.2f}  kw_f1_value:{:.2f}\".format(\n",
        "        epoch+1, loss_value / len(train_dataloader), label_train_f1, label_f1, F1\n",
        "    ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5KaklTDtCBYj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTmD13NfCBYj"
      },
      "source": [
        "#### inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z58fwV8aCBYj",
        "outputId": "6c6a01e1-baaa-48f9-e999-f8ed865a0594"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
          ]
        }
      ],
      "source": [
        "model = BertNerModel(num_labels=6)\n",
        "model.load_state_dict(torch.load('./pretrain_pt/bert_EGG.pt'))\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "_-rXkDbMCBYj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWagwga3CBYk"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "model.eval()\n",
        "kw_true, kw_pred = [], []\n",
        "label_true, label_pred = [],[]\n",
        "for i,batch in enumerate(test_dataloader):\n",
        "    input_ids, attention_masks, tokens, extra_features, tags = batch\n",
        "    with torch.no_grad():\n",
        "        for module in model.modules():\n",
        "            if isinstance(module, nn.Dropout):\n",
        "                module.p = 0\n",
        "                module.train(False)\n",
        "        #pred_tags = model(input_ids.to(device), attention_masks.to(device))\n",
        "        pred_tags = model(input_ids.to(device), attention_masks.to(device), extra_features.to(device))\n",
        "        pred_tags = F.softmax(pred_tags,dim=-1)\n",
        "        pred_tags = torch.argmax(pred_tags,dim=-1)\n",
        "\n",
        "    y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "    label_true.extend(y_true)\n",
        "    label_pred.extend(y_pred)\n",
        "\n",
        "    # more balance evaluate\n",
        "    poss = []\n",
        "    for i in range(len(tags)):\n",
        "        pos = []\n",
        "        for j in range(len(tags[i])):\n",
        "            if tags[i][j] == 0:\n",
        "                pos.append(j)\n",
        "        poss.append(pos)\n",
        "\n",
        "    kw_true.extend(TagConvert(tags,tokens))\n",
        "    kw_pred.extend(TagConvert(pred_tags,tokens,poss))\n",
        "\n",
        "label_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "P, R, F1 = evaluate(kw_true, kw_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHErJVLWCBYk",
        "outputId": "a32f31fa-861f-4175-d477-d5fd9119c62c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "70.43\n",
            "73.43\n",
            "71.9\n"
          ]
        }
      ],
      "source": [
        "print(P)\n",
        "print(R)\n",
        "print(F1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################BERT+EEG组合"
      ],
      "metadata": {
        "id": "U6iXeeUcEVc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import f1_score\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "# 定义模型类\n",
        "class BertNerModel(nn.Module):\n",
        "    def __init__(self, num_labels, eeg_combo_dim):\n",
        "        super(BertNerModel, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(weight)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(768 + eeg_combo_dim, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, extra_features, eeg_combo):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        bert_outputs = self.dropout(outputs[0])\n",
        "\n",
        "        # 动态选择 EEG 特征\n",
        "        if eeg_combo == 'EEG1':\n",
        "            eeg_features = extra_features[:, :, -8:-7]\n",
        "        elif eeg_combo == 'EEG2':\n",
        "            eeg_features = extra_features[:, :, -7:-6]\n",
        "        elif eeg_combo == 'EEG3':\n",
        "            eeg_features = extra_features[:, :, -6:-5]\n",
        "        elif eeg_combo == 'EEG4':\n",
        "            eeg_features = extra_features[:, :, -5:-4]\n",
        "        elif eeg_combo == 'EEG5':\n",
        "            eeg_features = extra_features[:, :, -4:-3]\n",
        "        elif eeg_combo == 'EEG6':\n",
        "            eeg_features = extra_features[:, :, -3:-2]\n",
        "        elif eeg_combo == 'EEG7':\n",
        "            eeg_features = extra_features[:, :, -2:-1]\n",
        "        elif eeg_combo == 'EEG8':\n",
        "            eeg_features = extra_features[:, :, -1:]\n",
        "        elif eeg_combo == 'EEG1.2':\n",
        "            eeg_features = extra_features[:, :, -8:-6]\n",
        "        elif eeg_combo == 'EEG2.3':\n",
        "            eeg_features = extra_features[:, :, -7:-5]\n",
        "        elif eeg_combo == 'EEG3.4':\n",
        "            eeg_features = extra_features[:, :, -6:-4]\n",
        "        elif eeg_combo == 'EEG4.5':\n",
        "            eeg_features = extra_features[:, :, -5:-3]\n",
        "        elif eeg_combo == 'EEG5.6':\n",
        "            eeg_features = extra_features[:, :, -4:-2]\n",
        "        elif eeg_combo == 'EEG6.7':\n",
        "            eeg_features = extra_features[:, :, -3:-1]\n",
        "        elif eeg_combo == 'EEG7.8':\n",
        "            eeg_features = extra_features[:, :, -2:]\n",
        "\n",
        "        outputs = torch.concat((bert_outputs, eeg_features), -1)\n",
        "        outputs = self.classifier(outputs)\n",
        "        return outputs\n",
        "\n",
        "# 训练和评估函数\n",
        "def train_and_evaluate(train_dataloader, test_dataloader, eeg_combo, num_labels=6, epochs=5, lr=5e-5):\n",
        "    eeg_combo_dim = len(eeg_combo.split('.'))  # EEG 组合维度\n",
        "\n",
        "    model = BertNerModel(num_labels=num_labels, eeg_combo_dim=eeg_combo_dim)\n",
        "    model = model.to(device)\n",
        "\n",
        "    optim = AdamW(model.parameters(), lr=lr, weight_decay=1e-2)\n",
        "    loss_fn = CrossEntropyLoss(reduction='none', ignore_index=0).to(device)\n",
        "\n",
        "    best_f1 = 0.0\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        loss_value = 0.0\n",
        "        model.train()\n",
        "        label_true, label_pred = [], []\n",
        "        for i, batch in enumerate(train_dataloader):\n",
        "            optim.zero_grad()\n",
        "            input_ids, attention_masks, _, features, tags = batch\n",
        "            pred_tags = model(input_ids.to(device), attention_masks.to(device), features.to(device), eeg_combo)\n",
        "\n",
        "            loss = loss_fn(pred_tags.permute(0, 2, 1), tags.to(device))\n",
        "            loss = loss.mean()\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "\n",
        "            pred_tags = F.softmax(pred_tags, dim=-1)\n",
        "            pred_tags = torch.argmax(pred_tags, dim=-1)\n",
        "\n",
        "            y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "            label_true.extend(y_true)\n",
        "            label_pred.extend(y_pred)\n",
        "\n",
        "            loss_value += loss.item()\n",
        "\n",
        "        label_train_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "\n",
        "        # Evaluation loop\n",
        "        model.eval()\n",
        "        kw_true, kw_pred = [], []\n",
        "        label_true, label_pred = [], []\n",
        "        for i, batch in enumerate(test_dataloader):\n",
        "            input_ids, attention_masks, tokens, features, tags = batch\n",
        "            with torch.no_grad():\n",
        "                for module in model.modules():\n",
        "                    if isinstance(module, nn.Dropout):\n",
        "                        module.p = 0\n",
        "                        module.train(False)\n",
        "                pred_tags = model(input_ids.to(device), attention_masks.to(device), features.to(device), eeg_combo)\n",
        "                pred_tags = F.softmax(pred_tags, dim=-1)\n",
        "                pred_tags = torch.argmax(pred_tags, dim=-1)\n",
        "\n",
        "            y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "            label_true.extend(y_true)\n",
        "            label_pred.extend(y_pred)\n",
        "\n",
        "            poss = []\n",
        "            for i in range(len(tags)):\n",
        "                pos = []\n",
        "                for j in range(len(tags[i])):\n",
        "                    if tags[i][j] == 0:\n",
        "                        pos.append(j)\n",
        "                poss.append(pos)\n",
        "\n",
        "            kw_true.extend(TagConvert(tags, tokens))\n",
        "            kw_pred.extend(TagConvert(pred_tags, tokens, poss))\n",
        "\n",
        "        label_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "        P, R, F1 = evaluate(kw_true, kw_pred)\n",
        "\n",
        "        # Save the best model for the given EEG combination\n",
        "        if F1 > best_f1:\n",
        "            best_f1 = F1\n",
        "            torch.save(model.state_dict(), f'/content/drive/MyDrive/ner/pretrain_pt/bert_{eeg_combo}.pt')\n",
        "\n",
        "        print(f\"epoch {epoch+1}: loss: {loss_value / len(train_dataloader):.2f} train_f1: {label_train_f1:.2f} test_f1: {label_f1:.2f} kw_f1: {F1:.2f}\")\n",
        "\n",
        "    return P, R, F1\n",
        "\n",
        "# 使用不同的 EEG 组合进行训练和评估\n",
        "eeg_combos = ['EEG1', 'EEG2', 'EEG3', 'EEG4', 'EEG5', 'EEG6', 'EEG7', 'EEG8',\n",
        "              'EEG1.2', 'EEG2.3', 'EEG3.4', 'EEG4.5', 'EEG5.6', 'EEG6.7', 'EEG7.8']\n",
        "\n",
        "for eeg_combo in eeg_combos:\n",
        "    print(f\"Training with EEG combo: {eeg_combo}\")\n",
        "    P, R, F1 = train_and_evaluate(train_dataloader, test_dataloader, eeg_combo)\n",
        "    print(f\"EEG combo: {eeg_combo} - Precision: {P:.2f}, Recall: {R:.2f}, F1 Score: {F1:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b8af14f01e5d4f3b96a05167f86233a7",
            "f6f38b1988e74412a05211bd9523a6fe",
            "a623560865bb47339268de61b861e43b",
            "873295fa124d47389dfc2e387f7aa10a",
            "e43f232aac20451a87e9ae63e7b3b0da",
            "6b193bbb04104bb0b1ac907111c089a3",
            "caa438e1404b4b9f88f3c80fd5e1ced8",
            "0490cf0dd3674d1e9574411c761a3652",
            "5b5741ab66034422a1f231b193c39dd3",
            "24708855f74c4e9f9b8196338c2507aa",
            "740636a0c06e49d2945e036c08c0c7f1"
          ]
        },
        "id": "sF0LUIpeETHz",
        "outputId": "1ed7e1fa-d37f-441d-84b8-21f44d54f560"
      },
      "execution_count": 21,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with EEG combo: EEG1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b8af14f01e5d4f3b96a05167f86233a7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 1/5 [06:25<25:40, 385.22s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1: loss: 0.11 train_f1: 0.64 test_f1: 0.86 kw_f1: 77.60\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 2/5 [12:35<18:49, 376.60s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2: loss: 0.04 train_f1: 0.91 test_f1: 0.89 kw_f1: 80.84\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 3/5 [18:37<12:19, 369.82s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3: loss: 0.02 train_f1: 0.96 test_f1: 0.89 kw_f1: 80.77\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 4/5 [24:39<06:06, 366.87s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4: loss: 0.01 train_f1: 0.97 test_f1: 0.90 kw_f1: 81.87\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [30:45<00:00, 369.08s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5: loss: 0.01 train_f1: 0.98 test_f1: 0.89 kw_f1: 81.77\n",
            "EEG combo: EEG1 - Precision: 82.64, Recall: 80.93, F1 Score: 81.77\n",
            "Training with EEG combo: EEG2\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " 20%|██        | 1/5 [06:25<25:41, 385.28s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1: loss: 0.11 train_f1: 0.65 test_f1: 0.87 kw_f1: 78.38\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 2/5 [12:27<18:35, 371.98s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2: loss: 0.04 train_f1: 0.91 test_f1: 0.89 kw_f1: 81.08\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 3/5 [18:29<12:14, 367.39s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3: loss: 0.02 train_f1: 0.96 test_f1: 0.89 kw_f1: 81.70\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 4/5 [24:30<06:04, 364.80s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4: loss: 0.01 train_f1: 0.97 test_f1: 0.89 kw_f1: 81.33\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [30:33<00:00, 366.64s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5: loss: 0.01 train_f1: 0.98 test_f1: 0.90 kw_f1: 82.17\n",
            "EEG combo: EEG2 - Precision: 82.89, Recall: 81.45, F1 Score: 82.17\n",
            "Training with EEG combo: EEG3\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " 20%|██        | 1/5 [06:21<25:26, 381.53s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1: loss: 0.11 train_f1: 0.65 test_f1: 0.87 kw_f1: 78.07\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 2/5 [12:24<18:32, 370.76s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2: loss: 0.04 train_f1: 0.91 test_f1: 0.89 kw_f1: 80.42\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 3/5 [18:26<12:13, 366.85s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3: loss: 0.02 train_f1: 0.96 test_f1: 0.89 kw_f1: 81.52\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 4/5 [24:32<06:06, 366.14s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4: loss: 0.01 train_f1: 0.97 test_f1: 0.90 kw_f1: 82.01\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [30:33<00:00, 366.64s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5: loss: 0.01 train_f1: 0.98 test_f1: 0.90 kw_f1: 82.25\n",
            "EEG combo: EEG3 - Precision: 82.69, Recall: 81.82, F1 Score: 82.25\n",
            "Training with EEG combo: EEG4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " 20%|██        | 1/5 [06:02<24:09, 362.34s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1: loss: 0.11 train_f1: 0.64 test_f1: 0.87 kw_f1: 77.39\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 2/5 [12:03<18:05, 361.72s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2: loss: 0.04 train_f1: 0.91 test_f1: 0.89 kw_f1: 80.69\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 3/5 [18:08<12:05, 362.99s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3: loss: 0.02 train_f1: 0.96 test_f1: 0.89 kw_f1: 81.59\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 4/5 [24:14<06:04, 364.47s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4: loss: 0.01 train_f1: 0.97 test_f1: 0.89 kw_f1: 81.62\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [30:22<00:00, 364.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5: loss: 0.01 train_f1: 0.98 test_f1: 0.89 kw_f1: 81.45\n",
            "EEG combo: EEG4 - Precision: 82.25, Recall: 80.66, F1 Score: 81.45\n",
            "Training with EEG combo: EEG5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 20%|██        | 1/5 [06:10<24:40, 370.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.11 train_f1: 0.64 test_f1: 0.87 kw_f1: 78.06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [12:23<18:35, 371.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2: loss: 0.04 train_f1: 0.91 test_f1: 0.89 kw_f1: 80.94\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [18:35<12:24, 372.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3: loss: 0.02 train_f1: 0.96 test_f1: 0.89 kw_f1: 81.19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [24:42<06:10, 370.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4: loss: 0.01 train_f1: 0.97 test_f1: 0.90 kw_f1: 81.65\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [30:47<00:00, 369.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5: loss: 0.01 train_f1: 0.98 test_f1: 0.89 kw_f1: 81.59\n",
            "EEG combo: EEG5 - Precision: 82.96, Recall: 80.26, F1 Score: 81.59\n",
            "Training with EEG combo: EEG6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 20%|██        | 1/5 [06:08<24:35, 368.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.11 train_f1: 0.64 test_f1: 0.87 kw_f1: 78.07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [12:20<18:32, 370.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2: loss: 0.04 train_f1: 0.91 test_f1: 0.89 kw_f1: 81.06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [18:30<12:20, 370.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3: loss: 0.02 train_f1: 0.95 test_f1: 0.89 kw_f1: 81.60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [24:43<06:11, 371.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4: loss: 0.01 train_f1: 0.97 test_f1: 0.90 kw_f1: 81.89\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [30:54<00:00, 370.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5: loss: 0.01 train_f1: 0.98 test_f1: 0.89 kw_f1: 81.65\n",
            "EEG combo: EEG6 - Precision: 82.70, Recall: 80.63, F1 Score: 81.65\n",
            "Training with EEG combo: EEG7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 20%|██        | 1/5 [06:07<24:30, 367.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.11 train_f1: 0.64 test_f1: 0.87 kw_f1: 78.46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [12:15<18:23, 367.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2: loss: 0.04 train_f1: 0.91 test_f1: 0.89 kw_f1: 81.12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [18:22<12:14, 367.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3: loss: 0.02 train_f1: 0.96 test_f1: 0.90 kw_f1: 82.10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [24:32<06:08, 368.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4: loss: 0.01 train_f1: 0.97 test_f1: 0.90 kw_f1: 82.24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [30:46<00:00, 369.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5: loss: 0.01 train_f1: 0.98 test_f1: 0.90 kw_f1: 81.98\n",
            "EEG combo: EEG7 - Precision: 82.52, Recall: 81.44, F1 Score: 81.98\n",
            "Training with EEG combo: EEG8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 20%|██        | 1/5 [06:13<24:53, 373.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.11 train_f1: 0.64 test_f1: 0.87 kw_f1: 77.91\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [12:29<18:45, 375.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2: loss: 0.04 train_f1: 0.91 test_f1: 0.89 kw_f1: 81.20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [18:34<12:21, 370.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3: loss: 0.02 train_f1: 0.96 test_f1: 0.90 kw_f1: 81.81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [24:39<06:08, 368.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4: loss: 0.01 train_f1: 0.98 test_f1: 0.90 kw_f1: 81.80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [30:46<00:00, 369.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5: loss: 0.01 train_f1: 0.98 test_f1: 0.89 kw_f1: 82.17\n",
            "EEG combo: EEG8 - Precision: 82.03, Recall: 82.32, F1 Score: 82.17\n",
            "Training with EEG combo: EEG1.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 20%|██        | 1/5 [06:25<25:40, 385.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.11 train_f1: 0.65 test_f1: 0.86 kw_f1: 77.47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [12:27<18:35, 371.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2: loss: 0.04 train_f1: 0.91 test_f1: 0.89 kw_f1: 81.37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [18:29<12:14, 367.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3: loss: 0.02 train_f1: 0.96 test_f1: 0.89 kw_f1: 81.52\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [24:31<06:05, 365.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4: loss: 0.01 train_f1: 0.97 test_f1: 0.89 kw_f1: 81.55\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [30:33<00:00, 366.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5: loss: 0.01 train_f1: 0.98 test_f1: 0.89 kw_f1: 81.58\n",
            "EEG combo: EEG1.2 - Precision: 82.53, Recall: 80.65, F1 Score: 81.58\n",
            "Training with EEG combo: EEG2.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 20%|██        | 1/5 [06:03<24:13, 363.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.12 train_f1: 0.63 test_f1: 0.87 kw_f1: 78.07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [12:05<18:07, 362.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2: loss: 0.04 train_f1: 0.91 test_f1: 0.89 kw_f1: 80.62\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [18:06<12:03, 361.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3: loss: 0.02 train_f1: 0.96 test_f1: 0.89 kw_f1: 81.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [24:08<06:01, 361.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4: loss: 0.01 train_f1: 0.97 test_f1: 0.89 kw_f1: 81.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [30:13<00:00, 362.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5: loss: 0.01 train_f1: 0.98 test_f1: 0.90 kw_f1: 81.91\n",
            "EEG combo: EEG2.3 - Precision: 82.48, Recall: 81.35, F1 Score: 81.91\n",
            "Training with EEG combo: EEG3.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 20%|██        | 1/5 [06:03<24:12, 363.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.11 train_f1: 0.65 test_f1: 0.87 kw_f1: 77.61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [12:05<18:07, 362.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2: loss: 0.04 train_f1: 0.91 test_f1: 0.89 kw_f1: 81.19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [18:07<12:04, 362.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3: loss: 0.02 train_f1: 0.96 test_f1: 0.89 kw_f1: 81.44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [24:09<06:02, 362.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4: loss: 0.01 train_f1: 0.97 test_f1: 0.89 kw_f1: 81.90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [30:10<00:00, 362.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5: loss: 0.01 train_f1: 0.98 test_f1: 0.90 kw_f1: 82.24\n",
            "EEG combo: EEG3.4 - Precision: 82.57, Recall: 81.91, F1 Score: 82.24\n",
            "Training with EEG combo: EEG4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 20%|██        | 1/5 [06:06<24:26, 366.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.11 train_f1: 0.65 test_f1: 0.86 kw_f1: 77.08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [12:08<18:12, 364.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2: loss: 0.04 train_f1: 0.91 test_f1: 0.89 kw_f1: 81.11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [18:11<12:06, 363.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3: loss: 0.02 train_f1: 0.96 test_f1: 0.89 kw_f1: 81.31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [24:16<06:04, 364.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4: loss: 0.01 train_f1: 0.97 test_f1: 0.90 kw_f1: 82.31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [30:17<00:00, 363.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5: loss: 0.01 train_f1: 0.98 test_f1: 0.89 kw_f1: 81.88\n",
            "EEG combo: EEG4.5 - Precision: 83.57, Recall: 80.26, F1 Score: 81.88\n",
            "Training with EEG combo: EEG5.6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 20%|██        | 1/5 [06:02<24:10, 362.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.11 train_f1: 0.65 test_f1: 0.87 kw_f1: 78.37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [12:04<18:06, 362.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2: loss: 0.04 train_f1: 0.91 test_f1: 0.89 kw_f1: 81.44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [18:07<12:05, 362.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3: loss: 0.02 train_f1: 0.96 test_f1: 0.90 kw_f1: 81.77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [24:11<06:03, 363.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4: loss: 0.01 train_f1: 0.97 test_f1: 0.90 kw_f1: 81.70\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [30:18<00:00, 363.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5: loss: 0.01 train_f1: 0.98 test_f1: 0.89 kw_f1: 81.83\n",
            "EEG combo: EEG5.6 - Precision: 83.74, Recall: 80.01, F1 Score: 81.83\n",
            "Training with EEG combo: EEG6.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 20%|██        | 1/5 [06:09<24:39, 369.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.11 train_f1: 0.65 test_f1: 0.87 kw_f1: 77.63\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [12:18<18:27, 369.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2: loss: 0.04 train_f1: 0.91 test_f1: 0.89 kw_f1: 80.97\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [18:28<12:19, 369.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3: loss: 0.02 train_f1: 0.96 test_f1: 0.74 kw_f1: 81.63\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [24:40<06:10, 370.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4: loss: 0.01 train_f1: 0.97 test_f1: 0.90 kw_f1: 82.09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [30:41<00:00, 368.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5: loss: 0.01 train_f1: 0.98 test_f1: 0.90 kw_f1: 82.21\n",
            "EEG combo: EEG6.7 - Precision: 82.57, Recall: 81.85, F1 Score: 82.21\n",
            "Training with EEG combo: EEG7.8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 20%|██        | 1/5 [06:02<24:11, 362.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.11 train_f1: 0.65 test_f1: 0.87 kw_f1: 78.14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [12:04<18:06, 362.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2: loss: 0.04 train_f1: 0.91 test_f1: 0.89 kw_f1: 80.71\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [18:05<12:03, 361.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3: loss: 0.02 train_f1: 0.96 test_f1: 0.89 kw_f1: 81.59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [24:07<06:01, 361.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4: loss: 0.01 train_f1: 0.97 test_f1: 0.90 kw_f1: 81.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [30:08<00:00, 361.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5: loss: 0.01 train_f1: 0.98 test_f1: 0.89 kw_f1: 81.34\n",
            "EEG combo: EEG7.8 - Precision: 82.76, Recall: 79.98, F1 Score: 81.34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "##############################################"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "IRb9Ho7MCBYk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "outputs": [],
      "source": [
        "fs_num = 25  # 定义额外特征的数量"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "g8ds1J_QCBYk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class SoftAttention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(SoftAttention, self).__init__()\n",
        "        self.attention_weights = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        attention_scores = self.attention_weights(hidden_states)  # [batch_size, seq_len, 1]\n",
        "        attention_weights = torch.softmax(attention_scores, dim=1)  # [batch_size, seq_len, 1]\n",
        "        context_vector = torch.sum(attention_weights * hidden_states, dim=1)  # [batch_size, hidden_dim]\n",
        "        return context_vector, attention_weights\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "RNQ8tR33CBYl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class BertNerModelWithAttention(nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super(BertNerModelWithAttention, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(weight)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.attention = SoftAttention(768)\n",
        "        self.classifier = nn.Linear(768 + 8, num_labels)  # 修改为17维\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, extra_features, token_type_ids=None):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        sequence_output = outputs[0]  # [batch_size, seq_len, hidden_dim]\n",
        "        sequence_output = self.dropout(sequence_output)\n",
        "\n",
        "        context_vector, attention_weights = self.attention(sequence_output)  # [batch_size, hidden_dim]\n",
        "\n",
        "        # 扩展 context_vector 以匹配 extra_features 的维度\n",
        "        context_vector = context_vector.unsqueeze(1).expand(-1, extra_features.size(1), -1)  # [batch_size, seq_len, hidden_dim]\n",
        "\n",
        "        # 只使用前 8 个 EGG 特征\n",
        "        eye_tracking_features = extra_features[:, :, -8:]  # [batch_size, seq_len, 17]\n",
        "\n",
        "        combined_output = torch.cat((context_vector, eye_tracking_features), dim=-1)  # [batch_size, seq_len, hidden_dim + 17]\n",
        "        logits = self.classifier(combined_output)  # [batch_size, seq_len, num_labels]\n",
        "\n",
        "        return logits, attention_weights\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "w2k5q9I2CBYt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "#####################"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "6tfd5G2hCBYt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(Attention, self).__init__()\n",
        "        self.att_weight = nn.Parameter(torch.Tensor(hidden_dim, 1))\n",
        "        nn.init.xavier_uniform_(self.att_weight)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def attention_layer(self, h, mask):\n",
        "        att_weight = self.att_weight.expand(mask.shape[0], -1, -1)  # B*H*1\n",
        "        att_score = torch.bmm(self.tanh(h), att_weight)  # B*L*H  *  B*H*1 -> B*L*1\n",
        "\n",
        "        # mask, remove the effect of 'PAD'\n",
        "        mask = mask.unsqueeze(dim=-1)  # B*L*1\n",
        "        att_score = att_score.masked_fill(mask.eq(0), float('-inf'))  # B*L*1\n",
        "        att_weight = F.softmax(att_score, dim=1)  # B*L*1\n",
        "\n",
        "        reps = h * att_weight  # B*L*H *  B*L*1 -> B*L*H\n",
        "        reps = self.tanh(reps)  # B*L*H\n",
        "        return reps, att_weight\n",
        "\n",
        "\n",
        "class BertNerModelWithAttention(nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super(BertNerModelWithAttention, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(weight)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.layernorm = nn.LayerNorm(normalized_shape=768)  # 使用BERT的输出维度进行LayerNorm\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear_dropout = nn.Dropout(0.1)\n",
        "        self.attention = Attention(768)\n",
        "        self.classifier = nn.Linear(768 + 8, num_labels)  # 修改为18维\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, extra_features, token_type_ids=None):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        sequence_output = outputs[0]  # [batch_size, seq_len, hidden_dim]\n",
        "        sequence_output = self.dropout(sequence_output)\n",
        "\n",
        "        # 添加LayerNorm、ReLU和Dropout操作\n",
        "        normalized_output = self.layernorm(sequence_output)\n",
        "        activated_output = self.relu(normalized_output)\n",
        "        dropout_output = self.linear_dropout(activated_output)\n",
        "\n",
        "        context_vector, attention_weights = self.attention.attention_layer(dropout_output, attention_mask)  # [batch_size, seq_len, hidden_dim]\n",
        "\n",
        "        # 只使用前18个ET特征\n",
        "        et_features = extra_features[:, :, -8:]  # 提取前18维度的特征\n",
        "\n",
        "        # 直接拼接 context_vector 和 et_features\n",
        "        combined_output = torch.cat((context_vector, et_features), dim=-1)  # [batch_size, seq_len, hidden_dim + 18]\n",
        "        logits = self.classifier(combined_output)  # [batch_size, seq_len, num_labels]\n",
        "\n",
        "        return logits, attention_weights\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "xynUO2qzCBYu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
          ]
        }
      ],
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import AdamW\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# model = BertNerModelWithSoftAttention(num_labels=6)\n",
        "# model = model.to(device)\n",
        "\n",
        "\n",
        "model = BertNerModelWithAttention(num_labels=6)\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "#optim = AdamW(model.parameters(), lr=5e-5, weight_decay=1e-2)\n",
        "optim = AdamW(model.parameters(), lr=1e-5, weight_decay=1e-2)  # 尝试降低学习率\n",
        "\n",
        "loss_fn = CrossEntropyLoss(reduction='none', ignore_index=0)\n",
        "loss_fn = loss_fn.to(device)\n",
        "\n",
        "epochs = 5\n",
        "best_f1 = 0.0\n",
        "num_labels = 6"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "BmYizQdTCBYu",
        "outputId": "af854bd6-2549-4ce3-aa36-529df02ec413"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]F:\\anaconda\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
            "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
            " 20%|██        | 1/5 [01:59<07:57, 119.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch1:  loss:0.98   train_f1_value:0.16  test_f1_value:0.16  kw_f1_value:1.50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 2/5 [03:57<05:56, 119.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch2:  loss:0.89   train_f1_value:0.16  test_f1_value:0.19  kw_f1_value:1.37\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 3/5 [05:55<03:57, 118.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch3:  loss:0.85   train_f1_value:0.16  test_f1_value:0.19  kw_f1_value:0.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 4/5 [07:54<01:58, 118.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch4:  loss:0.81   train_f1_value:0.19  test_f1_value:0.19  kw_f1_value:0.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [09:50<00:00, 118.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch5:  loss:0.78   train_f1_value:0.19  test_f1_value:0.19  kw_f1_value:0.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# 训练模型\n",
        "import torch.nn.functional as F\n",
        "\n",
        "epochs = 5\n",
        "best_f1 = 0.0\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    loss_value = 0.0\n",
        "    model.train()\n",
        "    label_true, label_pred = [], []\n",
        "    for i, batch in enumerate(train_dataloader):\n",
        "        optim.zero_grad()\n",
        "        input_ids, attention_masks, _, features, tags = batch\n",
        "        pred_tags, _ = model(input_ids.to(device), attention_masks.to(device), features.to(device))\n",
        "\n",
        "        loss = loss_fn(pred_tags.permute(0, 2, 1), tags.to(device))\n",
        "        loss = loss.mean()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "        pred_tags = F.softmax(pred_tags, dim=-1)\n",
        "        pred_tags = torch.argmax(pred_tags, dim=-1)\n",
        "\n",
        "        y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "        label_true.extend(y_true)\n",
        "        label_pred.extend(y_pred)\n",
        "\n",
        "        loss_value += loss.item()\n",
        "\n",
        "    label_train_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "\n",
        "    model.eval()\n",
        "    kw_true, kw_pred = [], []\n",
        "    label_true, label_pred = [], []\n",
        "    for i, batch in enumerate(test_dataloader):\n",
        "        input_ids, attention_masks, tokens, features, tags = batch\n",
        "        with torch.no_grad():\n",
        "            for module in model.modules():\n",
        "                if isinstance(module, nn.Dropout):\n",
        "                    module.p = 0\n",
        "                    module.train(False)\n",
        "            pred_tags, _ = model(input_ids.to(device), attention_masks.to(device), features.to(device))\n",
        "            pred_tags = F.softmax(pred_tags, dim=-1)\n",
        "            pred_tags = torch.argmax(pred_tags, dim=-1)\n",
        "\n",
        "        y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "        label_true.extend(y_true)\n",
        "        label_pred.extend(y_pred)\n",
        "\n",
        "        poss = []\n",
        "        for i in range(len(tags)):\n",
        "            pos = []\n",
        "            for j in range(len(tags[i])):\n",
        "                if tags[i][j] == 0:\n",
        "                    pos.append(j)\n",
        "            poss.append(pos)\n",
        "\n",
        "        kw_true.extend(TagConvert(tags, tokens))\n",
        "        kw_pred.extend(TagConvert(pred_tags, tokens, poss))\n",
        "\n",
        "    label_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "    P, R, F1 = evaluate(kw_true, kw_pred)\n",
        "\n",
        "    if F1 > best_f1:\n",
        "        best_f1 = F1\n",
        "        torch.save(model.state_dict(), './pretrain_pt/bert_with_soft_EGG.pt')\n",
        "\n",
        "    print(\"epoch{}:  loss:{:.2f}   train_f1_value:{:.2f}  test_f1_value:{:.2f}  kw_f1_value:{:.2f}\".format(\n",
        "        epoch + 1, loss_value / len(train_dataloader), label_train_f1, label_f1, F1\n",
        "    ))\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Htg3BCMkCBYu",
        "outputId": "8ef74e25-8397-427d-ab5d-2a123e091524"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
          ]
        }
      ],
      "source": [
        "model = BertNerModelWithAttention(num_labels=6)\n",
        "model.load_state_dict(torch.load('./pretrain_pt/bert_with_soft_EGG.pt'))\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "a944PVZhCBYv",
        "outputId": "14623373-b637-48c0-9f40-c84ce00feaf3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label F1 Score: 0.16\n",
            "Precision: 1.37\n",
            "Recall: 1.66\n",
            "F1 Score: 1.50\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import f1_score\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "\n",
        "# 加载最佳模型权重\n",
        "model.load_state_dict(torch.load('./pretrain_pt/bert_with_soft_EGG.pt'))\n",
        "model.eval()\n",
        "\n",
        "\n",
        "def inference_and_evaluate(test_dataloader, model, device):\n",
        "    kw_true, kw_pred = [], []\n",
        "    label_true, label_pred = [], []\n",
        "\n",
        "    for i, batch in enumerate(test_dataloader):\n",
        "        input_ids, attention_masks, tokens, features, tags = batch\n",
        "        with torch.no_grad():\n",
        "            for module in model.modules():\n",
        "                if isinstance(module, nn.Dropout):\n",
        "                    module.p = 0\n",
        "                    module.train(False)\n",
        "            outputs = model(input_ids.to(device), attention_masks.to(device), features.to(device))\n",
        "            pred_tags = outputs[0] if isinstance(outputs, tuple) else outputs  # Handle tuple output\n",
        "            pred_tags = F.softmax(pred_tags, dim=-1)\n",
        "            pred_tags = torch.argmax(pred_tags, dim=-1)\n",
        "\n",
        "        y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "        label_true.extend(y_true)\n",
        "        label_pred.extend(y_pred)\n",
        "\n",
        "        # more balance evaluate\n",
        "        poss = []\n",
        "        for i in range(len(tags)):\n",
        "            pos = []\n",
        "            for j in range(len(tags[i])):\n",
        "                if tags[i][j] == 0:\n",
        "                    pos.append(j)\n",
        "            poss.append(pos)\n",
        "\n",
        "        kw_true.extend(TagConvert(tags, tokens))\n",
        "        kw_pred.extend(TagConvert(pred_tags, tokens, poss))\n",
        "\n",
        "    label_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "    P, R, F1 = evaluate(kw_true, kw_pred)\n",
        "\n",
        "    return label_f1, P, R, F1\n",
        "\n",
        "# 调用推理和评价函数\n",
        "label_f1, P, R, F1 = inference_and_evaluate(test_dataloader, model, device)\n",
        "\n",
        "print(f\"Label F1 Score: {label_f1:.2f}\")\n",
        "print(f\"Precision: {P:.2f}\")\n",
        "print(f\"Recall: {R:.2f}\")\n",
        "print(f\"F1 Score: {F1:.2f}\")\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ycDwqJEtCBYv",
        "outputId": "7c6d2257-c62c-42f5-e158-5613bab3bea4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#################################soft——不同EGG组合"
      ],
      "metadata": {
        "id": "vMBzt3baKmMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import f1_score\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "# Attention 和 BertNerModelWithAttention 定义\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(Attention, self).__init__()\n",
        "        self.att_weight = nn.Parameter(torch.Tensor(hidden_dim, 1))\n",
        "        nn.init.xavier_uniform_(self.att_weight)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def attention_layer(self, h, mask):\n",
        "        att_weight = self.att_weight.expand(mask.shape[0], -1, -1)  # B*H*1\n",
        "        att_score = torch.bmm(self.tanh(h), att_weight)  # B*L*H  *  B*H*1 -> B*L*1\n",
        "\n",
        "        # mask, remove the effect of 'PAD'\n",
        "        mask = mask.unsqueeze(dim=-1)  # B*L*1\n",
        "        att_score = att_score.masked_fill(mask.eq(0), float('-inf'))  # B*L*1\n",
        "        att_weight = F.softmax(att_score, dim=1)  # B*L*1\n",
        "\n",
        "        reps = h * att_weight  # B*L*H *  B*L*1 -> B*L*H\n",
        "        reps = self.tanh(reps)  # B*L*H\n",
        "        return reps, att_weight\n",
        "\n",
        "\n",
        "class BertNerModelWithAttention(nn.Module):\n",
        "    def __init__(self, num_labels, eeg_combo_dim):\n",
        "        super(BertNerModelWithAttention, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(weight)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.layernorm = nn.LayerNorm(normalized_shape=768)  # 使用BERT的输出维度进行LayerNorm\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear_dropout = nn.Dropout(0.1)\n",
        "        self.attention = Attention(768)\n",
        "        self.classifier = nn.Linear(768 + eeg_combo_dim, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, extra_features, eeg_combo):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        sequence_output = outputs[0]  # [batch_size, seq_len, hidden_dim]\n",
        "        sequence_output = self.dropout(sequence_output)\n",
        "\n",
        "        # 添加LayerNorm、ReLU和Dropout操作\n",
        "        normalized_output = self.layernorm(sequence_output)\n",
        "        activated_output = self.relu(normalized_output)\n",
        "        dropout_output = self.linear_dropout(activated_output)\n",
        "\n",
        "        context_vector, attention_weights = self.attention.attention_layer(dropout_output, attention_mask)  # [batch_size, seq_len, hidden_dim]\n",
        "\n",
        "        # 动态选择 EEG 特征\n",
        "        if eeg_combo == 'EEG1':\n",
        "            eeg_features = extra_features[:, :, -8:-7]\n",
        "        elif eeg_combo == 'EEG2':\n",
        "            eeg_features = extra_features[:, :, -7:-6]\n",
        "        elif eeg_combo == 'EEG3':\n",
        "            eeg_features = extra_features[:, :, -6:-5]\n",
        "        elif eeg_combo == 'EEG4':\n",
        "            eeg_features = extra_features[:, :, -5:-4]\n",
        "        elif eeg_combo == 'EEG5':\n",
        "            eeg_features = extra_features[:, :, -4:-3]\n",
        "        elif eeg_combo == 'EEG6':\n",
        "            eeg_features = extra_features[:, :, -3:-2]\n",
        "        elif eeg_combo == 'EEG7':\n",
        "            eeg_features = extra_features[:, :, -2:-1]\n",
        "        elif eeg_combo == 'EEG8':\n",
        "            eeg_features = extra_features[:, :, -1:]\n",
        "        elif eeg_combo == 'EEG1.2':\n",
        "            eeg_features = extra_features[:, :, -8:-6]\n",
        "        elif eeg_combo == 'EEG2.3':\n",
        "            eeg_features = extra_features[:, :, -7:-5]\n",
        "        elif eeg_combo == 'EEG3.4':\n",
        "            eeg_features = extra_features[:, :, -6:-4]\n",
        "        elif eeg_combo == 'EEG4.5':\n",
        "            eeg_features = extra_features[:, :, -5:-3]\n",
        "        elif eeg_combo == 'EEG5.6':\n",
        "            eeg_features = extra_features[:, :, -4:-2]\n",
        "        elif eeg_combo == 'EEG6.7':\n",
        "            eeg_features = extra_features[:, :, -3:-1]\n",
        "        elif eeg_combo == 'EEG7.8':\n",
        "            eeg_features = extra_features[:, :, -2:]\n",
        "\n",
        "        combined_output = torch.cat((context_vector, eeg_features), dim=-1)  # [batch_size, seq_len, hidden_dim + eeg_combo_dim]\n",
        "        logits = self.classifier(combined_output)  # [batch_size, seq_len, num_labels]\n",
        "\n",
        "        return logits, attention_weights\n",
        "\n",
        "# 训练和评估函数\n",
        "def train_and_evaluate(train_dataloader, test_dataloader, eeg_combo, num_labels=6, epochs=3, lr=5e-5):\n",
        "    eeg_combo_dim = len(eeg_combo.split('.'))  # EEG 组合维度\n",
        "\n",
        "    model = BertNerModelWithAttention(num_labels=num_labels, eeg_combo_dim=eeg_combo_dim)\n",
        "    model = model.to(device)\n",
        "\n",
        "    optim = AdamW(model.parameters(), lr=lr, weight_decay=1e-2)\n",
        "    loss_fn = CrossEntropyLoss(reduction='none', ignore_index=0).to(device)\n",
        "\n",
        "    best_f1 = 0.0\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        loss_value = 0.0\n",
        "        model.train()\n",
        "        label_true, label_pred = [], []\n",
        "        for i, batch in enumerate(train_dataloader):\n",
        "            optim.zero_grad()\n",
        "            input_ids, attention_masks, _, features, tags = batch\n",
        "            pred_tags, _ = model(input_ids.to(device), attention_masks.to(device), features.to(device), eeg_combo)\n",
        "\n",
        "            loss = loss_fn(pred_tags.permute(0, 2, 1), tags.to(device))\n",
        "            loss = loss.mean()\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "\n",
        "            pred_tags = F.softmax(pred_tags, dim=-1)\n",
        "            pred_tags = torch.argmax(pred_tags, dim=-1)\n",
        "\n",
        "            y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "            label_true.extend(y_true)\n",
        "            label_pred.extend(y_pred)\n",
        "\n",
        "            loss_value += loss.item()\n",
        "\n",
        "        label_train_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "\n",
        "        # Evaluation loop\n",
        "        model.eval()\n",
        "        kw_true, kw_pred = [], []\n",
        "        label_true, label_pred = [], []\n",
        "        for i, batch in enumerate(test_dataloader):\n",
        "            input_ids, attention_masks, tokens, features, tags = batch\n",
        "            with torch.no_grad():\n",
        "                for module in model.modules():\n",
        "                    if isinstance(module, nn.Dropout):\n",
        "                        module.p = 0\n",
        "                        module.train(False)\n",
        "                pred_tags, _ = model(input_ids.to(device), attention_masks.to(device), features.to(device), eeg_combo)\n",
        "                pred_tags = F.softmax(pred_tags, dim=-1)\n",
        "                pred_tags = torch.argmax(pred_tags, dim=-1)\n",
        "\n",
        "            y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "            label_true.extend(y_true)\n",
        "            label_pred.extend(y_pred)\n",
        "\n",
        "            poss = []\n",
        "            for i in range(len(tags)):\n",
        "                pos = []\n",
        "                for j in range(len(tags[i])):\n",
        "                    if tags[i][j] == 0:\n",
        "                        pos.append(j)\n",
        "                poss.append(pos)\n",
        "\n",
        "            kw_true.extend(TagConvert(tags, tokens))\n",
        "            kw_pred.extend(TagConvert(pred_tags, tokens, poss))\n",
        "\n",
        "        label_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "        P, R, F1 = evaluate(kw_true, kw_pred)\n",
        "\n",
        "        # Save the best model for the given EEG combination\n",
        "        if F1 > best_f1:\n",
        "            best_f1 = F1\n",
        "            torch.save(model.state_dict(), f'/content/drive/MyDrive/ner/pretrain_pt/bert_soft_{eeg_combo}.pt')\n",
        "        print(f\"epoch {epoch+1}: loss: {loss_value / len(train_dataloader):.2f} train_f1: {label_train_f1:.2f} test_f1: {label_f1:.2f} kw_f1: {F1:.2f}\")\n",
        "\n",
        "    return P, R, F1\n",
        "\n",
        "# 使用不同的 EEG 组合进行训练和评估\n",
        "eeg_combos = ['EEG1', 'EEG2', 'EEG3', 'EEG4', 'EEG5', 'EEG6', 'EEG7', 'EEG8',\n",
        "              'EEG1.2', 'EEG2.3', 'EEG3.4', 'EEG4.5', 'EEG5.6', 'EEG6.7', 'EEG7.8']\n",
        "\n",
        "for eeg_combo in eeg_combos:\n",
        "    print(f\"Training with EEG combo: {eeg_combo}\")\n",
        "    P, R, F1 = train_and_evaluate(train_dataloader, test_dataloader, eeg_combo)\n",
        "    print(f\"EEG combo: {eeg_combo} - Precision: {P:.2f}, Recall: {R:.2f}, F1 Score: {F1:.2f}\")\n"
      ],
      "metadata": {
        "id": "mEsfzsgQKrwR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "81772882fbfd4f3aa27a0c6aa50a2112",
            "bb5679d7a63c430780cf7ccee329bde0",
            "01e746ea30a44cf799c638b8cc09c9f3",
            "ded9692e85bb4599a963a15d242af1ae",
            "ba0c10620d08463f9804d3e6c52aa603",
            "df29793c486b47e38a38ff25f715f89a",
            "eee0775404df44298b59b094ebe013b8",
            "db899ebfd20344869f0590da9b2903ac",
            "db3c721915b44a0181765c350aa3f5eb",
            "d0e2bd24016642a588a7e4b53a04c8df",
            "43688966bc1348e08caf09eb3f510afd"
          ]
        },
        "outputId": "e3283bae-5dd7-4a26-e893-f9a92cfa6296"
      },
      "execution_count": 20,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with EEG combo: EEG1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81772882fbfd4f3aa27a0c6aa50a2112",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 1/3 [10:04<20:09, 604.61s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1: loss: 0.61 train_f1: 0.16 test_f1: 0.18 kw_f1: 0.00\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 2/3 [20:08<10:04, 604.41s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2: loss: 0.35 train_f1: 0.18 test_f1: 0.18 kw_f1: 0.00\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [30:12<00:00, 604.03s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3: loss: 0.25 train_f1: 0.18 test_f1: 0.18 kw_f1: 0.00\n",
            "EEG combo: EEG1 - Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
            "Training with EEG combo: EEG2\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " 33%|███▎      | 1/3 [10:09<20:18, 609.38s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1: loss: 0.59 train_f1: 0.16 test_f1: 0.18 kw_f1: 0.00\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 2/3 [20:13<10:06, 606.09s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2: loss: 0.35 train_f1: 0.18 test_f1: 0.18 kw_f1: 0.00\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [30:17<00:00, 605.87s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3: loss: 0.25 train_f1: 0.18 test_f1: 0.18 kw_f1: 0.00\n",
            "EEG combo: EEG2 - Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
            "Training with EEG combo: EEG3\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " 33%|███▎      | 1/3 [10:13<20:26, 613.44s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1: loss: 0.62 train_f1: 0.22 test_f1: 0.28 kw_f1: 33.17\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 2/3 [20:18<10:08, 608.31s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2: loss: 0.36 train_f1: 0.21 test_f1: 0.18 kw_f1: 0.00\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [30:24<00:00, 608.32s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3: loss: 0.26 train_f1: 0.18 test_f1: 0.18 kw_f1: 0.00\n",
            "EEG combo: EEG3 - Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
            "Training with EEG combo: EEG4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " 33%|███▎      | 1/3 [10:08<20:16, 608.05s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1: loss: 0.58 train_f1: 0.18 test_f1: 0.18 kw_f1: 0.00\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 2/3 [20:12<10:05, 605.65s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2: loss: 0.33 train_f1: 0.18 test_f1: 0.18 kw_f1: 0.00\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [30:17<00:00, 605.87s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3: loss: 0.24 train_f1: 0.18 test_f1: 0.18 kw_f1: 0.00\n",
            "EEG combo: EEG4 - Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
            "Training with EEG combo: EEG5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " 33%|███▎      | 1/3 [10:09<20:19, 609.53s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1: loss: 0.61 train_f1: 0.24 test_f1: 0.19 kw_f1: 0.00\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 2/3 [20:13<10:06, 606.16s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2: loss: 0.35 train_f1: 0.18 test_f1: 0.18 kw_f1: 0.00\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [30:17<00:00, 605.77s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3: loss: 0.25 train_f1: 0.18 test_f1: 0.18 kw_f1: 0.00\n",
            "EEG combo: EEG5 - Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
            "Training with EEG combo: EEG6\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " 33%|███▎      | 1/3 [10:07<20:14, 607.35s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1: loss: 0.62 train_f1: 0.20 test_f1: 0.18 kw_f1: 0.00\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 2/3 [20:11<10:05, 605.56s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2: loss: 0.35 train_f1: 0.18 test_f1: 0.18 kw_f1: 0.00\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [30:18<00:00, 606.00s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3: loss: 0.25 train_f1: 0.18 test_f1: 0.18 kw_f1: 0.00\n",
            "EEG combo: EEG6 - Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
            "Training with EEG combo: EEG7\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " 33%|███▎      | 1/3 [10:06<20:13, 606.99s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1: loss: 0.60 train_f1: 0.19 test_f1: 0.18 kw_f1: 0.00\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 2/3 [20:10<10:05, 605.03s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2: loss: 0.34 train_f1: 0.18 test_f1: 0.18 kw_f1: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [30:12<00:00, 604.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3: loss: 0.25 train_f1: 0.18 test_f1: 0.18 kw_f1: 0.00\n",
            "EEG combo: EEG7 - Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
            "Training with EEG combo: EEG8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 33%|███▎      | 1/3 [10:09<20:18, 609.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.59 train_f1: 0.22 test_f1: 0.18 kw_f1: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 2/3 [20:10<10:04, 604.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2: loss: 0.34 train_f1: 0.18 test_f1: 0.18 kw_f1: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [30:11<00:00, 603.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3: loss: 0.25 train_f1: 0.18 test_f1: 0.18 kw_f1: 0.00\n",
            "EEG combo: EEG8 - Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
            "Training with EEG combo: EEG1.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 33%|███▎      | 1/3 [10:05<20:10, 605.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.63 train_f1: 0.20 test_f1: 0.18 kw_f1: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 2/3 [20:07<10:03, 603.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2: loss: 0.36 train_f1: 0.18 test_f1: 0.18 kw_f1: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [30:09<00:00, 603.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3: loss: 0.26 train_f1: 0.18 test_f1: 0.18 kw_f1: 0.00\n",
            "EEG combo: EEG1.2 - Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
            "Training with EEG combo: EEG2.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 33%|███▎      | 1/3 [10:05<20:11, 605.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.60 train_f1: 0.17 test_f1: 0.18 kw_f1: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 2/3 [20:07<10:03, 603.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2: loss: 0.35 train_f1: 0.18 test_f1: 0.18 kw_f1: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [30:10<00:00, 603.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3: loss: 0.25 train_f1: 0.18 test_f1: 0.18 kw_f1: 0.00\n",
            "EEG combo: EEG2.3 - Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
            "Training with EEG combo: EEG3.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 33%|███▎      | 1/3 [10:07<20:15, 607.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.61 train_f1: 0.21 test_f1: 0.18 kw_f1: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 2/3 [20:09<10:04, 604.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2: loss: 0.35 train_f1: 0.18 test_f1: 0.18 kw_f1: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [30:11<00:00, 603.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3: loss: 0.25 train_f1: 0.18 test_f1: 0.18 kw_f1: 0.00\n",
            "EEG combo: EEG3.4 - Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
            "Training with EEG combo: EEG4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 33%|███▎      | 1/3 [10:04<20:08, 604.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.56 train_f1: 0.15 test_f1: 0.18 kw_f1: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 2/3 [20:05<10:02, 602.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2: loss: 0.31 train_f1: 0.18 test_f1: 0.18 kw_f1: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [30:07<00:00, 602.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3: loss: 0.24 train_f1: 0.18 test_f1: 0.18 kw_f1: 0.00\n",
            "EEG combo: EEG4.5 - Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
            "Training with EEG combo: EEG5.6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 33%|███▎      | 1/3 [10:05<20:10, 605.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.56 train_f1: 0.15 test_f1: 0.18 kw_f1: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 2/3 [20:07<10:03, 603.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2: loss: 0.31 train_f1: 0.18 test_f1: 0.18 kw_f1: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [30:10<00:00, 603.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3: loss: 0.24 train_f1: 0.18 test_f1: 0.18 kw_f1: 0.00\n",
            "EEG combo: EEG5.6 - Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
            "Training with EEG combo: EEG6.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 33%|███▎      | 1/3 [10:08<20:16, 608.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.60 train_f1: 0.19 test_f1: 0.18 kw_f1: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 2/3 [20:10<10:04, 604.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2: loss: 0.33 train_f1: 0.18 test_f1: 0.18 kw_f1: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [30:12<00:00, 604.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3: loss: 0.24 train_f1: 0.18 test_f1: 0.18 kw_f1: 0.00\n",
            "EEG combo: EEG6.7 - Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
            "Training with EEG combo: EEG7.8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 33%|███▎      | 1/3 [10:03<20:07, 603.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.59 train_f1: 0.18 test_f1: 0.18 kw_f1: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 2/3 [20:05<10:02, 602.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2: loss: 0.33 train_f1: 0.18 test_f1: 0.18 kw_f1: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [30:07<00:00, 602.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3: loss: 0.24 train_f1: 0.18 test_f1: 0.18 kw_f1: 0.00\n",
            "EEG combo: EEG7.8 - Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ###定义词级别和句子级别的注意力层"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "eFvIYtSqCBYw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "层注意力 2.0"
      ],
      "metadata": {
        "collapsed": false,
        "id": "ndaZZOUHCBYw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertModel\n",
        "from sklearn.metrics import f1_score\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "6gsoKH3gCBYx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch1:  loss:0.28   train_f1_value:0.16  test_f1_value:0.19  kw_f1_value:0.25\n",
            "epoch2:  loss:0.24   train_f1_value:0.19  test_f1_value:0.19  kw_f1_value:0.00\n",
            "epoch3:  loss:0.23   train_f1_value:0.19  test_f1_value:0.19  kw_f1_value:0.37\n",
            "epoch4:  loss:0.22   train_f1_value:0.19  test_f1_value:0.19  kw_f1_value:0.25\n",
            "epoch5:  loss:0.21   train_f1_value:0.19  test_f1_value:0.19  kw_f1_value:0.37\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "from transformers import BertModel\n",
        "from torch import nn\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(Attention, self).__init__()\n",
        "        self.context = nn.Parameter(torch.FloatTensor(hidden_dim, 1))\n",
        "        nn.init.xavier_uniform_(self.context)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        attention_in = torch.tanh(torch.matmul(x, self.context))\n",
        "        attention_in = torch.squeeze(attention_in, -1)\n",
        "        if mask is not None:\n",
        "            attention_in = attention_in * mask.float()\n",
        "        attention_weights = F.softmax(attention_in, dim=-1)\n",
        "        weighted_sum = torch.bmm(attention_weights.unsqueeze(1), x).squeeze(1)\n",
        "        return weighted_sum\n",
        "\n",
        "class BertHANModel(nn.Module):\n",
        "    def __init__(self, num_labels, hidden_dim=768, rnn_dim=256):\n",
        "        super(BertHANModel, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.word_attention = Attention(hidden_dim)\n",
        "        self.rnn = nn.GRU(hidden_dim, rnn_dim, batch_first=True, bidirectional=True)\n",
        "        self.sentence_attention = Attention(rnn_dim * 2)\n",
        "        self.classifier = nn.Linear(rnn_dim * 2 + 8, num_labels)  # 修改为17维\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, extra_features):\n",
        "        bert_outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        sequence_output = bert_outputs[0]  # shape: (batch_size, seq_length, hidden_dim)\n",
        "\n",
        "        # Word-level attention\n",
        "        word_attention_output = self.word_attention(sequence_output)\n",
        "\n",
        "        # Sentence-level GRU\n",
        "        rnn_output, _ = self.rnn(word_attention_output.unsqueeze(1))\n",
        "\n",
        "        # Sentence-level attention\n",
        "        sentence_attention_output = self.sentence_attention(rnn_output)\n",
        "\n",
        "        # 确保 sentence_attention_output 是三维张量\n",
        "        if sentence_attention_output.dim() == 2:\n",
        "            # 将其调整为三维张量 [batch_size, seq_len, rnn_dim * 2]\n",
        "            sentence_attention_output = sentence_attention_output.unsqueeze(1).expand(-1, extra_features.size(1), -1)\n",
        "\n",
        "        # 只使用前 17 个 ET 特征\n",
        "        eye_tracking_features = extra_features[:, :, -8:]  # [batch_size, seq_len, 17]\n",
        "\n",
        "        # 打印维度以调试\n",
        "        # print(f\"Adjusted sentence_attention_output shape: {sentence_attention_output.shape}\")\n",
        "        # print(f\"eye_tracking_features shape: {eye_tracking_features.shape}\")\n",
        "\n",
        "        # 拼接特征\n",
        "        combined_output = torch.cat((sentence_attention_output, eye_tracking_features), dim=-1)  # [batch_size, seq_len, rnn_dim * 2 + 17]\n",
        "\n",
        "        logits = self.classifier(combined_output)  # shape: (batch_size, seq_len, num_labels)\n",
        "\n",
        "        return logits  # 返回 shape: (batch_size, seq_length, num_labels)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def calculate_f1(y_pred, y_true):\n",
        "    y_true = y_true.view(-1)\n",
        "    y_pred = y_pred.view(-1)\n",
        "    y_true = y_true.detach().cpu().numpy()\n",
        "    y_pred = y_pred.detach().cpu().numpy()\n",
        "    mask = np.where(y_true != 0)\n",
        "    y_true = y_true[mask]\n",
        "    y_pred = y_pred[mask]\n",
        "    return y_pred, y_true\n",
        "\n",
        "def TagConvert(raw_tags, words_set, poss=None):\n",
        "    true_tags = []\n",
        "    for i in range(raw_tags.shape[0]):\n",
        "        kw_list = []\n",
        "        nkw_list = \"\"\n",
        "        for j in range(len(raw_tags[i])):\n",
        "            item = raw_tags[i][j]\n",
        "            if item == 0:\n",
        "                continue\n",
        "            if poss != None and j in poss[i]:\n",
        "                continue\n",
        "            if item == 4:\n",
        "                kw_list.append(str(words_set[j][i]))\n",
        "            if item == 1:\n",
        "                nkw_list += str(words_set[j][i])\n",
        "            if item == 2:\n",
        "                nkw_list += \" \"\n",
        "                nkw_list += str(words_set[j][i])\n",
        "            if item == 3:\n",
        "                nkw_list += \" \"\n",
        "                nkw_list += str(words_set[j][i])\n",
        "                kw_list.append(nkw_list)\n",
        "                nkw_list = \"\"\n",
        "        true_tags.append(kw_list)\n",
        "    return true_tags\n",
        "\n",
        "def evaluate(predict_data, target_data, topk=3):\n",
        "    TRUE_COUNT, PRED_COUNT, GOLD_COUNT = 0.0, 0.0, 0.0\n",
        "    for index, words in enumerate(predict_data):\n",
        "        y_pred, y_true = None, target_data[index]\n",
        "        if type(predict_data) == str:\n",
        "            words = sorted(words.items(), key=lambda item: (-item[1], item[0]))\n",
        "            y_pred = [i[0] for i in words]\n",
        "        elif type(predict_data) == list:\n",
        "            y_pred = words\n",
        "        y_pred = y_pred[0: topk]\n",
        "        TRUE_NUM = len(set(y_pred) & set(y_true))\n",
        "        TRUE_COUNT += TRUE_NUM\n",
        "        PRED_COUNT += len(y_pred)\n",
        "        GOLD_COUNT += len(y_true)\n",
        "    if PRED_COUNT != 0:\n",
        "        p = (TRUE_COUNT / PRED_COUNT)\n",
        "    else:\n",
        "        p = 0\n",
        "    if GOLD_COUNT != 0:\n",
        "        r = (TRUE_COUNT / GOLD_COUNT)\n",
        "    else:\n",
        "        r = 0\n",
        "    if (r + p) != 0:\n",
        "        f1 = ((2 * r * p) / (r + p))\n",
        "    else:\n",
        "        f1 = 0\n",
        "    p = round(p * 100, 2)\n",
        "    r = round(r * 100, 2)\n",
        "    f1 = round(f1 * 100, 2)\n",
        "    return p, r, f1\n",
        "\n",
        "# 假设已经定义了数据集和数据加载器\n",
        "# train_dataloader = ...\n",
        "# test_dataloader = ...\n",
        "\n",
        "# 训练和评估\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = BertHANModel(num_labels=6)\n",
        "model = model.to(device)\n",
        "optim = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss(reduction='none', ignore_index=0)\n",
        "loss_fn = loss_fn.to(device)\n",
        "\n",
        "epochs = 5\n",
        "best_f1 = 0.0\n",
        "scaler = GradScaler()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    loss_value = 0.0\n",
        "    model.train()\n",
        "    label_true, label_pred = [], []\n",
        "    for i, batch in enumerate(train_dataloader):\n",
        "        optim.zero_grad()\n",
        "#input_ids, attention_masks, _, features, tags = batch\n",
        "        input_ids = batch[0].to(device)\n",
        "        attention_masks = batch[1].to(device)\n",
        "        features = batch[3].to(device)\n",
        "        tags = batch[4].to(device)\n",
        "\n",
        "        with autocast():\n",
        "            pred_tags = model(input_ids, attention_masks,features)\n",
        "\n",
        "            # 展平 pred_tags 和 tags 以匹配形状\n",
        "            pred_tags = pred_tags.reshape(-1, pred_tags.size(-1))\n",
        "            tags = tags.reshape(-1)\n",
        "\n",
        "            #print(f\"pred_tags shape: {pred_tags.shape}, tags shape: {tags.shape}\")\n",
        "\n",
        "            loss = loss_fn(pred_tags, tags)\n",
        "            loss = loss.mean()\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optim)\n",
        "        scaler.update()\n",
        "\n",
        "        pred_tags = F.softmax(pred_tags, dim=-1)\n",
        "        pred_tags = torch.argmax(pred_tags, dim=-1)\n",
        "        y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "        label_true.extend(y_true)\n",
        "        label_pred.extend(y_pred)\n",
        "        loss_value += loss.item()\n",
        "\n",
        "    label_train_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "\n",
        "    model.eval()\n",
        "    kw_true, kw_pred = [], []\n",
        "    label_true, label_pred = [], []\n",
        "    for i, batch in enumerate(test_dataloader):\n",
        "        input_ids = batch[0].to(device)\n",
        "        attention_masks = batch[1].to(device)\n",
        "        tokens = batch[2]  # tokens 不是 Tensor，直接使用\n",
        "        features = batch[3].to(device)\n",
        "        tags = batch[4].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for module in model.modules():\n",
        "                if isinstance(module, nn.Dropout):\n",
        "                    module.p = 0\n",
        "                    module.train(False)\n",
        "            with autocast():\n",
        "                pred_tags = model(input_ids, attention_masks,features)\n",
        "                pred_tags = F.softmax(pred_tags, dim=-1)\n",
        "                pred_tags = torch.argmax(pred_tags, dim=-1)\n",
        "\n",
        "        y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "        label_true.extend(y_true)\n",
        "        label_pred.extend(y_pred)\n",
        "\n",
        "        poss = []\n",
        "        for i in range(len(tags)):\n",
        "            pos = []\n",
        "            for j in range(len(tags[i])):\n",
        "                if tags[i][j] == 0:\n",
        "                    pos.append(j)\n",
        "            poss.append(pos)\n",
        "\n",
        "        kw_true.extend(TagConvert(tags, tokens))\n",
        "        kw_pred.extend(TagConvert(pred_tags, tokens, poss))\n",
        "\n",
        "    label_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "    P, R, F1 = evaluate(kw_true, kw_pred)\n",
        "\n",
        "    if F1 > best_f1:\n",
        "        best_f1 = F1\n",
        "        torch.save(model.state_dict(), './pretrain_pt/bert_HAtten_EGG.pt')\n",
        "\n",
        "    print(\"epoch{}:  loss:{:.2f}   train_f1_value:{:.2f}  test_f1_value:{:.2f}  kw_f1_value:{:.2f}\".format(\n",
        "        epoch + 1, loss_value / len(train_dataloader), label_train_f1, label_f1, F1\n",
        "    ))\n",
        "\n",
        "    torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5hPkvl3VCBYx",
        "outputId": "cbdcc222-d744-4a5f-9b3d-fc8025ec42fb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label_f1: 0.19, Precision: 0.18, Recall: 37.50, F1: 0.37\n"
          ]
        }
      ],
      "source": [
        "def load_model(model_path, num_labels):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = BertHANModel(num_labels=num_labels)\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "def calculate_f1(y_pred, y_true):\n",
        "    y_true = y_true.view(-1)\n",
        "    y_pred = y_pred.view(-1)\n",
        "    y_true = y_true.detach().cpu().numpy()\n",
        "    y_pred = y_pred.detach().cpu().numpy()\n",
        "    mask = np.where(y_true != 0)\n",
        "    y_true = y_true[mask]\n",
        "    y_pred = y_pred[mask]\n",
        "    return y_pred, y_true\n",
        "\n",
        "def TagConvert(raw_tags, words_set, poss=None):\n",
        "    true_tags = []\n",
        "    for i in range(raw_tags.shape[0]):\n",
        "        kw_list = []\n",
        "        nkw_list = \"\"\n",
        "        for j in range(len(raw_tags[i])):\n",
        "            item = raw_tags[i][j]\n",
        "            if item == 0:\n",
        "                continue\n",
        "            if poss != None and j in poss[i]:\n",
        "                continue\n",
        "            if item == 4:\n",
        "                kw_list.append(str(words_set[j][i]))\n",
        "            if item == 1:\n",
        "                nkw_list += str(words_set[j][i])\n",
        "            if item == 2:\n",
        "                nkw_list += \" \"\n",
        "                nkw_list += str(words_set[j][i])\n",
        "            if item == 3:\n",
        "                nkw_list += \" \"\n",
        "                nkw_list += str(words_set[j][i])\n",
        "                kw_list.append(nkw_list)\n",
        "                nkw_list = \"\"\n",
        "        true_tags.append(kw_list)\n",
        "    return true_tags\n",
        "\n",
        "def evaluate(predict_data, target_data, topk=3):\n",
        "    TRUE_COUNT, PRED_COUNT, GOLD_COUNT = 0.0, 0.0, 0.0\n",
        "    for index, words in enumerate(predict_data):\n",
        "        y_pred, y_true = None, target_data[index]\n",
        "        if type(predict_data) == str:\n",
        "            words = sorted(words.items(), key=lambda item: (-item[1], item[0]))\n",
        "            y_pred = [i[0] for i in words]\n",
        "        elif type(predict_data) == list:\n",
        "            y_pred = words\n",
        "        y_pred = y_pred[0: topk]\n",
        "        TRUE_NUM = len(set(y_pred) & set(y_true))\n",
        "        TRUE_COUNT += TRUE_NUM\n",
        "        PRED_COUNT += len(y_pred)\n",
        "        GOLD_COUNT += len(y_true)\n",
        "    if PRED_COUNT != 0:\n",
        "        p = (TRUE_COUNT / PRED_COUNT)\n",
        "    else:\n",
        "        p = 0\n",
        "    if GOLD_COUNT != 0:\n",
        "        r = (TRUE_COUNT / GOLD_COUNT)\n",
        "    else:\n",
        "        r = 0\n",
        "    if (r + p) != 0:\n",
        "        f1 = ((2 * r * p) / (r + p))\n",
        "    else:\n",
        "        f1 = 0\n",
        "    p = round(p * 100, 2)\n",
        "    r = round(r * 100, 2)\n",
        "    f1 = round(f1 * 100, 2)\n",
        "    return p, r, f1\n",
        "\n",
        "def predict_and_evaluate(model, dataloader):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    label_true, label_pred = [], []\n",
        "    kw_true, kw_pred = [], []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_masks = batch[1].to(device)\n",
        "            tokens = batch[2]  # tokens 不是 Tensor，直接使用\n",
        "            features = batch[3].to(device)\n",
        "            tags = batch[4].to(device)\n",
        "\n",
        "            pred_tags = model(input_ids, attention_masks,features)\n",
        "            pred_tags = torch.argmax(pred_tags, dim=-1)\n",
        "\n",
        "            y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "            label_true.extend(y_true)\n",
        "            label_pred.extend(y_pred)\n",
        "\n",
        "            poss = []\n",
        "            for i in range(len(tags)):\n",
        "                pos = []\n",
        "                for j in range(len(tags[i])):\n",
        "                    if tags[i][j] == 0:\n",
        "                        pos.append(j)\n",
        "                poss.append(pos)\n",
        "            kw_true.extend(TagConvert(tags, tokens))\n",
        "            kw_pred.extend(TagConvert(pred_tags, tokens, poss))\n",
        "\n",
        "    label_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "    P, R, F1 = evaluate(kw_true, kw_pred)\n",
        "    return label_f1, P, R, F1\n",
        "\n",
        "# 加载模型\n",
        "model_path = './pretrain_pt/bert_HAtten_EGG.pt'\n",
        "num_labels = 6\n",
        "model = load_model(model_path, num_labels)\n",
        "\n",
        "# 假设 test_dataloader 已经定义好\n",
        "label_f1, P, R, F1 = predict_and_evaluate(model, test_dataloader)\n",
        "\n",
        "print(f\"label_f1: {label_f1:.2f}, Precision: {P:.2f}, Recall: {R:.2f}, F1: {F1:.2f}\")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "4Frqt1FDCBYz",
        "outputId": "b1fc894b-6542-4540-edbe-e456ecf81b90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "####################层注意力+不同EEG组合"
      ],
      "metadata": {
        "id": "ea8r-dKiLhev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "from transformers import BertModel\n",
        "from torch import nn\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "from transformers import BertModel\n",
        "from torch import nn\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "# 定义 Attention 机制\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(Attention, self).__init__()\n",
        "        self.context = nn.Parameter(torch.FloatTensor(hidden_dim, 1))\n",
        "        nn.init.xavier_uniform_(self.context)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        attention_in = torch.tanh(torch.matmul(x, self.context))\n",
        "        attention_in = torch.squeeze(attention_in, -1)\n",
        "        if mask is not None:\n",
        "            attention_in = attention_in * mask.float()\n",
        "        attention_weights = F.softmax(attention_in, dim=-1)\n",
        "        weighted_sum = torch.bmm(attention_weights.unsqueeze(1), x).squeeze(1)\n",
        "        return weighted_sum\n",
        "\n",
        "# 定义 BertHANModel\n",
        "class BertHANModel(nn.Module):\n",
        "    def __init__(self, num_labels, hidden_dim=768, rnn_dim=256, eeg_dim=8):\n",
        "        super(BertHANModel, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.word_attention = Attention(hidden_dim)\n",
        "        self.rnn = nn.GRU(hidden_dim, rnn_dim, batch_first=True, bidirectional=True)\n",
        "        self.sentence_attention = Attention(rnn_dim * 2)\n",
        "        self.classifier = nn.Linear(rnn_dim * 2 + eeg_dim, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, extra_features):\n",
        "        bert_outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        sequence_output = bert_outputs[0]  # shape: (batch_size, seq_length, hidden_dim)\n",
        "\n",
        "        # Word-level attention\n",
        "        word_attention_output = self.word_attention(sequence_output)\n",
        "\n",
        "        # Sentence-level GRU\n",
        "        rnn_output, _ = self.rnn(word_attention_output.unsqueeze(1))\n",
        "\n",
        "        # Sentence-level attention\n",
        "        sentence_attention_output = self.sentence_attention(rnn_output)\n",
        "\n",
        "        # 确保 sentence_attention_output 是三维张量\n",
        "        if sentence_attention_output.dim() == 2:\n",
        "            sentence_attention_output = sentence_attention_output.unsqueeze(1).expand(-1, extra_features.size(1), -1)\n",
        "\n",
        "        # 拼接特征\n",
        "        combined_output = torch.cat((sentence_attention_output, extra_features), dim=-1)  # [batch_size, seq_len, rnn_dim * 2 + eeg_dim]\n",
        "\n",
        "        logits = self.classifier(combined_output)  # shape: (batch_size, seq_len, num_labels)\n",
        "\n",
        "        return logits  # 返回 shape: (batch_size, seq_length, num_labels)\n",
        "\n",
        "# 根据 EEG 组合标签获取相应的维度索引\n",
        "def get_eeg_dim(combo):\n",
        "    mappings = {\n",
        "        'EEG1': (0, 1),\n",
        "        'EEG2': (1, 2),\n",
        "        'EEG3': (2, 3),\n",
        "        'EEG4': (3, 4),\n",
        "        'EEG5': (4, 5),\n",
        "        'EEG6': (5, 6),\n",
        "        'EEG7': (6, 7),\n",
        "        'EEG8': (7, 8),\n",
        "        'EEG1.2': (0, 2),\n",
        "        'EEG2.3': (1, 3),\n",
        "        'EEG3.4': (2, 4),\n",
        "        'EEG4.5': (3, 5),\n",
        "        'EEG5.6': (4, 6),\n",
        "        'EEG6.7': (5, 7),\n",
        "        'EEG7.8': (6, 8),\n",
        "    }\n",
        "    return mappings[combo]\n",
        "\n",
        "# 训练和评估函数\n",
        "def train_and_evaluate(eeg_combo):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    eeg_start, eeg_end = get_eeg_dim(eeg_combo)\n",
        "    eeg_dim = eeg_end - eeg_start\n",
        "\n",
        "    model = BertHANModel(num_labels=6, eeg_dim=eeg_dim)\n",
        "    model = model.to(device)\n",
        "    optim = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=1e-2)\n",
        "    loss_fn = nn.CrossEntropyLoss(reduction='none', ignore_index=0)\n",
        "    loss_fn = loss_fn.to(device)\n",
        "\n",
        "    epochs = 3\n",
        "    best_f1 = 0.0\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        loss_value = 0.0\n",
        "        model.train()\n",
        "        label_true, label_pred = [], []\n",
        "        for i, batch in enumerate(train_dataloader):\n",
        "            optim.zero_grad()\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_masks = batch[1].to(device)\n",
        "            features = batch[3][:, :, eeg_start:eeg_end].to(device)\n",
        "            tags = batch[4].to(device)\n",
        "\n",
        "            with autocast():\n",
        "                pred_tags = model(input_ids, attention_masks, features)\n",
        "\n",
        "                # 展平 pred_tags 和 tags 以匹配形状\n",
        "                pred_tags = pred_tags.reshape(-1, pred_tags.size(-1))\n",
        "                tags = tags.reshape(-1)\n",
        "\n",
        "                loss = loss_fn(pred_tags, tags)\n",
        "                loss = loss.mean()\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optim)\n",
        "            scaler.update()\n",
        "\n",
        "            pred_tags = F.softmax(pred_tags, dim=-1)\n",
        "            pred_tags = torch.argmax(pred_tags, dim=-1)\n",
        "            y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "            label_true.extend(y_true)\n",
        "            label_pred.extend(y_pred)\n",
        "            loss_value += loss.item()\n",
        "\n",
        "        label_train_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "\n",
        "        model.eval()\n",
        "        kw_true, kw_pred = [], []\n",
        "        label_true, label_pred = [], []\n",
        "        for i, batch in enumerate(test_dataloader):\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_masks = batch[1].to(device)\n",
        "            tokens = batch[2]  # tokens 不是 Tensor，直接使用\n",
        "            features = batch[3][:, :, eeg_start:eeg_end].to(device)\n",
        "            tags = batch[4].to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for module in model.modules():\n",
        "                    if isinstance(module, nn.Dropout):\n",
        "                        module.p = 0\n",
        "                        module.train(False)\n",
        "                with autocast():\n",
        "                    pred_tags = model(input_ids, attention_masks, features)\n",
        "                    pred_tags = F.softmax(pred_tags, dim=-1)\n",
        "                    pred_tags = torch.argmax(pred_tags, dim=-1)\n",
        "\n",
        "            y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "            label_true.extend(y_true)\n",
        "            label_pred.extend(y_pred)\n",
        "\n",
        "            poss = []\n",
        "            for i in range(len(tags)):\n",
        "                pos = []\n",
        "                for j in range(len(tags[i])):\n",
        "                    if tags[i][j] == 0:\n",
        "                        pos.append(j)\n",
        "                poss.append(pos)\n",
        "\n",
        "            kw_true.extend(TagConvert(tags, tokens))\n",
        "            kw_pred.extend(TagConvert(pred_tags, tokens, poss))\n",
        "\n",
        "        label_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "        P, R, F1 = evaluate(kw_true, kw_pred)\n",
        "\n",
        "        # if F1 > best_f1:\n",
        "        #     best_f1 = F1\n",
        "        #     torch.save(model.state_dict(), f'/content/drive/MyDrive/ner/pretrain_pt/bert_HAtten_{eeg_combo}.pt')\n",
        "\n",
        "        print(f\"epoch {epoch + 1}: loss: {loss_value / len(train_dataloader):.2f} train_f1: {label_train_f1:.2f} test_f1: {label_f1:.2f} kw_f1: {F1:.2f}\")\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return P, R, F1\n",
        "\n",
        "# 使用不同的 EEG 组合进行训练和评估\n",
        "eeg_combos = ['EEG1', 'EEG2', 'EEG3', 'EEG4', 'EEG5', 'EEG6', 'EEG7', 'EEG8',\n",
        "              'EEG1.2', 'EEG2.3', 'EEG3.4', 'EEG4.5', 'EEG5.6', 'EEG6.7', 'EEG7.8']\n",
        "\n",
        "for eeg_combo in eeg_combos:\n",
        "    print(f\"Training with EEG combo: {eeg_combo}\")\n",
        "    P, R, F1 = train_and_evaluate(eeg_combo)\n",
        "    print(f\"EEG combo: {eeg_combo} - Precision: {P:.2f}, Recall: {R:.2f}, F1 Score: {F1:.2f}\")\n"
      ],
      "metadata": {
        "id": "HZMPAOPfLlN1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ac6c07c-fd13-4f1c-8e74-34d4d61f5810"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with EEG combo: EEG1\n",
            "epoch 1: loss: 0.29 train_f1: 0.16 test_f1: 0.21 kw_f1: 0.10\n",
            "epoch 2: loss: 0.26 train_f1: 0.20 test_f1: 0.19 kw_f1: 0.09\n",
            "epoch 3: loss: 0.25 train_f1: 0.20 test_f1: 0.21 kw_f1: 0.17\n",
            "EEG combo: EEG1 - Precision: 0.09, Recall: 23.98, F1 Score: 0.17\n",
            "Training with EEG combo: EEG2\n",
            "epoch 1: loss: 0.29 train_f1: 0.19 test_f1: 0.24 kw_f1: 0.09\n",
            "epoch 2: loss: 0.26 train_f1: 0.20 test_f1: 0.21 kw_f1: 0.07\n",
            "epoch 3: loss: 0.25 train_f1: 0.20 test_f1: 0.21 kw_f1: 0.11\n",
            "EEG combo: EEG2 - Precision: 0.06, Recall: 18.12, F1 Score: 0.11\n",
            "Training with EEG combo: EEG3\n",
            "epoch 1: loss: 0.29 train_f1: 0.16 test_f1: 0.19 kw_f1: 0.41\n",
            "epoch 2: loss: 0.26 train_f1: 0.20 test_f1: 0.21 kw_f1: 0.13\n",
            "epoch 3: loss: 0.25 train_f1: 0.20 test_f1: 0.21 kw_f1: 0.13\n",
            "EEG combo: EEG3 - Precision: 0.07, Recall: 12.65, F1 Score: 0.13\n",
            "Training with EEG combo: EEG4\n",
            "epoch 1: loss: 0.29 train_f1: 0.16 test_f1: 0.23 kw_f1: 0.11\n",
            "epoch 2: loss: 0.26 train_f1: 0.20 test_f1: 0.22 kw_f1: 0.31\n",
            "epoch 3: loss: 0.25 train_f1: 0.20 test_f1: 0.20 kw_f1: 0.31\n",
            "EEG combo: EEG4 - Precision: 0.15, Recall: 26.15, F1 Score: 0.31\n",
            "Training with EEG combo: EEG5\n",
            "epoch 1: loss: 0.29 train_f1: 0.16 test_f1: 0.21 kw_f1: 0.96\n",
            "epoch 2: loss: 0.26 train_f1: 0.20 test_f1: 0.19 kw_f1: 0.36\n",
            "epoch 3: loss: 0.25 train_f1: 0.20 test_f1: 0.23 kw_f1: 0.17\n",
            "EEG combo: EEG5 - Precision: 0.08, Recall: 20.73, F1 Score: 0.17\n",
            "Training with EEG combo: EEG6\n",
            "epoch 1: loss: 0.29 train_f1: 0.16 test_f1: 0.24 kw_f1: 0.55\n",
            "epoch 2: loss: 0.26 train_f1: 0.20 test_f1: 0.19 kw_f1: 0.53\n",
            "epoch 3: loss: 0.25 train_f1: 0.20 test_f1: 0.22 kw_f1: 0.67\n",
            "EEG combo: EEG6 - Precision: 0.34, Recall: 32.60, F1 Score: 0.67\n",
            "Training with EEG combo: EEG7\n",
            "epoch 1: loss: 0.29 train_f1: 0.16 test_f1: 0.19 kw_f1: 0.77\n",
            "epoch 2: loss: 0.26 train_f1: 0.20 test_f1: 0.23 kw_f1: 0.59\n",
            "epoch 3: loss: 0.25 train_f1: 0.20 test_f1: 0.19 kw_f1: 0.26\n",
            "EEG combo: EEG7 - Precision: 0.13, Recall: 28.25, F1 Score: 0.26\n",
            "Training with EEG combo: EEG8\n",
            "epoch 1: loss: 0.29 train_f1: 0.20 test_f1: 0.19 kw_f1: 0.14\n",
            "epoch 2: loss: 0.26 train_f1: 0.20 test_f1: 0.18 kw_f1: 0.05\n",
            "epoch 3: loss: 0.25 train_f1: 0.20 test_f1: 0.21 kw_f1: 0.08\n",
            "EEG combo: EEG8 - Precision: 0.04, Recall: 31.25, F1 Score: 0.08\n",
            "Training with EEG combo: EEG1.2\n",
            "epoch 1: loss: 0.29 train_f1: 0.16 test_f1: 0.21 kw_f1: 0.03\n",
            "epoch 2: loss: 0.26 train_f1: 0.20 test_f1: 0.22 kw_f1: 0.06\n",
            "epoch 3: loss: 0.25 train_f1: 0.20 test_f1: 0.19 kw_f1: 0.20\n",
            "EEG combo: EEG1.2 - Precision: 0.10, Recall: 25.13, F1 Score: 0.20\n",
            "Training with EEG combo: EEG2.3\n",
            "epoch 1: loss: 0.29 train_f1: 0.16 test_f1: 0.24 kw_f1: 0.07\n",
            "epoch 2: loss: 0.26 train_f1: 0.20 test_f1: 0.19 kw_f1: 0.21\n",
            "epoch 3: loss: 0.25 train_f1: 0.20 test_f1: 0.22 kw_f1: 0.95\n",
            "EEG combo: EEG2.3 - Precision: 0.48, Recall: 39.49, F1 Score: 0.95\n",
            "Training with EEG combo: EEG3.4\n",
            "epoch 1: loss: 0.29 train_f1: 0.16 test_f1: 0.23 kw_f1: 0.08\n",
            "epoch 2: loss: 0.26 train_f1: 0.20 test_f1: 0.21 kw_f1: 0.21\n",
            "epoch 3: loss: 0.25 train_f1: 0.20 test_f1: 0.19 kw_f1: 0.66\n",
            "EEG combo: EEG3.4 - Precision: 0.33, Recall: 42.44, F1 Score: 0.66\n",
            "Training with EEG combo: EEG4.5\n",
            "epoch 1: loss: 0.29 train_f1: 0.20 test_f1: 0.21 kw_f1: 0.53\n",
            "epoch 2: loss: 0.26 train_f1: 0.20 test_f1: 0.21 kw_f1: 0.14\n",
            "epoch 3: loss: 0.25 train_f1: 0.20 test_f1: 0.19 kw_f1: 0.15\n",
            "EEG combo: EEG4.5 - Precision: 0.07, Recall: 15.65, F1 Score: 0.15\n",
            "Training with EEG combo: EEG5.6\n",
            "epoch 1: loss: 0.29 train_f1: 0.17 test_f1: 0.21 kw_f1: 0.05\n",
            "epoch 2: loss: 0.26 train_f1: 0.20 test_f1: 0.21 kw_f1: 0.14\n",
            "epoch 3: loss: 0.25 train_f1: 0.20 test_f1: 0.22 kw_f1: 0.23\n",
            "EEG combo: EEG5.6 - Precision: 0.12, Recall: 16.42, F1 Score: 0.23\n",
            "Training with EEG combo: EEG6.7\n",
            "epoch 1: loss: 0.29 train_f1: 0.16 test_f1: 0.21 kw_f1: 0.07\n",
            "epoch 2: loss: 0.26 train_f1: 0.20 test_f1: 0.19 kw_f1: 0.50\n",
            "epoch 3: loss: 0.25 train_f1: 0.20 test_f1: 0.21 kw_f1: 0.43\n",
            "EEG combo: EEG6.7 - Precision: 0.22, Recall: 41.18, F1 Score: 0.43\n",
            "Training with EEG combo: EEG7.8\n",
            "epoch 1: loss: 0.29 train_f1: 0.16 test_f1: 0.19 kw_f1: 0.75\n",
            "epoch 2: loss: 0.26 train_f1: 0.20 test_f1: 0.21 kw_f1: 0.11\n",
            "epoch 3: loss: 0.25 train_f1: 0.20 test_f1: 0.21 kw_f1: 0.11\n",
            "EEG combo: EEG7.8 - Precision: 0.06, Recall: 21.60, F1 Score: 0.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KnblJcb1baOL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "XRT8rWFHCBY6"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b8af14f01e5d4f3b96a05167f86233a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6f38b1988e74412a05211bd9523a6fe",
              "IPY_MODEL_a623560865bb47339268de61b861e43b",
              "IPY_MODEL_873295fa124d47389dfc2e387f7aa10a"
            ],
            "layout": "IPY_MODEL_e43f232aac20451a87e9ae63e7b3b0da"
          }
        },
        "f6f38b1988e74412a05211bd9523a6fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b193bbb04104bb0b1ac907111c089a3",
            "placeholder": "​",
            "style": "IPY_MODEL_caa438e1404b4b9f88f3c80fd5e1ced8",
            "value": "model.safetensors: 100%"
          }
        },
        "a623560865bb47339268de61b861e43b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0490cf0dd3674d1e9574411c761a3652",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b5741ab66034422a1f231b193c39dd3",
            "value": 440449768
          }
        },
        "873295fa124d47389dfc2e387f7aa10a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24708855f74c4e9f9b8196338c2507aa",
            "placeholder": "​",
            "style": "IPY_MODEL_740636a0c06e49d2945e036c08c0c7f1",
            "value": " 440M/440M [00:02&lt;00:00, 233MB/s]"
          }
        },
        "e43f232aac20451a87e9ae63e7b3b0da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b193bbb04104bb0b1ac907111c089a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "caa438e1404b4b9f88f3c80fd5e1ced8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0490cf0dd3674d1e9574411c761a3652": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b5741ab66034422a1f231b193c39dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24708855f74c4e9f9b8196338c2507aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "740636a0c06e49d2945e036c08c0c7f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "945b98f99ede48ecb3aca429df5da57e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_360758de4b93457ebbf180823e870062",
              "IPY_MODEL_4027763e947c4b34b94c03a2e6f2206a",
              "IPY_MODEL_c3dccc6931494ee098cb94f9a506ef67"
            ],
            "layout": "IPY_MODEL_96776ed4b3664a5199f05deca2e5cd41"
          }
        },
        "360758de4b93457ebbf180823e870062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90adcf69ca68454bbae6264746f2fe3f",
            "placeholder": "​",
            "style": "IPY_MODEL_af25c31158524dc5b9879e8e4036dc26",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "4027763e947c4b34b94c03a2e6f2206a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4e6e03a78354ef0b5ab792083c94520",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ecbe78157a44ecd97ad51a4784af224",
            "value": 48
          }
        },
        "c3dccc6931494ee098cb94f9a506ef67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc47f2a155c84369914dde7e7d4edf08",
            "placeholder": "​",
            "style": "IPY_MODEL_540cd3e641ae4870b703dc88b7b92a27",
            "value": " 48.0/48.0 [00:00&lt;00:00, 3.30kB/s]"
          }
        },
        "96776ed4b3664a5199f05deca2e5cd41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90adcf69ca68454bbae6264746f2fe3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af25c31158524dc5b9879e8e4036dc26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4e6e03a78354ef0b5ab792083c94520": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ecbe78157a44ecd97ad51a4784af224": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc47f2a155c84369914dde7e7d4edf08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "540cd3e641ae4870b703dc88b7b92a27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c15521aec7d64dbcb80f33082bb1a5dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b1ba10ec06d2405aa3dab05f610e4c52",
              "IPY_MODEL_039a5fd5f9304ca3a326513ca3883546",
              "IPY_MODEL_18031af146b74f538bd65fb8f7d7ed9a"
            ],
            "layout": "IPY_MODEL_248859323fa34af89ddbfad52dc70be2"
          }
        },
        "b1ba10ec06d2405aa3dab05f610e4c52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42b737d16c954242bdc770b6121e6d4a",
            "placeholder": "​",
            "style": "IPY_MODEL_f3c41eeca33c472db5a476ca5d558802",
            "value": "vocab.txt: 100%"
          }
        },
        "039a5fd5f9304ca3a326513ca3883546": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19c28ea5e428451bbf526787ddea8f71",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23a44a7e5f4c4467b37b12745a973407",
            "value": 231508
          }
        },
        "18031af146b74f538bd65fb8f7d7ed9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3dac01bfe2d4aa48f2fb92dacbe3bfc",
            "placeholder": "​",
            "style": "IPY_MODEL_1b3d7ea36c394184aca348775a6864d5",
            "value": " 232k/232k [00:00&lt;00:00, 1.74MB/s]"
          }
        },
        "248859323fa34af89ddbfad52dc70be2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42b737d16c954242bdc770b6121e6d4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3c41eeca33c472db5a476ca5d558802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19c28ea5e428451bbf526787ddea8f71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23a44a7e5f4c4467b37b12745a973407": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3dac01bfe2d4aa48f2fb92dacbe3bfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b3d7ea36c394184aca348775a6864d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81d7805874804829825d50a7110d94a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b689e41d39747339b9ea8bc3b407d25",
              "IPY_MODEL_28f899e1c7ed48dab5a586d3dcec3b24",
              "IPY_MODEL_c7be6a223e9a45248db8fa1449f1b3a1"
            ],
            "layout": "IPY_MODEL_25b238cae5634089aa41334d480d3076"
          }
        },
        "9b689e41d39747339b9ea8bc3b407d25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58302cb84195455f9dfc76619121256c",
            "placeholder": "​",
            "style": "IPY_MODEL_5355e1ba66034d0d9cd65e055ed43f17",
            "value": "tokenizer.json: 100%"
          }
        },
        "28f899e1c7ed48dab5a586d3dcec3b24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0255df3e4aa44369ad3ddc1d70517cc8",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fce4c0fca41e4aeaa21a259c781ff8b5",
            "value": 466062
          }
        },
        "c7be6a223e9a45248db8fa1449f1b3a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5113aa0374fc48bab5caf8153ecb1b64",
            "placeholder": "​",
            "style": "IPY_MODEL_ca61bf2e1a854163b40ce33009729d62",
            "value": " 466k/466k [00:00&lt;00:00, 27.5MB/s]"
          }
        },
        "25b238cae5634089aa41334d480d3076": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58302cb84195455f9dfc76619121256c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5355e1ba66034d0d9cd65e055ed43f17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0255df3e4aa44369ad3ddc1d70517cc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fce4c0fca41e4aeaa21a259c781ff8b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5113aa0374fc48bab5caf8153ecb1b64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca61bf2e1a854163b40ce33009729d62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7e981cad9be42b89dd6666a34dc4a66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ebdda8bf02174e38b974abed47926294",
              "IPY_MODEL_5cf99467cd6e4467922e44ccc68445bc",
              "IPY_MODEL_48e3ad9de87c4877bd2d4d78abf4d9a3"
            ],
            "layout": "IPY_MODEL_74789379eeef407fa217fb7f28575ab1"
          }
        },
        "ebdda8bf02174e38b974abed47926294": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ed3345c3749498b96303007e234698d",
            "placeholder": "​",
            "style": "IPY_MODEL_fdc0623c4b3946ea90ff797c9326c838",
            "value": "config.json: 100%"
          }
        },
        "5cf99467cd6e4467922e44ccc68445bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01893e988b754e12a84238b5807379b1",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3378d101e6ca43889ef2eb928b30cf4e",
            "value": 570
          }
        },
        "48e3ad9de87c4877bd2d4d78abf4d9a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58f0d6e3b01b4e95a9935e7fc738bd27",
            "placeholder": "​",
            "style": "IPY_MODEL_b614196c78b741749c2bc32a50418a90",
            "value": " 570/570 [00:00&lt;00:00, 36.4kB/s]"
          }
        },
        "74789379eeef407fa217fb7f28575ab1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ed3345c3749498b96303007e234698d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdc0623c4b3946ea90ff797c9326c838": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01893e988b754e12a84238b5807379b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3378d101e6ca43889ef2eb928b30cf4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "58f0d6e3b01b4e95a9935e7fc738bd27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b614196c78b741749c2bc32a50418a90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81772882fbfd4f3aa27a0c6aa50a2112": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb5679d7a63c430780cf7ccee329bde0",
              "IPY_MODEL_01e746ea30a44cf799c638b8cc09c9f3",
              "IPY_MODEL_ded9692e85bb4599a963a15d242af1ae"
            ],
            "layout": "IPY_MODEL_ba0c10620d08463f9804d3e6c52aa603"
          }
        },
        "bb5679d7a63c430780cf7ccee329bde0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df29793c486b47e38a38ff25f715f89a",
            "placeholder": "​",
            "style": "IPY_MODEL_eee0775404df44298b59b094ebe013b8",
            "value": "model.safetensors: 100%"
          }
        },
        "01e746ea30a44cf799c638b8cc09c9f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db899ebfd20344869f0590da9b2903ac",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db3c721915b44a0181765c350aa3f5eb",
            "value": 440449768
          }
        },
        "ded9692e85bb4599a963a15d242af1ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0e2bd24016642a588a7e4b53a04c8df",
            "placeholder": "​",
            "style": "IPY_MODEL_43688966bc1348e08caf09eb3f510afd",
            "value": " 440M/440M [00:06&lt;00:00, 137MB/s]"
          }
        },
        "ba0c10620d08463f9804d3e6c52aa603": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df29793c486b47e38a38ff25f715f89a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eee0775404df44298b59b094ebe013b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db899ebfd20344869f0590da9b2903ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db3c721915b44a0181765c350aa3f5eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d0e2bd24016642a588a7e4b53a04c8df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43688966bc1348e08caf09eb3f510afd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}