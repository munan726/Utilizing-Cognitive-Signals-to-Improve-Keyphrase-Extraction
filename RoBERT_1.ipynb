{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WV2VL3c_30ei"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "import torch\n",
        "from transformers import BertModel, BertTokenizerFast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YelXxWu30ek"
      },
      "outputs": [],
      "source": [
        "weight = 'bert-base-uncased'\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "max_len = 35"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkA1uPWqAmUA"
      },
      "outputs": [],
      "source": [
        "weight = 'bert-base-uncased'\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "max_len = 35\n",
        "import json\n",
        "\n",
        "train_path = '/content/drive/MyDrive/ner/datas/Election-Trec/train.json'\n",
        "# train_path = '../datas/daily life/train.json'\n",
        "test_path = '/content/drive/MyDrive/ner/datas/Election-Trec/test.json'\n",
        "# test_path = '../datas/daily life/test.json'\n",
        "\n",
        "train_file = json.load(open(train_path,'r',encoding='utf-8'))\n",
        "test_file = json.load(open(test_path, 'r', encoding='utf-8'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwhPsxYX30el"
      },
      "source": [
        "#### load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1YYHvA-30em"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "train_path = '/content/drive/MyDrive/ner/datas/Election-Trec/train.json'\n",
        "# train_path = '../datas/daily life/train.json'\n",
        "test_path = '/content/drive/MyDrive/ner/datas/Election-Trec/test.json'\n",
        "# test_path = '../datas/daily life/test.json'\n",
        "\n",
        "train_file = json.load(open(train_path,'r',encoding='utf-8'))\n",
        "test_file = json.load(open(test_path, 'r', encoding='utf-8'))\n",
        "# Append all words, eye-tracking signals, EEG signals and tags from training json to list\n",
        "train_sens, train_tags = [],[]\n",
        "train_Feature = []\n",
        "train_word_nums = []\n",
        "\n",
        "sens = ''\n",
        "nums = 0\n",
        "for key in train_file.keys():\n",
        "    tags = []\n",
        "    features = []\n",
        "    items = train_file[key]\n",
        "    sens = ''\n",
        "    nums = 0\n",
        "    for item in items:\n",
        "        sens += item[0]\n",
        "        sens += ' '\n",
        "        features.append(item[1:-1])               # ET+EEG: [1: -1]\n",
        "        tags.append(item[-1])\n",
        "        nums += 1\n",
        "    train_sens.append(sens.strip())\n",
        "    train_word_nums.append(nums)\n",
        "    train_Feature.append(features)\n",
        "    train_tags.append(tags)\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(weight)\n",
        "label_to_ids = {'none': 0, 'B': 1, 'I': 2, 'E': 3, 'S': 4, \"O\": 5}\n",
        "# label_to_ids = {'O': 0, 'B': 1, 'I': 2, 'E': 3, 'S': 4}\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, texts, old_features, tags):\n",
        "        self.texts = texts\n",
        "        self.tags = tags\n",
        "        self.old_features = old_features\n",
        "\n",
        "        self.labels = []\n",
        "        self.tokens = []\n",
        "        self.features = []\n",
        "\n",
        "        self.input_ids = None\n",
        "        self.attention_masks = None\n",
        "\n",
        "    def encode(self):\n",
        "        for i in tqdm(range(len(self.texts))):\n",
        "          text = self.texts[i]\n",
        "          tag = self.tags[i]\n",
        "          feature = self.old_features[i]\n",
        "          tags, tokens, features = align_label(text, tag, feature)\n",
        "          self.labels.append(tags)\n",
        "          self.tokens.append(tokens)\n",
        "          self.features.append(features)\n",
        "\n",
        "        self.features = np.array(self.features,float)\n",
        "        self.inputs = tokenizer(self.texts, max_length=max_len, add_special_tokens=True, padding='max_length', truncation=True, return_tensors='pt')\n",
        "        self.input_ids = self.inputs['input_ids']\n",
        "        self.attention_masks = self.inputs['attention_mask']\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx,:], self.attention_masks[idx,:], self.tokens[idx], torch.tensor(self.features[idx],dtype=torch.float32), torch.tensor(self.labels[idx])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "\n",
        "label_all_tokens = True\n",
        "\n",
        "\n",
        "def align_label(text, labels, features):\n",
        "    input = tokenizer(text, max_length=max_len, add_special_tokens=True, padding='max_length', truncation=True, return_tensors='pt')\n",
        "    word_ids = input.word_ids()\n",
        "    input_ids = input['input_ids']\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "\n",
        "    previous_word_idx = None\n",
        "    new_labels, new_features = [], []\n",
        "    no_features = [0 for _ in range(1, 26)]\n",
        "\n",
        "    for word_idx in word_ids:\n",
        "        if word_idx is None:\n",
        "            new_labels.append('none')\n",
        "            new_features.append(no_features)\n",
        "        elif word_idx != previous_word_idx:\n",
        "            try:\n",
        "                new_labels.append(labels[word_idx])\n",
        "                new_features.append(features[word_idx])\n",
        "            except:\n",
        "                new_labels.append('none')\n",
        "                new_features.append(no_features)\n",
        "        else:\n",
        "            try:\n",
        "                new_labels.append(labels[word_idx] if label_all_tokens else 'none')\n",
        "                new_features.append(features[word_idx] if label_all_tokens else no_features)\n",
        "            except:\n",
        "                new_labels.append('none')\n",
        "                new_features.append(no_features)\n",
        "        previous_word_idx = word_idx\n",
        "\n",
        "    label_ids = [label_to_ids[label] for label in new_labels]\n",
        "    return label_ids, tokens, new_features\n",
        "\n",
        "train_dataset = MyDataset(train_sens, train_Feature, train_tags)\n",
        "train_dataset.encode()\n",
        "\n",
        "\n",
        "test_dataset = MyDataset(test_sens, test_Feature, test_tags)\n",
        "test_dataset.encode()\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=128)\n",
        "test_dataloader = DataLoader(test_dataset, shuffle=True, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TA5RBljv30en"
      },
      "outputs": [],
      "source": [
        "# Append all words, eye-tracking signals, EEG signals and tags from training json to list\n",
        "train_sens, train_tags = [],[]\n",
        "train_Feature = []\n",
        "train_word_nums = []\n",
        "\n",
        "sens = ''\n",
        "nums = 0\n",
        "for key in train_file.keys():\n",
        "    tags = []\n",
        "    features = []\n",
        "    items = train_file[key]\n",
        "    sens = ''\n",
        "    nums = 0\n",
        "    for item in items:\n",
        "        sens += item[0]\n",
        "        sens += ' '\n",
        "        features.append(item[1:-1])               # ET+EEG: [1: -1]\n",
        "        tags.append(item[-1])\n",
        "        nums += 1\n",
        "    train_sens.append(sens.strip())\n",
        "    train_word_nums.append(nums)\n",
        "    train_Feature.append(features)\n",
        "    train_tags.append(tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGwyUNAB34v4",
        "outputId": "eff389fc-1e47-4197-e0f7-051754dceac0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbD357xA30eo"
      },
      "outputs": [],
      "source": [
        "# Append all words, eye-tracking signals, EEG signals and tags from testing json to list\n",
        "test_sens, test_tags = [],[]\n",
        "test_Feature = []\n",
        "test_word_nums = []\n",
        "\n",
        "sens = ''\n",
        "nums = 0\n",
        "for key in test_file.keys():\n",
        "    tags = []\n",
        "    features = []\n",
        "    items = test_file[key]\n",
        "    sens = ''\n",
        "    nums = 0\n",
        "    for item in items:\n",
        "        sens += item[0]\n",
        "        sens += ' '\n",
        "        features.append(item[1:-1])                # ET+EEG: [1: -1]\n",
        "        tags.append(item[-1])\n",
        "        nums += 1\n",
        "    test_sens.append(sens.strip())\n",
        "    test_word_nums.append(nums)\n",
        "    test_Feature.append(features)\n",
        "    test_tags.append(tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MySdNpjj30eo"
      },
      "outputs": [],
      "source": [
        "len(test_sens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mED9TvYz30eq"
      },
      "source": [
        "#### build dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1reUtm530eq"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejyw3ik330er"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained(weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dtYleMZ30er"
      },
      "outputs": [],
      "source": [
        "label_to_ids = {'none': 0, 'B': 1, 'I': 2, 'E': 3, 'S': 4, \"O\": 5}\n",
        "# label_to_ids = {'O': 0, 'B': 1, 'I': 2, 'E': 3, 'S': 4}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGeQuPBT30es"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, texts, old_features, tags):\n",
        "        self.texts = texts\n",
        "        self.tags = tags\n",
        "        self.old_features = old_features\n",
        "\n",
        "        self.labels = []\n",
        "        self.tokens = []\n",
        "        self.features = []\n",
        "\n",
        "        self.input_ids = None\n",
        "        self.attention_masks = None\n",
        "\n",
        "    def encode(self):\n",
        "        for i in tqdm(range(len(self.texts))):\n",
        "          text = self.texts[i]\n",
        "          tag = self.tags[i]\n",
        "          feature = self.old_features[i]\n",
        "          tags, tokens, features = align_label(text, tag, feature)\n",
        "          self.labels.append(tags)\n",
        "          self.tokens.append(tokens)\n",
        "          self.features.append(features)\n",
        "\n",
        "        self.features = np.array(self.features,float)\n",
        "        self.inputs = tokenizer(self.texts, max_length=max_len, add_special_tokens=True, padding='max_length', truncation=True, return_tensors='pt')\n",
        "        self.input_ids = self.inputs['input_ids']\n",
        "        self.attention_masks = self.inputs['attention_mask']\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx,:], self.attention_masks[idx,:], self.tokens[idx], torch.tensor(self.features[idx],dtype=torch.float32), torch.tensor(self.labels[idx])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAyLAo9S30es"
      },
      "outputs": [],
      "source": [
        "label_all_tokens = True\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def align_label(text, labels, features):\n",
        "    input = tokenizer(text, max_length=max_len, add_special_tokens=True, padding='max_length', truncation=True, return_tensors='pt')\n",
        "    word_ids = input.word_ids()\n",
        "    input_ids = input['input_ids']\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "\n",
        "    previous_word_idx = None\n",
        "    new_labels, new_features = [], []\n",
        "    no_features = [0 for _ in range(1, 26)]\n",
        "\n",
        "    for word_idx in word_ids:\n",
        "        if word_idx is None:\n",
        "            new_labels.append('none')\n",
        "            new_features.append(no_features)\n",
        "        elif word_idx != previous_word_idx:\n",
        "            try:\n",
        "                new_labels.append(labels[word_idx])\n",
        "                new_features.append(features[word_idx])\n",
        "            except:\n",
        "                new_labels.append('none')\n",
        "                new_features.append(no_features)\n",
        "        else:\n",
        "            try:\n",
        "                new_labels.append(labels[word_idx] if label_all_tokens else 'none')\n",
        "                new_features.append(features[word_idx] if label_all_tokens else no_features)\n",
        "            except:\n",
        "                new_labels.append('none')\n",
        "                new_features.append(no_features)\n",
        "        previous_word_idx = word_idx\n",
        "\n",
        "    label_ids = [label_to_ids[label] for label in new_labels]\n",
        "    return label_ids, tokens, new_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F057RX2D30es"
      },
      "outputs": [],
      "source": [
        "train_dataset = MyDataset(train_sens, train_Feature, train_tags)\n",
        "train_dataset.encode()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGOLh8us30et"
      },
      "outputs": [],
      "source": [
        "test_dataset = MyDataset(test_sens, test_Feature, test_tags)\n",
        "test_dataset.encode()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDYdOycO30et"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=128)\n",
        "test_dataloader = DataLoader(test_dataset, shuffle=True, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPc5rcNR30et"
      },
      "source": [
        "#### construct model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WTcSQ3q30et"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class BertNerModel(nn.Module):\n",
        "    def __init__(self,num_labels):\n",
        "        super(BertNerModel,self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained(weight)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(768+25,num_labels)\n",
        "\n",
        "    def forward(self,input_ids,attention_mask,extra_features,token_type_ids=None):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "\n",
        "        pooled_output = outputs[0]\n",
        "        bert_outputs = self.dropout(pooled_output)\n",
        "\n",
        "        outputs = torch.concat((bert_outputs,extra_features[:,:,:]),-1)\n",
        "        # outputs = bert_outputs\n",
        "        outputs = self.classifier(outputs)\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR5hWCKz30et"
      },
      "source": [
        "#### evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HM_fiH6x30et"
      },
      "outputs": [],
      "source": [
        "def TagConvert(raw_tags, words_set, poss=None):\n",
        "    true_tags = []\n",
        "    for i in range(raw_tags.shape[0]):\n",
        "      kw_list = []\n",
        "      nkw_list = \"\"\n",
        "      for j in range(len(raw_tags[i])):\n",
        "          item = raw_tags[i][j]\n",
        "          if item == 0:\n",
        "              continue\n",
        "          if poss !=None and j in poss[i]:\n",
        "              continue\n",
        "          # if item == 5:\n",
        "          #     continue\n",
        "          if item == 4:\n",
        "              kw_list.append(str(words_set[j][i]))\n",
        "          if item == 1:\n",
        "              nkw_list += str(words_set[j][i])\n",
        "          if item == 2:\n",
        "              nkw_list += \" \"\n",
        "              nkw_list += str(words_set[j][i])\n",
        "          if item == 3:\n",
        "              nkw_list += \" \"\n",
        "              nkw_list += str(words_set[j][i])\n",
        "              kw_list.append(nkw_list)\n",
        "              nkw_list = \"\"\n",
        "\n",
        "      true_tags.append(kw_list)\n",
        "    return true_tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeaDWi2O30eu"
      },
      "outputs": [],
      "source": [
        "def evaluate(predict_data, target_data, topk=3):\n",
        "  TRUE_COUNT, PRED_COUNT, GOLD_COUNT = 0.0, 0.0, 0.0\n",
        "  for index, words in enumerate(predict_data):\n",
        "      y_pred, y_true = None, target_data[index]\n",
        "\n",
        "      if type(predict_data) == str:\n",
        "          words = sorted(words.items(), key=lambda item: (-item[1], item[0]))\n",
        "          y_pred = [i[0] for i in words]\n",
        "      elif type(predict_data) == list:\n",
        "          y_pred = words\n",
        "\n",
        "      y_pred = y_pred[0: topk]\n",
        "      TRUE_NUM = len(set(y_pred) & set(y_true))\n",
        "      TRUE_COUNT += TRUE_NUM\n",
        "      PRED_COUNT += len(y_pred)\n",
        "      GOLD_COUNT += len(y_true)\n",
        "  # compute P\n",
        "  if PRED_COUNT != 0:\n",
        "      p = (TRUE_COUNT / PRED_COUNT)\n",
        "  else:\n",
        "      p = 0\n",
        "  # compute R\n",
        "  if GOLD_COUNT != 0:\n",
        "      r = (TRUE_COUNT / GOLD_COUNT)\n",
        "  else:\n",
        "      r = 0\n",
        "  # compute F1\n",
        "  if (r + p) != 0:\n",
        "      f1 = ((2 * r * p) / (r + p))\n",
        "  else:\n",
        "      f1 = 0\n",
        "\n",
        "  p = round(p * 100, 2)\n",
        "  r = round(r * 100, 2)\n",
        "  f1 = round(f1 * 100, 2)\n",
        "\n",
        "  return p, r, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIW3PQMt30eu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_f1(y_pred, y_true):\n",
        "    # flatten and convert to numpy array\n",
        "    y_true = y_true.view(-1)\n",
        "    y_pred = y_pred.view(-1)\n",
        "    y_true = y_true.detach().cpu().numpy()\n",
        "    y_pred = y_pred.detach().cpu().numpy()\n",
        "\n",
        "    mask = np.where(y_true != 0)\n",
        "\n",
        "    y_true = y_true[mask]\n",
        "    y_pred = y_pred[mask]\n",
        "\n",
        "    return y_pred, y_true"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBZSKd6v30ev"
      },
      "source": [
        "#### start training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9P5Vdcx30ev"
      },
      "outputs": [],
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam, AdamW\n",
        "\n",
        "model = BertNerModel(num_labels=6)\n",
        "model = model.to(device)\n",
        "\n",
        "optim = AdamW(model.parameters(),lr=5e-5,weight_decay=1e-2)\n",
        "loss_fn = CrossEntropyLoss(reduction='none', ignore_index=0)\n",
        "loss_fn = loss_fn.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8pYVkAo30ev"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phuv-BHn30ev"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "epochs = 5\n",
        "best_f1 = 0.0\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    loss_value = 0.0\n",
        "    model.train()\n",
        "    label_true, label_pred = [], []\n",
        "    for i,batch in enumerate(train_dataloader):\n",
        "        optim.zero_grad()\n",
        "        input_ids, attention_masks, _, features, tags = batch\n",
        "        pred_tags = model(input_ids.to(device), attention_masks.to(device), features.to(device))\n",
        "\n",
        "        loss = loss_fn(pred_tags.permute(0,2,1),tags.to(device))\n",
        "        loss = loss.mean()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "        pred_tags = F.softmax(pred_tags,dim=-1)\n",
        "        pred_tags = torch.argmax(pred_tags,dim=-1)\n",
        "\n",
        "        y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "        label_true.extend(y_true)\n",
        "        label_pred.extend(y_pred)\n",
        "\n",
        "        loss_value += loss.item()\n",
        "\n",
        "    label_train_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "\n",
        "    model.eval()\n",
        "    kw_true, kw_pred = [], []\n",
        "    label_true, label_pred = [],[]\n",
        "    for i,batch in enumerate(test_dataloader):\n",
        "      input_ids, attention_masks, tokens, features, tags = batch\n",
        "      with torch.no_grad():\n",
        "          for module in model.modules():\n",
        "              if isinstance(module, nn.Dropout):\n",
        "                  module.p = 0\n",
        "                  module.train(False)\n",
        "          pred_tags = model(input_ids.to(device), attention_masks.to(device), features.to(device))\n",
        "          pred_tags = F.softmax(pred_tags,dim=-1)\n",
        "          pred_tags = torch.argmax(pred_tags,dim=-1)\n",
        "\n",
        "      y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "      label_true.extend(y_true)\n",
        "      label_pred.extend(y_pred)\n",
        "\n",
        "      # more balance evaluate\n",
        "      poss = []\n",
        "      for i in range(len(tags)):\n",
        "          pos = []\n",
        "          for j in range(len(tags[i])):\n",
        "              if tags[i][j] == 0:\n",
        "                  pos.append(j)\n",
        "          poss.append(pos)\n",
        "\n",
        "      kw_true.extend(TagConvert(tags,tokens))\n",
        "      kw_pred.extend(TagConvert(pred_tags,tokens,poss))\n",
        "\n",
        "    label_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "    P, R, F1 = evaluate(kw_true, kw_pred)\n",
        "\n",
        "    if F1 > best_f1:\n",
        "        best_f1 = F1\n",
        "        torch.save(model.state_dict(),'./pretrain_pt/bert.pt')\n",
        "\n",
        "    print(\"epoch{}:  loss:{:.2f}   train_f1_value:{:.2f}  test_f1_value:{:.2f}  kw_f1_value:{:.2f}\".format(\n",
        "        epoch+1, loss_value / len(train_dataloader), label_train_f1, label_f1, F1\n",
        "    ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bwu5-I-X30ew"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9IInQlq30ew"
      },
      "source": [
        "#### inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8SxBZts30ew"
      },
      "outputs": [],
      "source": [
        "model = BertNerModel(num_labels=6)\n",
        "model.load_state_dict(torch.load('./pretrain_pt/bert.pt'))\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gm9qo5EK30ew"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1XRRnHu30ew"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "model.eval()\n",
        "kw_true, kw_pred = [], []\n",
        "label_true, label_pred = [],[]\n",
        "for i,batch in enumerate(test_dataloader):\n",
        "    input_ids, attention_masks, tokens, extra_features, tags = batch\n",
        "    with torch.no_grad():\n",
        "        for module in model.modules():\n",
        "            if isinstance(module, nn.Dropout):\n",
        "                module.p = 0\n",
        "                module.train(False)\n",
        "        #pred_tags = model(input_ids.to(device), attention_masks.to(device))\n",
        "        pred_tags = model(input_ids.to(device), attention_masks.to(device), extra_features.to(device))\n",
        "        pred_tags = F.softmax(pred_tags,dim=-1)\n",
        "        pred_tags = torch.argmax(pred_tags,dim=-1)\n",
        "\n",
        "    y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "    label_true.extend(y_true)\n",
        "    label_pred.extend(y_pred)\n",
        "\n",
        "    # more balance evaluate\n",
        "    poss = []\n",
        "    for i in range(len(tags)):\n",
        "        pos = []\n",
        "        for j in range(len(tags[i])):\n",
        "            if tags[i][j] == 0:\n",
        "                pos.append(j)\n",
        "        poss.append(pos)\n",
        "\n",
        "    kw_true.extend(TagConvert(tags,tokens))\n",
        "    kw_pred.extend(TagConvert(pred_tags,tokens,poss))\n",
        "\n",
        "label_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "P, R, F1 = evaluate(kw_true, kw_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6krJATmu30ew"
      },
      "outputs": [],
      "source": [
        "print(P)\n",
        "print(R)\n",
        "print(F1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDqanUap30ex"
      },
      "outputs": [],
      "source": [
        "##############################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2Csn5Nh30ex"
      },
      "outputs": [],
      "source": [
        "fs_num = 25  # 定义额外特征的数量"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maUzbiVv30ez"
      },
      "outputs": [],
      "source": [
        "################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mchBSUE-30e7"
      },
      "outputs": [],
      "source": [
        "class SoftAttention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(SoftAttention, self).__init__()\n",
        "        self.attention_weights = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        attention_scores = self.attention_weights(hidden_states)  # [batch_size, seq_len, 1]\n",
        "        attention_weights = torch.softmax(attention_scores, dim=1)  # [batch_size, seq_len, 1]\n",
        "        context_vector = torch.sum(attention_weights * hidden_states, dim=1)  # [batch_size, hidden_dim]\n",
        "        return context_vector, attention_weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEONvBvj30e8"
      },
      "outputs": [],
      "source": [
        "class BertNerModelWithAttention(nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super(BertNerModelWithAttention, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(weight)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.attention = SoftAttention(768)\n",
        "        self.classifier = nn.Linear(768 + 25, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, extra_features, token_type_ids=None):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        sequence_output = outputs[0]  # [batch_size, seq_len, hidden_dim]\n",
        "        sequence_output = self.dropout(sequence_output)\n",
        "\n",
        "        context_vector, attention_weights = self.attention(sequence_output)  # [batch_size, hidden_dim]\n",
        "\n",
        "        # 扩展 context_vector 以匹配 extra_features 的维度\n",
        "        context_vector = context_vector.unsqueeze(1).expand(-1, extra_features.size(1), -1)  # [batch_size, seq_len, hidden_dim]\n",
        "\n",
        "        combined_output = torch.cat((context_vector, extra_features), dim=-1)  # [batch_size, seq_len, hidden_dim + 25]\n",
        "        logits = self.classifier(combined_output)  # [batch_size, seq_len, num_labels]\n",
        "\n",
        "        return logits, attention_weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pnFbxQJ30e8"
      },
      "outputs": [],
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import AdamW\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# model = BertNerModelWithSoftAttention(num_labels=6)\n",
        "# model = model.to(device)\n",
        "\n",
        "\n",
        "model = BertNerModelWithAttention(num_labels=6)\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "#optim = AdamW(model.parameters(), lr=5e-5, weight_decay=1e-2)\n",
        "optim = AdamW(model.parameters(), lr=1e-5, weight_decay=1e-2)  # 尝试降低学习率\n",
        "\n",
        "loss_fn = CrossEntropyLoss(reduction='none', ignore_index=0)\n",
        "loss_fn = loss_fn.to(device)\n",
        "\n",
        "epochs = 5\n",
        "best_f1 = 0.0\n",
        "num_labels = 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYa8tQMX30e8"
      },
      "outputs": [],
      "source": [
        "# 训练模型\n",
        "import torch.nn.functional as F\n",
        "\n",
        "epochs = 20\n",
        "best_f1 = 0.0\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    loss_value = 0.0\n",
        "    model.train()\n",
        "    label_true, label_pred = [], []\n",
        "    for i, batch in enumerate(train_dataloader):\n",
        "        optim.zero_grad()\n",
        "        input_ids, attention_masks, _, features, tags = batch\n",
        "        pred_tags, _ = model(input_ids.to(device), attention_masks.to(device), features.to(device))\n",
        "\n",
        "        loss = loss_fn(pred_tags.permute(0, 2, 1), tags.to(device))\n",
        "        loss = loss.mean()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "        pred_tags = F.softmax(pred_tags, dim=-1)\n",
        "        pred_tags = torch.argmax(pred_tags, dim=-1)\n",
        "\n",
        "        y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "        label_true.extend(y_true)\n",
        "        label_pred.extend(y_pred)\n",
        "\n",
        "        loss_value += loss.item()\n",
        "\n",
        "    label_train_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "\n",
        "    model.eval()\n",
        "    kw_true, kw_pred = [], []\n",
        "    label_true, label_pred = [], []\n",
        "    for i, batch in enumerate(test_dataloader):\n",
        "        input_ids, attention_masks, tokens, features, tags = batch\n",
        "        with torch.no_grad():\n",
        "            for module in model.modules():\n",
        "                if isinstance(module, nn.Dropout):\n",
        "                    module.p = 0\n",
        "                    module.train(False)\n",
        "            pred_tags, _ = model(input_ids.to(device), attention_masks.to(device), features.to(device))\n",
        "            pred_tags = F.softmax(pred_tags, dim=-1)\n",
        "            pred_tags = torch.argmax(pred_tags, dim=-1)\n",
        "\n",
        "        y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "        label_true.extend(y_true)\n",
        "        label_pred.extend(y_pred)\n",
        "\n",
        "        poss = []\n",
        "        for i in range(len(tags)):\n",
        "            pos = []\n",
        "            for j in range(len(tags[i])):\n",
        "                if tags[i][j] == 0:\n",
        "                    pos.append(j)\n",
        "            poss.append(pos)\n",
        "\n",
        "        kw_true.extend(TagConvert(tags, tokens))\n",
        "        kw_pred.extend(TagConvert(pred_tags, tokens, poss))\n",
        "\n",
        "    label_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "    P, R, F1 = evaluate(kw_true, kw_pred)\n",
        "\n",
        "    if F1 > best_f1:\n",
        "        best_f1 = F1\n",
        "        torch.save(model.state_dict(), './pretrain_pt/bert_with_attention.pt')\n",
        "\n",
        "    print(\"epoch{}:  loss:{:.2f}   train_f1_value:{:.2f}  test_f1_value:{:.2f}  kw_f1_value:{:.2f}\".format(\n",
        "        epoch + 1, loss_value / len(train_dataloader), label_train_f1, label_f1, F1\n",
        "    ))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tan6xw7c30e-"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "kw_true, kw_pred = [], []\n",
        "label_true, label_pred = [], []\n",
        "for i, batch in enumerate(test_dataloader):\n",
        "    input_ids, attention_masks, tokens, extra_features, tags = batch\n",
        "    with torch.no_grad():\n",
        "        for module in model.modules():\n",
        "            if isinstance(module, nn.Dropout):\n",
        "                module.p = 0\n",
        "                module.train(False)\n",
        "        pred_tags, word_attention_weights, sentence_attention_weights = model(input_ids.to(device), attention_masks.to(device), extra_features.to(device))\n",
        "        pred_tags = F.softmax(pred_tags, dim=-1)\n",
        "        pred_tags = torch.argmax(pred_tags, dim=-1)\n",
        "\n",
        "    y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "    label_true.extend(y_true)\n",
        "    label_pred.extend(y_pred)\n",
        "\n",
        "    poss = []\n",
        "    for i in range(len(tags)):\n",
        "        pos = []\n",
        "        for j in range(len(tags[i])):\n",
        "            if tags[i][j] == 0:\n",
        "                pos.append(j)\n",
        "        poss.append(pos)\n",
        "\n",
        "    kw_true.extend(TagConvert(tags, tokens))\n",
        "    kw_pred.extend(TagConvert(pred_tags, tokens, poss))\n",
        "\n",
        "label_f1 = f1_score(label_true, label_pred, average='macro') * 100\n",
        "P, R, F1 = evaluate(kw_true, kw_pred)\n",
        "print(P, R, F1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "INXfaAZq30fD"
      },
      "source": [
        " ###定义词级别和句子级别的注意力层"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxDHcJc830fD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "rrplSHar30fF"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "83QbfSkn30fF"
      },
      "source": [
        "层注意力 2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wk_NcvFx30fF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertModel\n",
        "from sklearn.metrics import f1_score\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5CWnG3h30fF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertModel\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim, regularizer=None):\n",
        "        super(Attention, self).__init__()\n",
        "        self.context = nn.Parameter(torch.FloatTensor(hidden_dim, 1) * 0.01)\n",
        "        nn.init.normal_(self.context, mean=0.0, std=0.05)\n",
        "        self.regularizer = regularizer\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        attention_in = torch.exp(torch.squeeze(torch.matmul(x, self.context), -1))\n",
        "        if mask is not None:\n",
        "            attention_in = attention_in * mask.float()\n",
        "        attention = attention_in / torch.unsqueeze(torch.sum(attention_in, -1), -1)\n",
        "        weighted_sum = torch.bmm(attention.unsqueeze(1), x).squeeze(1)\n",
        "        return weighted_sum\n",
        "\n",
        "class BertHANModel(nn.Module):\n",
        "    def __init__(self, num_labels, hidden_dim=768):\n",
        "        super(BertHANModel, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.word_attention = Attention(hidden_dim)\n",
        "        self.sentence_attention = Attention(hidden_dim)\n",
        "        self.classifier = nn.Linear(hidden_dim, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, sentence_ids):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        sequence_output = outputs[0]  # shape: (batch_size, seq_length, hidden_dim)\n",
        "        mask = (sentence_ids != 0).float()\n",
        "        word_attention_output = self.word_attention(sequence_output, mask)\n",
        "        sentence_attention_output = self.sentence_attention(word_attention_output, mask)\n",
        "        logits = self.classifier(sentence_attention_output)\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_PqOsFm30fG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = BertHANModel(num_labels=6)\n",
        "model = model.to(device)\n",
        "\n",
        "optim = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss(reduction='none', ignore_index=0)\n",
        "loss_fn = loss_fn.to(device)\n",
        "\n",
        "scaler = GradScaler()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3MC2vqG30fG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "from transformers import BertModel\n",
        "from torch import nn\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(Attention, self).__init__()\n",
        "        self.context = nn.Parameter(torch.FloatTensor(hidden_dim, 1))\n",
        "        nn.init.xavier_uniform_(self.context)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        attention_in = torch.tanh(torch.matmul(x, self.context))\n",
        "        attention_in = torch.squeeze(attention_in, -1)\n",
        "        if mask is not None:\n",
        "            attention_in = attention_in * mask.float()\n",
        "        attention_weights = F.softmax(attention_in, dim=-1)\n",
        "        weighted_sum = torch.bmm(attention_weights.unsqueeze(1), x).squeeze(1)\n",
        "        return weighted_sum\n",
        "\n",
        "class BertHANModel(nn.Module):\n",
        "    def __init__(self, num_labels, hidden_dim=768, rnn_dim=256):\n",
        "        super(BertHANModel, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.word_attention = Attention(hidden_dim)\n",
        "        self.rnn = nn.GRU(hidden_dim, rnn_dim, batch_first=True, bidirectional=True)\n",
        "        self.sentence_attention = Attention(rnn_dim * 2)\n",
        "        self.classifier = nn.Linear(rnn_dim * 2, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        bert_outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        sequence_output = bert_outputs[0]  # shape: (batch_size, seq_length, hidden_dim)\n",
        "\n",
        "        # Word-level attention\n",
        "        word_attention_output = self.word_attention(sequence_output)\n",
        "\n",
        "        # Sentence-level GRU\n",
        "        rnn_output, _ = self.rnn(word_attention_output.unsqueeze(1))\n",
        "\n",
        "        # Sentence-level attention\n",
        "        sentence_attention_output = self.sentence_attention(rnn_output)\n",
        "\n",
        "        logits = self.classifier(sentence_attention_output).unsqueeze(1)  # shape: (batch_size, 1, num_labels)\n",
        "        return logits.expand(-1, sequence_output.size(1), -1)  # shape: (batch_size, seq_length, num_labels)\n",
        "\n",
        "def calculate_f1(y_pred, y_true):\n",
        "    y_true = y_true.view(-1)\n",
        "    y_pred = y_pred.view(-1)\n",
        "    y_true = y_true.detach().cpu().numpy()\n",
        "    y_pred = y_pred.detach().cpu().numpy()\n",
        "    mask = np.where(y_true != 0)\n",
        "    y_true = y_true[mask]\n",
        "    y_pred = y_pred[mask]\n",
        "    return y_pred, y_true\n",
        "\n",
        "def TagConvert(raw_tags, words_set, poss=None):\n",
        "    true_tags = []\n",
        "    for i in range(raw_tags.shape[0]):\n",
        "        kw_list = []\n",
        "        nkw_list = \"\"\n",
        "        for j in range(len(raw_tags[i])):\n",
        "            item = raw_tags[i][j]\n",
        "            if item == 0:\n",
        "                continue\n",
        "            if poss != None and j in poss[i]:\n",
        "                continue\n",
        "            if item == 4:\n",
        "                kw_list.append(str(words_set[j][i]))\n",
        "            if item == 1:\n",
        "                nkw_list += str(words_set[j][i])\n",
        "            if item == 2:\n",
        "                nkw_list += \" \"\n",
        "                nkw_list += str(words_set[j][i])\n",
        "            if item == 3:\n",
        "                nkw_list += \" \"\n",
        "                nkw_list += str(words_set[j][i])\n",
        "                kw_list.append(nkw_list)\n",
        "                nkw_list = \"\"\n",
        "        true_tags.append(kw_list)\n",
        "    return true_tags\n",
        "\n",
        "def evaluate(predict_data, target_data, topk=3):\n",
        "    TRUE_COUNT, PRED_COUNT, GOLD_COUNT = 0.0, 0.0, 0.0\n",
        "    for index, words in enumerate(predict_data):\n",
        "        y_pred, y_true = None, target_data[index]\n",
        "        if type(predict_data) == str:\n",
        "            words = sorted(words.items(), key=lambda item: (-item[1], item[0]))\n",
        "            y_pred = [i[0] for i in words]\n",
        "        elif type(predict_data) == list:\n",
        "            y_pred = words\n",
        "        y_pred = y_pred[0: topk]\n",
        "        TRUE_NUM = len(set(y_pred) & set(y_true))\n",
        "        TRUE_COUNT += TRUE_NUM\n",
        "        PRED_COUNT += len(y_pred)\n",
        "        GOLD_COUNT += len(y_true)\n",
        "    if PRED_COUNT != 0:\n",
        "        p = (TRUE_COUNT / PRED_COUNT)\n",
        "    else:\n",
        "        p = 0\n",
        "    if GOLD_COUNT != 0:\n",
        "        r = (TRUE_COUNT / GOLD_COUNT)\n",
        "    else:\n",
        "        r = 0\n",
        "    if (r + p) != 0:\n",
        "        f1 = ((2 * r * p) / (r + p))\n",
        "    else:\n",
        "        f1 = 0\n",
        "    p = round(p * 100, 2)\n",
        "    r = round(r * 100, 2)\n",
        "    f1 = round(f1 * 100, 2)\n",
        "    return p, r, f1\n",
        "\n",
        "# 假设已经定义了数据集和数据加载器\n",
        "# train_dataloader = ...\n",
        "# test_dataloader = ...\n",
        "\n",
        "# 训练和评估\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = BertHANModel(num_labels=6)\n",
        "model = model.to(device)\n",
        "optim = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss(reduction='none', ignore_index=0)\n",
        "loss_fn = loss_fn.to(device)\n",
        "\n",
        "epochs = 5\n",
        "best_f1 = 0.0\n",
        "scaler = GradScaler()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    loss_value = 0.0\n",
        "    model.train()\n",
        "    label_true, label_pred = [], []\n",
        "    for i, batch in enumerate(train_dataloader):\n",
        "        optim.zero_grad()\n",
        "\n",
        "        input_ids = batch[0].to(device)\n",
        "        attention_masks = batch[1].to(device)\n",
        "        tags = batch[4].to(device)\n",
        "\n",
        "        with autocast():\n",
        "            pred_tags = model(input_ids, attention_masks)\n",
        "\n",
        "            # 展平 pred_tags 和 tags 以匹配形状\n",
        "            pred_tags = pred_tags.reshape(-1, pred_tags.size(-1))\n",
        "            tags = tags.reshape(-1)\n",
        "\n",
        "            #print(f\"pred_tags shape: {pred_tags.shape}, tags shape: {tags.shape}\")\n",
        "\n",
        "            loss = loss_fn(pred_tags, tags)\n",
        "            loss = loss.mean()\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optim)\n",
        "        scaler.update()\n",
        "\n",
        "        pred_tags = F.softmax(pred_tags, dim=-1)\n",
        "        pred_tags = torch.argmax(pred_tags, dim=-1)\n",
        "        y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "        label_true.extend(y_true)\n",
        "        label_pred.extend(y_pred)\n",
        "        loss_value += loss.item()\n",
        "\n",
        "    label_train_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "\n",
        "    model.eval()\n",
        "    kw_true, kw_pred = [], []\n",
        "    label_true, label_pred = [], []\n",
        "    for i, batch in enumerate(test_dataloader):\n",
        "        input_ids = batch[0].to(device)\n",
        "        attention_masks = batch[1].to(device)\n",
        "        tokens = batch[2]  # tokens 不是 Tensor，直接使用\n",
        "        tags = batch[4].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for module in model.modules():\n",
        "                if isinstance(module, nn.Dropout):\n",
        "                    module.p = 0\n",
        "                    module.train(False)\n",
        "            with autocast():\n",
        "                pred_tags = model(input_ids, attention_masks)\n",
        "                pred_tags = F.softmax(pred_tags, dim=-1)\n",
        "                pred_tags = torch.argmax(pred_tags, dim=-1)\n",
        "\n",
        "        y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "        label_true.extend(y_true)\n",
        "        label_pred.extend(y_pred)\n",
        "\n",
        "        poss = []\n",
        "        for i in range(len(tags)):\n",
        "            pos = []\n",
        "            for j in range(len(tags[i])):\n",
        "                if tags[i][j] == 0:\n",
        "                    pos.append(j)\n",
        "            poss.append(pos)\n",
        "\n",
        "        kw_true.extend(TagConvert(tags, tokens))\n",
        "        kw_pred.extend(TagConvert(pred_tags, tokens, poss))\n",
        "\n",
        "    label_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "    P, R, F1 = evaluate(kw_true, kw_pred)\n",
        "\n",
        "    if F1 > best_f1:\n",
        "        best_f1 = F1\n",
        "        torch.save(model.state_dict(), './pretrain_pt/bert_HAtten.pt')\n",
        "\n",
        "    print(\"epoch{}:  loss:{:.2f}   train_f1_value:{:.2f}  test_f1_value:{:.2f}  kw_f1_value:{:.2f}\".format(\n",
        "        epoch + 1, loss_value / len(train_dataloader), label_train_f1, label_f1, F1\n",
        "    ))\n",
        "\n",
        "    torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vv5VsYgA30fI"
      },
      "outputs": [],
      "source": [
        "def load_model(model_path, num_labels):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = BertHANModel(num_labels=num_labels)\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "def calculate_f1(y_pred, y_true):\n",
        "    y_true = y_true.view(-1)\n",
        "    y_pred = y_pred.view(-1)\n",
        "    y_true = y_true.detach().cpu().numpy()\n",
        "    y_pred = y_pred.detach().cpu().numpy()\n",
        "    mask = np.where(y_true != 0)\n",
        "    y_true = y_true[mask]\n",
        "    y_pred = y_pred[mask]\n",
        "    return y_pred, y_true\n",
        "\n",
        "def TagConvert(raw_tags, words_set, poss=None):\n",
        "    true_tags = []\n",
        "    for i in range(raw_tags.shape[0]):\n",
        "        kw_list = []\n",
        "        nkw_list = \"\"\n",
        "        for j in range(len(raw_tags[i])):\n",
        "            item = raw_tags[i][j]\n",
        "            if item == 0:\n",
        "                continue\n",
        "            if poss != None and j in poss[i]:\n",
        "                continue\n",
        "            if item == 4:\n",
        "                kw_list.append(str(words_set[j][i]))\n",
        "            if item == 1:\n",
        "                nkw_list += str(words_set[j][i])\n",
        "            if item == 2:\n",
        "                nkw_list += \" \"\n",
        "                nkw_list += str(words_set[j][i])\n",
        "            if item == 3:\n",
        "                nkw_list += \" \"\n",
        "                nkw_list += str(words_set[j][i])\n",
        "                kw_list.append(nkw_list)\n",
        "                nkw_list = \"\"\n",
        "        true_tags.append(kw_list)\n",
        "    return true_tags\n",
        "\n",
        "def evaluate(predict_data, target_data, topk=3):\n",
        "    TRUE_COUNT, PRED_COUNT, GOLD_COUNT = 0.0, 0.0, 0.0\n",
        "    for index, words in enumerate(predict_data):\n",
        "        y_pred, y_true = None, target_data[index]\n",
        "        if type(predict_data) == str:\n",
        "            words = sorted(words.items(), key=lambda item: (-item[1], item[0]))\n",
        "            y_pred = [i[0] for i in words]\n",
        "        elif type(predict_data) == list:\n",
        "            y_pred = words\n",
        "        y_pred = y_pred[0: topk]\n",
        "        TRUE_NUM = len(set(y_pred) & set(y_true))\n",
        "        TRUE_COUNT += TRUE_NUM\n",
        "        PRED_COUNT += len(y_pred)\n",
        "        GOLD_COUNT += len(y_true)\n",
        "    if PRED_COUNT != 0:\n",
        "        p = (TRUE_COUNT / PRED_COUNT)\n",
        "    else:\n",
        "        p = 0\n",
        "    if GOLD_COUNT != 0:\n",
        "        r = (TRUE_COUNT / GOLD_COUNT)\n",
        "    else:\n",
        "        r = 0\n",
        "    if (r + p) != 0:\n",
        "        f1 = ((2 * r * p) / (r + p))\n",
        "    else:\n",
        "        f1 = 0\n",
        "    p = round(p * 100, 2)\n",
        "    r = round(r * 100, 2)\n",
        "    f1 = round(f1 * 100, 2)\n",
        "    return p, r, f1\n",
        "\n",
        "def predict_and_evaluate(model, dataloader):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    label_true, label_pred = [], []\n",
        "    kw_true, kw_pred = [], []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_masks = batch[1].to(device)\n",
        "            tokens = batch[2]\n",
        "            tags = batch[4].to(device)\n",
        "\n",
        "            pred_tags = model(input_ids, attention_masks)\n",
        "            pred_tags = torch.argmax(pred_tags, dim=-1)\n",
        "\n",
        "            y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "            label_true.extend(y_true)\n",
        "            label_pred.extend(y_pred)\n",
        "\n",
        "            poss = []\n",
        "            for i in range(len(tags)):\n",
        "                pos = []\n",
        "                for j in range(len(tags[i])):\n",
        "                    if tags[i][j] == 0:\n",
        "                        pos.append(j)\n",
        "                poss.append(pos)\n",
        "            kw_true.extend(TagConvert(tags, tokens))\n",
        "            kw_pred.extend(TagConvert(pred_tags, tokens, poss))\n",
        "\n",
        "    label_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "    P, R, F1 = evaluate(kw_true, kw_pred)\n",
        "    return label_f1, P, R, F1\n",
        "\n",
        "# 加载模型\n",
        "model_path = './pretrain_pt/bert_HAtten.pt'\n",
        "num_labels = 6\n",
        "model = load_model(model_path, num_labels)\n",
        "\n",
        "# 假设 test_dataloader 已经定义好\n",
        "label_f1, P, R, F1 = predict_and_evaluate(model, test_dataloader)\n",
        "\n",
        "print(f\"label_f1: {label_f1:.2f}, Precision: {P:.2f}, Recall: {R:.2f}, F1: {F1:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rc65AZDF0E_C"
      },
      "source": [
        "#####其它模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7FCLYyZfOMX"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "train_path = '/content/drive/MyDrive/ner/datas/Election-Trec/train.json'\n",
        "test_path = '/content/drive/MyDrive/ner/datas/Election-Trec/test.json'\n",
        "\n",
        "\n",
        "# 加载训练和测试数据\n",
        "with open(train_path, 'r', encoding='utf-8') as f:\n",
        "    train_file = json.load(f)\n",
        "\n",
        "with open(test_path, 'r', encoding='utf-8') as f:\n",
        "    test_file = json.load(f)\n",
        "\n",
        "# 预处理训练数据\n",
        "train_sens, train_tags, train_Feature = [], [], []\n",
        "train_word_nums = []\n",
        "\n",
        "for key in train_file.keys():\n",
        "    items = train_file[key]\n",
        "    sens = ''\n",
        "    tags = []\n",
        "    features = []\n",
        "    nums = 0\n",
        "\n",
        "    for item in items:\n",
        "        sens += item[0] + ' '\n",
        "        features.append(item[1:-1])  # 取出ET和EEG特征\n",
        "        tags.append(item[-1])  # 最后一个是标签\n",
        "        nums += 1\n",
        "\n",
        "    train_sens.append(sens.strip())\n",
        "    train_Feature.append(features)\n",
        "    train_tags.append(tags)\n",
        "    train_word_nums.append(nums)\n",
        "\n",
        "# 预处理测试数据\n",
        "test_sens, test_tags, test_Feature = [], [], []\n",
        "test_word_nums = []\n",
        "\n",
        "for key in test_file.keys():\n",
        "    items = test_file[key]\n",
        "    sens = ''\n",
        "    tags = []\n",
        "    features = []\n",
        "    nums = 0\n",
        "\n",
        "    for item in items:\n",
        "        sens += item[0] + ' '\n",
        "        features.append(item[1:-1])  # 取出ET和EEG特征\n",
        "        tags.append(item[-1])  # 最后一个是标签\n",
        "        nums += 1\n",
        "\n",
        "    test_sens.append(sens.strip())\n",
        "    test_Feature.append(features)\n",
        "    test_tags.append(tags)\n",
        "    test_word_nums.append(nums)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzX7X_7bfQTK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306,
          "referenced_widgets": [
            "5ca96f3c0f2446b1868993129c67f90a",
            "cc08b098c9574a97a06c1a3912b3bb9d",
            "1c48b97aa0fd4131be5a4be237a97aea",
            "2b5f5d7f531a41ce8648515c4506925b",
            "62195acefa1f460899b99eec8fd64fd8",
            "7a00b431cecd48bfb8f46c1bd38eb59a",
            "ff09175e7a3a4e35bb4358b0392cdcc6",
            "5983767d0d924377900fe6d6cfd421d3",
            "52518eb06fb24a4f8e17c12c7aa3256c",
            "ebf582f7f1a047f4906a7c4f13870649",
            "733cbef4849d4cc99569905541110c16",
            "15318a207af743b694022a5f535a827d",
            "10ba27367b5f4280b69526b14d0b6fc3",
            "bd7b52fc0b374b67875001eb1711b97a",
            "971cb32a8530400a926de1b19b339ea0",
            "339e81e867c347858bec3b68ed1e9b20",
            "55da55a55f624f6084d632727c1b4ba6",
            "03a5349779a74ef7a3fbdcb4ed373771",
            "1982b98b018049a9a090d89a81af754f",
            "161bde2ea196459f8e70c37e011bd675",
            "622c28e17032499697370e08088b67a6",
            "297f5ab924a24ff3a93c059ff5340302",
            "26653a1478b344af9c7b4673a8d2f406",
            "9e8c03c5cff84635bebab030a50d29f0",
            "0a1963b2f73941398136ee5fcd304b0c",
            "f681554ba2894b53aeba107c82a83292",
            "816614a185634e9395bdb4a7c7ac27ed",
            "37df2d9206024afd9ec527e3202ca61f",
            "e2621e8698e44c9f8b29d0bd4f27f942",
            "9252b5fb792c44fdbac7085c95af8912",
            "4c1cdb5b32a24f73bb9d4db8ce58c157",
            "fedc275e72b9401b9321464f13987b67",
            "f5e27a9d9b34422fb15bbd542c983098",
            "ed8af7c53f4c412d9b70cb8f0a074abe",
            "dfcaf2cf411f447180b4a499d547d216",
            "94810557722b4e71b8e782314905799a",
            "ebd36555c4c548bda979c89f67d4c731",
            "4c207b891dc44a7d8be46452b34a2de5",
            "9ed057b8c6a3451c9880e92aa13be3d6",
            "693912d97c84456d8d8f2c9bee684f37",
            "ca8f1ef6b1a34b3fb6725e767bee4215",
            "5748928ddc7648f2bde150300269ffd5",
            "891b38f2c22e4adbbd0fe40d43956685",
            "790cbdeb9ebd4cdbb8eddcf52a916c5d",
            "8b8ea24553414421b3da9fb97a8bf32a",
            "5033c90522174d76bf1ed2009a974db3",
            "3cd0d99fd965439989a28c64f8a77429",
            "43a85ad2222449bb9dbbb6378708c4ee",
            "772cc5dcd08c460c87f95d5a3d98da83",
            "49e75571413e47dabbdfae47f0d35596",
            "e83951165bef4a068c2e18261f4adc34",
            "8131b3b978fc4eebafee0e255e3a7008",
            "9e9b09faa34241f8a567d7f2967b433d",
            "bd901d61e18c44dfbeb2b826e913970c",
            "16ac6be89d3444bb920cc78fe07275a4"
          ]
        },
        "outputId": "7c3323f0-5226-4a7a-fea7-ec28fe78948e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ca96f3c0f2446b1868993129c67f90a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15318a207af743b694022a5f535a827d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26653a1478b344af9c7b4673a8d2f406"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed8af7c53f4c412d9b70cb8f0a074abe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b8ea24553414421b3da9fb97a8bf32a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import RobertaTokenizerFast\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 加载tokenizer\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n",
        "max_len = 128  # 设置最大序列长度\n",
        "\n",
        "label_to_ids = {'none': 0, 'B': 1, 'I': 2, 'E': 3, 'S': 4, \"O\": 5}\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, texts, old_features, tags):\n",
        "        self.texts = texts\n",
        "        self.tags = tags\n",
        "        self.old_features = old_features\n",
        "\n",
        "        self.labels = []\n",
        "        self.tokens = []\n",
        "        self.features = []\n",
        "\n",
        "        self.input_ids = None\n",
        "        self.attention_masks = None\n",
        "\n",
        "    def encode(self):\n",
        "        for i in tqdm(range(len(self.texts))):\n",
        "            text = self.texts[i]\n",
        "            tag = self.tags[i]\n",
        "            feature = self.old_features[i]\n",
        "            tags, tokens, features = align_label(text, tag, feature)\n",
        "            self.labels.append(tags)\n",
        "            self.tokens.append(tokens)\n",
        "            self.features.append(features)\n",
        "\n",
        "        self.features = np.array(self.features, float)\n",
        "        self.inputs = tokenizer(self.texts, max_length=max_len, add_special_tokens=True, padding='max_length', truncation=True, return_tensors='pt')\n",
        "        self.input_ids = self.inputs['input_ids']\n",
        "        self.attention_masks = self.inputs['attention_mask']\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx, :], self.attention_masks[idx, :], self.tokens[idx], torch.tensor(self.features[idx], dtype=torch.float32), torch.tensor(self.labels[idx])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGUNOy02fUxF"
      },
      "outputs": [],
      "source": [
        "def align_label(text, labels, features):\n",
        "    input = tokenizer(text, max_length=max_len, add_special_tokens=True, padding='max_length', truncation=True, return_tensors='pt')\n",
        "    word_ids = input.word_ids()\n",
        "    input_ids = input['input_ids']\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "\n",
        "    previous_word_idx = None\n",
        "    new_labels, new_features = [], []\n",
        "    no_features = [0 for _ in range(1, 26)]  # 根据特征数量调整\n",
        "\n",
        "    for word_idx in word_ids:\n",
        "        if word_idx is None:\n",
        "            new_labels.append('none')\n",
        "            new_features.append(no_features)\n",
        "        elif word_idx != previous_word_idx:\n",
        "            try:\n",
        "                new_labels.append(labels[word_idx])\n",
        "                new_features.append(features[word_idx])\n",
        "            except:\n",
        "                new_labels.append('none')\n",
        "                new_features.append(no_features)\n",
        "        else:\n",
        "            try:\n",
        "                new_labels.append(labels[word_idx] if label_all_tokens else 'none')\n",
        "                new_features.append(features[word_idx] if label_all_tokens else no_features)\n",
        "            except:\n",
        "                new_labels.append('none')\n",
        "                new_features.append(no_features)\n",
        "        previous_word_idx = word_idx\n",
        "\n",
        "    label_ids = [label_to_ids[label] for label in new_labels]\n",
        "    return label_ids, tokens, new_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVjAsMC5BVh8"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8Q73w0wfagL",
        "outputId": "fbcc061b-867b-4c76-d49a-cc5d2008215b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24210/24210 [00:15<00:00, 1521.48it/s]\n",
            "100%|██████████| 3027/3027 [00:02<00:00, 1489.99it/s]\n"
          ]
        }
      ],
      "source": [
        "# 创建数据集对象\n",
        "train_dataset = MyDataset(train_sens, train_Feature, train_tags)\n",
        "train_dataset.encode()\n",
        "\n",
        "test_dataset = MyDataset(test_sens, test_Feature, test_tags)\n",
        "test_dataset.encode()\n",
        "\n",
        "# 数据加载器\n",
        "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=128)\n",
        "test_dataloader = DataLoader(test_dataset, shuffle=True, batch_size=128)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "7591abc281164081986d0d7086325ccd",
            "cf23e095f0774e8fa6e139f96e9069c3",
            "df75aeb50ddd4eac908cc4e90d58e618",
            "0f10a72f3c464a77b055f5c2e9eb71f4",
            "68c97e0c5129463ca7f00fe171b259a3",
            "5c685604062742d28a3ccad895f2a851",
            "7f3be5b2b24642fe903eb443a7b6e025",
            "2dae1bc345ec4ad28d86452478899b38",
            "12dc5199598748bd9bb337dd8d8546b5",
            "d3393bf775c04c6cbc7c4e3030b9c92d",
            "ff4d8172c21c46c68bcd7afa1fcd830f"
          ]
        },
        "id": "cheRiv5MWJOa",
        "outputId": "facc0d32-23f2-4ea2-e09e-753284f721fa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7591abc281164081986d0d7086325ccd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import RobertaTokenizerFast, RobertaForTokenClassification\n",
        "\n",
        "# 加载预训练的tokenizer和模型\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n",
        "model = RobertaForTokenClassification.from_pretrained(\"roberta-base\", num_labels=len(label_to_ids))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnlAIDFsWQoe"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from transformers import RobertaModel\n",
        "\n",
        "class RobertaNerModel(nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super(RobertaNerModel, self).__init__()\n",
        "        # 加载预训练的RoBERTa模型\n",
        "        self.bert = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(768 + 25, num_labels)  # 假设你有25个额外特征\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, extra_features, token_type_ids=None):\n",
        "        # 前向传播\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        pooled_output = outputs.last_hidden_state  # 获取RoBERTa的最后一层隐藏状态\n",
        "        #print(\"Pooled output shape:\", pooled_output.shape)\n",
        "\n",
        "        bert_outputs = self.dropout(pooled_output)\n",
        "        outputs = torch.concat((bert_outputs, extra_features), -1)  # 拼接额外特征\n",
        "        outputs = self.classifier(outputs)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7Lty9QGWc6e"
      },
      "outputs": [],
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader, epochs=3, lr=2e-5):\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    model = model.to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # 将数据加载到GPU\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            extra_features = batch[3].to(device)\n",
        "            labels = batch[4].to(device)\n",
        "\n",
        "            # 输出输入数据的形状\n",
        "\n",
        "\n",
        "            try:\n",
        "                # 模型前向传播\n",
        "                outputs = model(input_ids, attention_mask, extra_features)\n",
        "\n",
        "\n",
        "                # 计算损失\n",
        "                loss = loss_fn(outputs.view(-1, outputs.shape[-1]), labels.view(-1))\n",
        "                total_loss += loss.item()\n",
        "                #print(f\"Loss at step {step+1}: {loss.item()}\")\n",
        "\n",
        "                # 反向传播\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "\n",
        "            except RuntimeError as e:\n",
        "                print(f\"Runtime error at step {step+1}: {str(e)}\")\n",
        "                print(\"Skipping this batch...\")\n",
        "                continue\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "        print(f\"Epoch {epoch + 1}, Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # 验证模型\n",
        "        evaluate(model, val_dataloader)\n",
        "\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    model.eval()\n",
        "    eval_loss = 0\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    correct_preds, total_preds = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            extra_features = batch[3].to(device)\n",
        "            labels = batch[4].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask, extra_features)\n",
        "            loss = loss_fn(outputs.view(-1, outputs.shape[-1]), labels.view(-1))\n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=-1)\n",
        "\n",
        "            all_preds.extend(preds.view(-1).cpu().numpy())\n",
        "            all_labels.extend(labels.view(-1).cpu().numpy())\n",
        "\n",
        "            correct_preds += (preds == labels).sum().item()\n",
        "            total_preds += labels.numel()\n",
        "\n",
        "    avg_eval_loss = eval_loss / len(val_dataloader)\n",
        "    accuracy = correct_preds / total_preds\n",
        "\n",
        "    # 计算 P, R, F1\n",
        "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"Validation Loss: {avg_eval_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPoVRVu5Wfgj"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# 将数据集划分为训练集和验证集\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=128)\n",
        "val_dataloader = DataLoader(val_dataset, shuffle=True, batch_size=128)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3-SLK7Kf86S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7c4027c-2e31-46ef-d43b-eb5c2b5ce615"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ],
      "source": [
        "print(len(label_to_ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGdAy9NFftee",
        "outputId": "10d7491b-f462-4c97-ea09-d277c2a2e4a4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Training Loss: 0.0279\n",
            "Validation Loss: 0.0140, Accuracy: 0.9953\n",
            "Precision: 0.8943, Recall: 0.8554, F1 Score: 0.8736\n",
            "Epoch 2, Training Loss: 0.0118\n",
            "Validation Loss: 0.0119, Accuracy: 0.9960\n",
            "Precision: 0.8895, Recall: 0.8942, F1 Score: 0.8916\n",
            "Epoch 3, Training Loss: 0.0082\n",
            "Validation Loss: 0.0117, Accuracy: 0.9964\n",
            "Precision: 0.9067, Recall: 0.8957, F1 Score: 0.9011\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = RobertaNerModel(num_labels=len(label_to_ids))\n",
        "\n",
        "# 开始训练模型\n",
        "train(model, train_dataloader, val_dataloader, epochs=3, lr=2e-5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6LnSszn9265_"
      },
      "outputs": [],
      "source": [
        "def test(model, test_dataloader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    correct_preds, total_preds = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            extra_features = batch[3].to(device)\n",
        "            labels = batch[4].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask, extra_features)\n",
        "            loss = loss_fn(outputs.view(-1, outputs.shape[-1]), labels.view(-1))\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=-1)\n",
        "\n",
        "            all_preds.extend(preds.view(-1).cpu().numpy())\n",
        "            all_labels.extend(labels.view(-1).cpu().numpy())\n",
        "\n",
        "            correct_preds += (preds == labels).sum().item()\n",
        "            total_preds += labels.numel()\n",
        "\n",
        "    avg_test_loss = test_loss / len(test_dataloader)\n",
        "    accuracy = correct_preds / total_preds\n",
        "\n",
        "    # 计算 P, R, F1\n",
        "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"Test Loss: {avg_test_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    return avg_test_loss, accuracy, precision, recall, f1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3xKsYBIi28Z6",
        "outputId": "ba6728ac-d170-4f96-ba31-3af045959fd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.0118, Accuracy: 0.9964\n",
            "Precision: 0.9059, Recall: 0.8957, F1 Score: 0.9008\n"
          ]
        }
      ],
      "source": [
        "# 假设已经定义了 test_dataloader\n",
        "# test_dataloader = ...\n",
        "\n",
        "# 在测试集上评估模型\n",
        "test_loss, test_accuracy, test_precision, test_recall, test_f1 = test(model, test_dataloader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmUBkgZ9C6Jm"
      },
      "outputs": [],
      "source": [
        "##############################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQ223iKbCfMP",
        "outputId": "7cd4cdec-29d6-411b-df39-5c456395b277"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Training Loss: 0.0808\n",
            "Validation Loss: 0.0286, Accuracy: 0.9909\n",
            "Precision: 0.8189, Recall: 0.6978, F1 Score: 0.7484\n",
            "Epoch 2, Training Loss: 0.0272\n",
            "Validation Loss: 0.0213, Accuracy: 0.9929\n",
            "Precision: 0.8198, Recall: 0.7971, F1 Score: 0.8078\n",
            "Epoch 3, Training Loss: 0.0224\n",
            "Validation Loss: 0.0202, Accuracy: 0.9933\n",
            "Precision: 0.8284, Recall: 0.8093, F1 Score: 0.8183\n",
            "Test Loss: 0.0205, Accuracy: 0.9933\n",
            "Precision: 0.8327, Recall: 0.8094, F1 Score: 0.8205\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "from transformers import RobertaModel\n",
        "\n",
        "class RobertaNerModel(nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super(RobertaNerModel, self).__init__()\n",
        "        # 加载预训练的RoBERTa模型\n",
        "        self.bert = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(768 + 17, num_labels)  # 假设你有25个额外特征\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, extra_features, token_type_ids=None):\n",
        "        # 前向传播\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        pooled_output = outputs.last_hidden_state  # 获取RoBERTa的最后一层隐藏状态\n",
        "        #print(\"Pooled output shape:\", pooled_output.shape)\n",
        "\n",
        "        bert_outputs = self.dropout(pooled_output)\n",
        "        eeg_features = extra_features[:, :, :17]  # [batch_size, seq_len, 8]\n",
        "\n",
        "        outputs = torch.concat((bert_outputs, eeg_features), -1)  # 拼接额外特征\n",
        "\n",
        "        outputs = self.classifier(outputs)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader, epochs=3, lr=2e-5):\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    model = model.to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # 将数据加载到GPU\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            extra_features = batch[3].to(device)\n",
        "            labels = batch[4].to(device)\n",
        "\n",
        "            # 输出输入数据的形状\n",
        "\n",
        "\n",
        "            try:\n",
        "                # 模型前向传播\n",
        "                outputs = model(input_ids, attention_mask, extra_features)\n",
        "\n",
        "\n",
        "                # 计算损失\n",
        "                loss = loss_fn(outputs.view(-1, outputs.shape[-1]), labels.view(-1))\n",
        "                total_loss += loss.item()\n",
        "                #print(f\"Loss at step {step+1}: {loss.item()}\")\n",
        "\n",
        "                # 反向传播\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "\n",
        "            except RuntimeError as e:\n",
        "                print(f\"Runtime error at step {step+1}: {str(e)}\")\n",
        "                print(\"Skipping this batch...\")\n",
        "                continue\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "        print(f\"Epoch {epoch + 1}, Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # 验证模型\n",
        "        evaluate(model, val_dataloader)\n",
        "\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    model.eval()\n",
        "    eval_loss = 0\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    correct_preds, total_preds = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            extra_features = batch[3].to(device)\n",
        "            labels = batch[4].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask, extra_features)\n",
        "            loss = loss_fn(outputs.view(-1, outputs.shape[-1]), labels.view(-1))\n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=-1)\n",
        "\n",
        "            all_preds.extend(preds.view(-1).cpu().numpy())\n",
        "            all_labels.extend(labels.view(-1).cpu().numpy())\n",
        "\n",
        "            correct_preds += (preds == labels).sum().item()\n",
        "            total_preds += labels.numel()\n",
        "\n",
        "    avg_eval_loss = eval_loss / len(val_dataloader)\n",
        "    accuracy = correct_preds / total_preds\n",
        "\n",
        "    # 计算 P, R, F1\n",
        "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"Validation Loss: {avg_eval_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# 将数据集划分为训练集和验证集\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=128)\n",
        "val_dataloader = DataLoader(val_dataset, shuffle=True, batch_size=128)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = RobertaNerModel(num_labels=len(label_to_ids))\n",
        "\n",
        "# 开始训练模型\n",
        "train(model, train_dataloader, val_dataloader, epochs=3, lr=2e-5)\n",
        "def test(model, test_dataloader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    correct_preds, total_preds = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            extra_features = batch[3].to(device)\n",
        "            labels = batch[4].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask, extra_features)\n",
        "            loss = loss_fn(outputs.view(-1, outputs.shape[-1]), labels.view(-1))\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=-1)\n",
        "\n",
        "            all_preds.extend(preds.view(-1).cpu().numpy())\n",
        "            all_labels.extend(labels.view(-1).cpu().numpy())\n",
        "\n",
        "            correct_preds += (preds == labels).sum().item()\n",
        "            total_preds += labels.numel()\n",
        "\n",
        "    avg_test_loss = test_loss / len(test_dataloader)\n",
        "    accuracy = correct_preds / total_preds\n",
        "\n",
        "    # 计算 P, R, F1\n",
        "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"Test Loss: {avg_test_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    return avg_test_loss, accuracy, precision, recall, f1\n",
        "# 假设已经定义了 test_dataloader\n",
        "# test_dataloader = ...\n",
        "\n",
        "# 在测试集上评估模型\n",
        "test_loss, test_accuracy, test_precision, test_recall, test_f1 = test(model, test_dataloader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPLpOjz-27qt",
        "outputId": "2fedc470-494c-4155-f3c4-1eaa449dd933"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.0204, Accuracy: 0.9933\n",
            "Precision: 0.8327, Recall: 0.8094, F1 Score: 0.8205\n"
          ]
        }
      ],
      "source": [
        "def test(model, test_dataloader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    correct_preds, total_preds = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            extra_features = batch[3].to(device)\n",
        "            labels = batch[4].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask, extra_features)\n",
        "            loss = loss_fn(outputs.view(-1, outputs.shape[-1]), labels.view(-1))\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=-1)\n",
        "\n",
        "            all_preds.extend(preds.view(-1).cpu().numpy())\n",
        "            all_labels.extend(labels.view(-1).cpu().numpy())\n",
        "\n",
        "            correct_preds += (preds == labels).sum().item()\n",
        "            total_preds += labels.numel()\n",
        "\n",
        "    avg_test_loss = test_loss / len(test_dataloader)\n",
        "    accuracy = correct_preds / total_preds\n",
        "\n",
        "    # 计算 P, R, F1\n",
        "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"Test Loss: {avg_test_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    return avg_test_loss, accuracy, precision, recall, f1\n",
        "# 假设已经定义了 test_dataloader\n",
        "# test_dataloader = ...\n",
        "\n",
        "# 在测试集上评估模型\n",
        "test_loss, test_accuracy, test_precision, test_recall, test_f1 = test(model, test_dataloader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "798NtoOwapLR",
        "outputId": "ef6ad6b3-61a3-4c6c-cf10-0be4296dbea9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Training Loss: 0.1164\n",
            "Validation Loss: 0.0425, Accuracy: 0.9864\n",
            "Precision: 0.6724, Recall: 0.5935, F1 Score: 0.5710\n",
            "Epoch 2, Training Loss: 0.0371\n",
            "Validation Loss: 0.0275, Accuracy: 0.9909\n",
            "Precision: 0.7729, Recall: 0.7418, F1 Score: 0.7554\n",
            "Epoch 3, Training Loss: 0.0290\n",
            "Validation Loss: 0.0255, Accuracy: 0.9918\n",
            "Precision: 0.7880, Recall: 0.7718, F1 Score: 0.7793\n",
            "Test Loss: 0.0254, Accuracy: 0.9918\n",
            "Precision: 0.7923, Recall: 0.7755, F1 Score: 0.7834\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "from transformers import RobertaModel\n",
        "\n",
        "class RobertaNerModel(nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super(RobertaNerModel, self).__init__()\n",
        "        # 加载预训练的RoBERTa模型\n",
        "        self.bert = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(768 + 8, num_labels)  # 假设你有25个额外特征\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, extra_features, token_type_ids=None):\n",
        "        # 前向传播\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        pooled_output = outputs.last_hidden_state  # 获取RoBERTa的最后一层隐藏状态\n",
        "        #print(\"Pooled output shape:\", pooled_output.shape)\n",
        "\n",
        "        bert_outputs = self.dropout(pooled_output)\n",
        "        eeg_features = extra_features[:, :,-8:]  # [batch_size, seq_len, 8]\n",
        "\n",
        "        outputs = torch.concat((bert_outputs, eeg_features), -1)  # 拼接额外特征\n",
        "\n",
        "        outputs = self.classifier(outputs)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader, epochs=3, lr=2e-5):\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    model = model.to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # 将数据加载到GPU\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            extra_features = batch[3].to(device)\n",
        "            labels = batch[4].to(device)\n",
        "\n",
        "            # 输出输入数据的形状\n",
        "\n",
        "\n",
        "            try:\n",
        "                # 模型前向传播\n",
        "                outputs = model(input_ids, attention_mask, extra_features)\n",
        "\n",
        "\n",
        "                # 计算损失\n",
        "                loss = loss_fn(outputs.view(-1, outputs.shape[-1]), labels.view(-1))\n",
        "                total_loss += loss.item()\n",
        "                #print(f\"Loss at step {step+1}: {loss.item()}\")\n",
        "\n",
        "                # 反向传播\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "\n",
        "            except RuntimeError as e:\n",
        "                print(f\"Runtime error at step {step+1}: {str(e)}\")\n",
        "                print(\"Skipping this batch...\")\n",
        "                continue\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "        print(f\"Epoch {epoch + 1}, Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # 验证模型\n",
        "        evaluate(model, val_dataloader)\n",
        "\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    model.eval()\n",
        "    eval_loss = 0\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    correct_preds, total_preds = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            extra_features = batch[3].to(device)\n",
        "            labels = batch[4].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask, extra_features)\n",
        "            loss = loss_fn(outputs.view(-1, outputs.shape[-1]), labels.view(-1))\n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=-1)\n",
        "\n",
        "            all_preds.extend(preds.view(-1).cpu().numpy())\n",
        "            all_labels.extend(labels.view(-1).cpu().numpy())\n",
        "\n",
        "            correct_preds += (preds == labels).sum().item()\n",
        "            total_preds += labels.numel()\n",
        "\n",
        "    avg_eval_loss = eval_loss / len(val_dataloader)\n",
        "    accuracy = correct_preds / total_preds\n",
        "\n",
        "    # 计算 P, R, F1\n",
        "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"Validation Loss: {avg_eval_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# 将数据集划分为训练集和验证集\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=128)\n",
        "val_dataloader = DataLoader(val_dataset, shuffle=True, batch_size=128)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = RobertaNerModel(num_labels=len(label_to_ids))\n",
        "\n",
        "# 开始训练模型\n",
        "train(model, train_dataloader, val_dataloader, epochs=3, lr=2e-5)\n",
        "def test(model, test_dataloader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    correct_preds, total_preds = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            extra_features = batch[3].to(device)\n",
        "            labels = batch[4].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask, extra_features)\n",
        "            loss = loss_fn(outputs.view(-1, outputs.shape[-1]), labels.view(-1))\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=-1)\n",
        "\n",
        "            all_preds.extend(preds.view(-1).cpu().numpy())\n",
        "            all_labels.extend(labels.view(-1).cpu().numpy())\n",
        "\n",
        "            correct_preds += (preds == labels).sum().item()\n",
        "            total_preds += labels.numel()\n",
        "\n",
        "    avg_test_loss = test_loss / len(test_dataloader)\n",
        "    accuracy = correct_preds / total_preds\n",
        "\n",
        "    # 计算 P, R, F1\n",
        "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"Test Loss: {avg_test_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    return avg_test_loss, accuracy, precision, recall, f1\n",
        "# 假设已经定义了 test_dataloader\n",
        "# test_dataloader = ...\n",
        "\n",
        "# 在测试集上评估模型\n",
        "test_loss, test_accuracy, test_precision, test_recall, test_f1 = test(model, test_dataloader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXqfsRT93D1a",
        "outputId": "90e82ab4-149e-4a18-b8a4-827be01026b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.0254, Accuracy: 0.9918\n",
            "Precision: 0.7923, Recall: 0.7755, F1 Score: 0.7834\n"
          ]
        }
      ],
      "source": [
        "def test(model, test_dataloader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    correct_preds, total_preds = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            extra_features = batch[3].to(device)\n",
        "            labels = batch[4].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask, extra_features)\n",
        "            loss = loss_fn(outputs.view(-1, outputs.shape[-1]), labels.view(-1))\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=-1)\n",
        "\n",
        "            all_preds.extend(preds.view(-1).cpu().numpy())\n",
        "            all_labels.extend(labels.view(-1).cpu().numpy())\n",
        "\n",
        "            correct_preds += (preds == labels).sum().item()\n",
        "            total_preds += labels.numel()\n",
        "\n",
        "    avg_test_loss = test_loss / len(test_dataloader)\n",
        "    accuracy = correct_preds / total_preds\n",
        "\n",
        "    # 计算 P, R, F1\n",
        "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"Test Loss: {avg_test_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    return avg_test_loss, accuracy, precision, recall, f1\n",
        "# 假设已经定义了 test_dataloader\n",
        "# test_dataloader = ...\n",
        "\n",
        "# 在测试集上评估模型\n",
        "test_loss, test_accuracy, test_precision, test_recall, test_f1 = test(model, test_dataloader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CB0PzwCIMQLa"
      },
      "source": [
        "#####不同EEG组合"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from sklearn.metrics import f1_score\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "optim = AdamW(model.parameters(), lr=5e-5, weight_decay=1e-2)\n",
        "loss_fn = CrossEntropyLoss(reduction='none', ignore_index=0)\n",
        "loss_fn = loss_fn.to(device)\n",
        "\n",
        "def calculate_f1(y_pred, y_true):\n",
        "    y_true = y_true.view(-1)\n",
        "    y_pred = y_pred.view(-1)\n",
        "    y_true = y_true.detach().cpu().numpy()\n",
        "    y_pred = y_pred.detach().cpu().numpy()\n",
        "\n",
        "    mask = np.where(y_true != 0)\n",
        "\n",
        "    y_true = y_true[mask]\n",
        "    y_pred = y_pred[mask]\n",
        "\n",
        "    return y_pred, y_true\n",
        "\n",
        "def TagConvert(raw_tags, words_set, poss=None):\n",
        "    true_tags = []\n",
        "    for i in range(raw_tags.shape[0]):\n",
        "        kw_list = []\n",
        "        nkw_list = \"\"\n",
        "        for j in range(len(raw_tags[i])):\n",
        "            item = raw_tags[i][j]\n",
        "            if item == 0:\n",
        "                continue\n",
        "            if poss != None and j in poss[i]:\n",
        "                continue\n",
        "            if item == 4:\n",
        "                kw_list.append(str(words_set[j][i]))\n",
        "            if item == 1:\n",
        "                nkw_list += str(words_set[j][i])\n",
        "            if item == 2:\n",
        "                nkw_list += \" \"\n",
        "                nkw_list += str(words_set[j][i])\n",
        "            if item == 3:\n",
        "                nkw_list += \" \"\n",
        "                nkw_list += str(words_set[j][i])\n",
        "                kw_list.append(nkw_list)\n",
        "                nkw_list = \"\"\n",
        "\n",
        "        true_tags.append(kw_list)\n",
        "    return true_tags\n",
        "\n",
        "def evaluate(predict_data, target_data, topk=3):\n",
        "    TRUE_COUNT, PRED_COUNT, GOLD_COUNT = 0.0, 0.0, 0.0\n",
        "    for index, words in enumerate(predict_data):\n",
        "        y_pred, y_true = None, target_data[index]\n",
        "\n",
        "        if type(predict_data) == str:\n",
        "            words = sorted(words.items(), key=lambda item: (-item[1], item[0]))\n",
        "            y_pred = [i[0] for i in words]\n",
        "        elif type(predict_data) == list:\n",
        "            y_pred = words\n",
        "\n",
        "        y_pred = y_pred[0: topk]\n",
        "        TRUE_NUM = len(set(y_pred) & set(y_true))\n",
        "        TRUE_COUNT += TRUE_NUM\n",
        "        PRED_COUNT += len(y_pred)\n",
        "        GOLD_COUNT += len(y_true)\n",
        "    if PRED_COUNT != 0:\n",
        "        p = (TRUE_COUNT / PRED_COUNT)\n",
        "    else:\n",
        "        p = 0\n",
        "    if GOLD_COUNT != 0:\n",
        "        r = (TRUE_COUNT / GOLD_COUNT)\n",
        "    else:\n",
        "        r = 0\n",
        "    if (r + p) != 0:\n",
        "        f1 = ((2 * r * p) / (r + p))\n",
        "    else:\n",
        "        f1 = 0\n",
        "\n",
        "    p = round(p * 100, 2)\n",
        "    r = round(r * 100, 2)\n",
        "    f1 = round(f1 * 100, 2)\n",
        "\n",
        "    return p, r, f1"
      ],
      "metadata": {
        "id": "6FJNegVf_LDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "from transformers import RobertaModel\n",
        "from torch import nn\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "\n",
        "\n",
        "# 定义 RobertaNerModel\n",
        "class RobertaNerModel(nn.Module):\n",
        "    def __init__(self, num_labels, hidden_dim=768, eeg_dim=8):\n",
        "        super(RobertaNerModel, self).__init__()\n",
        "        self.roberta = RobertaModel.from_pretrained('roberta-base')\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(hidden_dim + eeg_dim, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, extra_features):\n",
        "        roberta_outputs = self.roberta(input_ids, attention_mask=attention_mask)\n",
        "        sequence_output = roberta_outputs[0]  # shape: (batch_size, seq_length, hidden_dim)\n",
        "\n",
        "        # 拼接特征\n",
        "        combined_output = torch.cat((sequence_output, extra_features), dim=-1)  # [batch_size, seq_len, hidden_dim + eeg_dim]\n",
        "        combined_output = self.dropout(combined_output)\n",
        "\n",
        "        logits = self.classifier(combined_output)  # shape: (batch_size, seq_len, num_labels)\n",
        "\n",
        "        return logits\n",
        "\n",
        "# 根据 EEG 组合标签获取相应的维度索引\n",
        "def get_eeg_dim(combo):\n",
        "    mappings = {\n",
        "        'EEG1': (0, 1),\n",
        "        'EEG2': (1, 2),\n",
        "        'EEG3': (2, 3),\n",
        "        'EEG4': (3, 4),\n",
        "        'EEG5': (4, 5),\n",
        "        'EEG6': (5, 6),\n",
        "        'EEG7': (6, 7),\n",
        "        'EEG8': (7, 8),\n",
        "        'EEG1.2': (0, 2),\n",
        "        'EEG2.3': (1, 3),\n",
        "        'EEG3.4': (2, 4),\n",
        "        'EEG4.5': (3, 5),\n",
        "        'EEG5.6': (4, 6),\n",
        "        'EEG6.7': (5, 7),\n",
        "        'EEG7.8': (6, 8),\n",
        "    }\n",
        "    return mappings[combo]\n",
        "\n",
        "# 训练和评估函数\n",
        "def train_and_evaluate(eeg_combo):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    eeg_start, eeg_end = get_eeg_dim(eeg_combo)\n",
        "    eeg_dim = eeg_end - eeg_start\n",
        "\n",
        "    model = RobertaNerModel(num_labels=6, eeg_dim=eeg_dim)\n",
        "    model = model.to(device)\n",
        "    optim = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=1e-2)\n",
        "    loss_fn = nn.CrossEntropyLoss(reduction='none', ignore_index=0)\n",
        "    loss_fn = loss_fn.to(device)\n",
        "\n",
        "    epochs = 2\n",
        "    best_f1 = 0.0\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        loss_value = 0.0\n",
        "        model.train()\n",
        "        label_true, label_pred = [], []\n",
        "        for i, batch in enumerate(train_dataloader):\n",
        "            optim.zero_grad()\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_masks = batch[1].to(device)\n",
        "            features = batch[3][:, :, eeg_start:eeg_end].to(device)\n",
        "            tags = batch[4].to(device)\n",
        "\n",
        "            with autocast():\n",
        "                pred_tags = model(input_ids, attention_masks, features)\n",
        "\n",
        "                # 展平 pred_tags 和 tags 以匹配形状\n",
        "                pred_tags = pred_tags.reshape(-1, pred_tags.size(-1))\n",
        "                tags = tags.reshape(-1)\n",
        "\n",
        "                loss = loss_fn(pred_tags, tags)\n",
        "                loss = loss.mean()\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optim)\n",
        "            scaler.update()\n",
        "\n",
        "            pred_tags = F.softmax(pred_tags, dim=-1)\n",
        "            pred_tags = torch.argmax(pred_tags, dim=-1)\n",
        "            y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "            label_true.extend(y_true)\n",
        "            label_pred.extend(y_pred)\n",
        "            loss_value += loss.item()\n",
        "\n",
        "        label_train_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "\n",
        "        model.eval()\n",
        "        kw_true, kw_pred = [], []\n",
        "        label_true, label_pred = [], []\n",
        "        for i, batch in enumerate(test_dataloader):\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_masks = batch[1].to(device)\n",
        "            tokens = batch[2]  # tokens 不是 Tensor，直接使用\n",
        "            features = batch[3][:, :, eeg_start:eeg_end].to(device)\n",
        "            tags = batch[4].to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for module in model.modules():\n",
        "                    if isinstance(module, nn.Dropout):\n",
        "                        module.p = 0\n",
        "                        module.train(False)\n",
        "                with autocast():\n",
        "                    pred_tags = model(input_ids, attention_masks, features)\n",
        "                    pred_tags = F.softmax(pred_tags, dim=-1)\n",
        "                    pred_tags = torch.argmax(pred_tags, dim=-1)\n",
        "\n",
        "            y_pred, y_true = calculate_f1(pred_tags, tags)\n",
        "            label_true.extend(y_true)\n",
        "            label_pred.extend(y_pred)\n",
        "\n",
        "            poss = []\n",
        "            for i in range(len(tags)):\n",
        "                pos = []\n",
        "                for j in range(len(tags[i])):\n",
        "                    if tags[i][j] == 0:\n",
        "                        pos.append(j)\n",
        "                poss.append(pos)\n",
        "\n",
        "            kw_true.extend(TagConvert(tags, tokens))\n",
        "            kw_pred.extend(TagConvert(pred_tags, tokens, poss))\n",
        "\n",
        "        label_f1 = f1_score(label_true, label_pred, average='macro')\n",
        "        P, R, F1 = evaluate(kw_true, kw_pred)\n",
        "\n",
        "        # if F1 > best_f1:\n",
        "        #     best_f1 = F1\n",
        "        #     torch.save(model.state_dict(), f'/content/drive/MyDrive/ner/pretrain_pt/roberta_HAtten_{eeg_combo}.pt')\n",
        "\n",
        "        print(f\"epoch {epoch + 1}: loss: {loss_value / len(train_dataloader):.2f} train_f1: {label_train_f1:.2f} test_f1: {label_f1:.2f} kw_f1: {F1:.2f}\")\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return P, R, F1\n",
        "\n",
        "# 使用不同的 EEG 组合进行训练和评估\n",
        "eeg_combos = ['EEG1', 'EEG2', 'EEG3', 'EEG4', 'EEG5', 'EEG6', 'EEG7', 'EEG8',\n",
        "              'EEG1.2', 'EEG2.3', 'EEG3.4', 'EEG4.5', 'EEG5.6', 'EEG6.7', 'EEG7.8']\n",
        "\n",
        "for eeg_combo in eeg_combos:\n",
        "    print(f\"Training with EEG combo: {eeg_combo}\")\n",
        "    P, R, F1 = train_and_evaluate(eeg_combo)\n",
        "    print(f\"EEG combo: {eeg_combo} - Precision: {P:.2f}, Recall: {R:.2f}, F1 Score: {F1:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kM08ljw0-w6s",
        "outputId": "662d045b-eb5b-4018-8fa6-547b8ba1ba7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with EEG combo: EEG1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.04 train_f1: 0.24 test_f1: 0.52 kw_f1: 50.70\n",
            "epoch 2: loss: 0.02 train_f1: 0.61 test_f1: 0.66 kw_f1: 65.61\n",
            "EEG combo: EEG1 - Precision: 61.54, Recall: 70.26, F1 Score: 65.61\n",
            "Training with EEG combo: EEG2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.04 train_f1: 0.24 test_f1: 0.45 kw_f1: 51.69\n",
            "epoch 2: loss: 0.02 train_f1: 0.61 test_f1: 0.66 kw_f1: 66.63\n",
            "EEG combo: EEG2 - Precision: 59.35, Recall: 75.94, F1 Score: 66.63\n",
            "Training with EEG combo: EEG3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.05 train_f1: 0.17 test_f1: 0.31 kw_f1: 41.76\n",
            "epoch 2: loss: 0.03 train_f1: 0.49 test_f1: 0.58 kw_f1: 56.39\n",
            "EEG combo: EEG3 - Precision: 43.06, Recall: 81.69, F1 Score: 56.39\n",
            "Training with EEG combo: EEG4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.05 train_f1: 0.23 test_f1: 0.50 kw_f1: 49.85\n",
            "epoch 2: loss: 0.02 train_f1: 0.61 test_f1: 0.66 kw_f1: 68.09\n",
            "EEG combo: EEG4 - Precision: 65.06, Recall: 71.41, F1 Score: 68.09\n",
            "Training with EEG combo: EEG5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.05 train_f1: 0.20 test_f1: 0.38 kw_f1: 42.99\n",
            "epoch 2: loss: 0.03 train_f1: 0.54 test_f1: 0.65 kw_f1: 64.17\n",
            "EEG combo: EEG5 - Precision: 56.52, Recall: 74.23, F1 Score: 64.17\n",
            "Training with EEG combo: EEG6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.05 train_f1: 0.23 test_f1: 0.52 kw_f1: 49.38\n",
            "epoch 2: loss: 0.02 train_f1: 0.60 test_f1: 0.64 kw_f1: 67.18\n",
            "EEG combo: EEG6 - Precision: 61.15, Recall: 74.53, F1 Score: 67.18\n",
            "Training with EEG combo: EEG7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.04 train_f1: 0.27 test_f1: 0.57 kw_f1: 53.96\n",
            "epoch 2: loss: 0.02 train_f1: 0.62 test_f1: 0.67 kw_f1: 65.88\n",
            "EEG combo: EEG7 - Precision: 57.33, Recall: 77.42, F1 Score: 65.88\n",
            "Training with EEG combo: EEG8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.05 train_f1: 0.21 test_f1: 0.48 kw_f1: 50.06\n",
            "epoch 2: loss: 0.02 train_f1: 0.57 test_f1: 0.64 kw_f1: 63.13\n",
            "EEG combo: EEG8 - Precision: 61.54, Recall: 64.81, F1 Score: 63.13\n",
            "Training with EEG combo: EEG1.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.04 train_f1: 0.26 test_f1: 0.53 kw_f1: 53.35\n",
            "epoch 2: loss: 0.02 train_f1: 0.63 test_f1: 0.65 kw_f1: 68.38\n",
            "EEG combo: EEG1.2 - Precision: 61.05, Recall: 77.72, F1 Score: 68.38\n",
            "Training with EEG combo: EEG2.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.05 train_f1: 0.20 test_f1: 0.35 kw_f1: 40.15\n",
            "epoch 2: loss: 0.03 train_f1: 0.53 test_f1: 0.62 kw_f1: 64.58\n",
            "EEG combo: EEG2.3 - Precision: 57.53, Recall: 73.60, F1 Score: 64.58\n",
            "Training with EEG combo: EEG3.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.05 train_f1: 0.22 test_f1: 0.41 kw_f1: 50.94\n",
            "epoch 2: loss: 0.02 train_f1: 0.61 test_f1: 0.68 kw_f1: 69.08\n",
            "EEG combo: EEG3.4 - Precision: 64.41, Recall: 74.48, F1 Score: 69.08\n",
            "Training with EEG combo: EEG4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.05 train_f1: 0.23 test_f1: 0.46 kw_f1: 46.56\n",
            "epoch 2: loss: 0.02 train_f1: 0.60 test_f1: 0.64 kw_f1: 63.74\n",
            "EEG combo: EEG4.5 - Precision: 52.09, Recall: 82.12, F1 Score: 63.74\n",
            "Training with EEG combo: EEG5.6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.04 train_f1: 0.23 test_f1: 0.40 kw_f1: 51.19\n",
            "epoch 2: loss: 0.02 train_f1: 0.62 test_f1: 0.66 kw_f1: 66.26\n",
            "EEG combo: EEG5.6 - Precision: 58.77, Recall: 75.95, F1 Score: 66.26\n",
            "Training with EEG combo: EEG6.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.04 train_f1: 0.23 test_f1: 0.50 kw_f1: 48.75\n",
            "epoch 2: loss: 0.02 train_f1: 0.60 test_f1: 0.65 kw_f1: 66.96\n",
            "EEG combo: EEG6.7 - Precision: 62.81, Recall: 71.69, F1 Score: 66.96\n",
            "Training with EEG combo: EEG7.8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: loss: 0.04 train_f1: 0.24 test_f1: 0.51 kw_f1: 50.80\n",
            "epoch 2: loss: 0.02 train_f1: 0.61 test_f1: 0.66 kw_f1: 66.44\n",
            "EEG combo: EEG7.8 - Precision: 59.55, Recall: 75.12, F1 Score: 66.44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5o66KaByEt5"
      },
      "outputs": [],
      "source": [
        "#########################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGzczALaa3rk",
        "outputId": "bbfb7fbd-6f67-4a3a-8c5a-29e875470e09"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Training Loss: 0.1248\n",
            "Validation Loss: 0.0414, Accuracy: 0.9877\n",
            "Precision: 0.7661, Recall: 0.5404, F1 Score: 0.5758\n",
            "Epoch 2, Training Loss: 0.0372\n",
            "Validation Loss: 0.0294, Accuracy: 0.9902\n",
            "Precision: 0.7596, Recall: 0.7484, F1 Score: 0.7529\n",
            "Epoch 3, Training Loss: 0.0299\n",
            "Validation Loss: 0.0266, Accuracy: 0.9911\n",
            "Precision: 0.7859, Recall: 0.7640, F1 Score: 0.7745\n",
            "Test Loss: 0.0264, Accuracy: 0.9913\n",
            "Precision: 0.7854, Recall: 0.7665, F1 Score: 0.7756\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "from transformers import RobertaModel\n",
        "\n",
        "class RobertaNerModel(nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super(RobertaNerModel, self).__init__()\n",
        "        # 加载预训练的RoBERTa模型\n",
        "        self.bert = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(768 , num_labels)  # 假设你有25个额外特征\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, extra_features, token_type_ids=None):\n",
        "        # 前向传播\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        pooled_output = outputs.last_hidden_state  # 获取RoBERTa的最后一层隐藏状态\n",
        "        #print(\"Pooled output shape:\", pooled_output.shape)\n",
        "\n",
        "        bert_outputs = self.dropout(pooled_output)\n",
        "        # eeg_features = extra_features[:, :,-8:]  # [batch_size, seq_len, 8]\n",
        "\n",
        "        # outputs = torch.concat((bert_outputs, eeg_features), -1)  # 拼接额外特征\n",
        "\n",
        "        outputs = self.classifier(bert_outputs)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader, epochs=3, lr=2e-5):\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    model = model.to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # 将数据加载到GPU\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            extra_features = batch[3].to(device)\n",
        "            labels = batch[4].to(device)\n",
        "\n",
        "            # 输出输入数据的形状\n",
        "\n",
        "\n",
        "            try:\n",
        "                # 模型前向传播\n",
        "                outputs = model(input_ids, attention_mask, extra_features)\n",
        "\n",
        "\n",
        "                # 计算损失\n",
        "                loss = loss_fn(outputs.view(-1, outputs.shape[-1]), labels.view(-1))\n",
        "                total_loss += loss.item()\n",
        "                #print(f\"Loss at step {step+1}: {loss.item()}\")\n",
        "\n",
        "                # 反向传播\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "\n",
        "            except RuntimeError as e:\n",
        "                print(f\"Runtime error at step {step+1}: {str(e)}\")\n",
        "                print(\"Skipping this batch...\")\n",
        "                continue\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "        print(f\"Epoch {epoch + 1}, Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # 验证模型\n",
        "        evaluate(model, val_dataloader)\n",
        "\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    model.eval()\n",
        "    eval_loss = 0\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    correct_preds, total_preds = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            extra_features = batch[3].to(device)\n",
        "            labels = batch[4].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask, extra_features)\n",
        "            loss = loss_fn(outputs.view(-1, outputs.shape[-1]), labels.view(-1))\n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=-1)\n",
        "\n",
        "            all_preds.extend(preds.view(-1).cpu().numpy())\n",
        "            all_labels.extend(labels.view(-1).cpu().numpy())\n",
        "\n",
        "            correct_preds += (preds == labels).sum().item()\n",
        "            total_preds += labels.numel()\n",
        "\n",
        "    avg_eval_loss = eval_loss / len(val_dataloader)\n",
        "    accuracy = correct_preds / total_preds\n",
        "\n",
        "    # 计算 P, R, F1\n",
        "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"Validation Loss: {avg_eval_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# 将数据集划分为训练集和验证集\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=128)\n",
        "val_dataloader = DataLoader(val_dataset, shuffle=True, batch_size=128)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = RobertaNerModel(num_labels=len(label_to_ids))\n",
        "\n",
        "# 开始训练模型\n",
        "train(model, train_dataloader, val_dataloader, epochs=3, lr=2e-5)\n",
        "def test(model, test_dataloader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    correct_preds, total_preds = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            extra_features = batch[3].to(device)\n",
        "            labels = batch[4].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask, extra_features)\n",
        "            loss = loss_fn(outputs.view(-1, outputs.shape[-1]), labels.view(-1))\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=-1)\n",
        "\n",
        "            all_preds.extend(preds.view(-1).cpu().numpy())\n",
        "            all_labels.extend(labels.view(-1).cpu().numpy())\n",
        "\n",
        "            correct_preds += (preds == labels).sum().item()\n",
        "            total_preds += labels.numel()\n",
        "\n",
        "    avg_test_loss = test_loss / len(test_dataloader)\n",
        "    accuracy = correct_preds / total_preds\n",
        "\n",
        "    # 计算 P, R, F1\n",
        "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"Test Loss: {avg_test_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    return avg_test_loss, accuracy, precision, recall, f1\n",
        "# 假设已经定义了 test_dataloader\n",
        "# test_dataloader = ...\n",
        "\n",
        "# 在测试集上评估模型\n",
        "test_loss, test_accuracy, test_precision, test_recall, test_f1 = test(model, test_dataloader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeL9JclP3G8p",
        "outputId": "e7920c4d-cc3c-4448-90f2-adb0e6d8429b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.0264, Accuracy: 0.9913\n",
            "Precision: 0.7854, Recall: 0.7665, F1 Score: 0.7756\n"
          ]
        }
      ],
      "source": [
        "def test(model, test_dataloader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    correct_preds, total_preds = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            extra_features = batch[3].to(device)\n",
        "            labels = batch[4].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask, extra_features)\n",
        "            loss = loss_fn(outputs.view(-1, outputs.shape[-1]), labels.view(-1))\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=-1)\n",
        "\n",
        "            all_preds.extend(preds.view(-1).cpu().numpy())\n",
        "            all_labels.extend(labels.view(-1).cpu().numpy())\n",
        "\n",
        "            correct_preds += (preds == labels).sum().item()\n",
        "            total_preds += labels.numel()\n",
        "\n",
        "    avg_test_loss = test_loss / len(test_dataloader)\n",
        "    accuracy = correct_preds / total_preds\n",
        "\n",
        "    # 计算 P, R, F1\n",
        "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"Test Loss: {avg_test_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    return avg_test_loss, accuracy, precision, recall, f1\n",
        "# 假设已经定义了 test_dataloader\n",
        "# test_dataloader = ...\n",
        "\n",
        "# 在测试集上评估模型\n",
        "test_loss, test_accuracy, test_precision, test_recall, test_f1 = test(model, test_dataloader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdHHM6wc0_BN"
      },
      "source": [
        "################结束"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Csamx6ElmbG1"
      },
      "outputs": [],
      "source": [
        "###################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DH7BWlGOPg_Q"
      },
      "outputs": [],
      "source": [
        "###################################"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5ca96f3c0f2446b1868993129c67f90a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc08b098c9574a97a06c1a3912b3bb9d",
              "IPY_MODEL_1c48b97aa0fd4131be5a4be237a97aea",
              "IPY_MODEL_2b5f5d7f531a41ce8648515c4506925b"
            ],
            "layout": "IPY_MODEL_62195acefa1f460899b99eec8fd64fd8"
          }
        },
        "cc08b098c9574a97a06c1a3912b3bb9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a00b431cecd48bfb8f46c1bd38eb59a",
            "placeholder": "​",
            "style": "IPY_MODEL_ff09175e7a3a4e35bb4358b0392cdcc6",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "1c48b97aa0fd4131be5a4be237a97aea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5983767d0d924377900fe6d6cfd421d3",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52518eb06fb24a4f8e17c12c7aa3256c",
            "value": 25
          }
        },
        "2b5f5d7f531a41ce8648515c4506925b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebf582f7f1a047f4906a7c4f13870649",
            "placeholder": "​",
            "style": "IPY_MODEL_733cbef4849d4cc99569905541110c16",
            "value": " 25.0/25.0 [00:00&lt;00:00, 2.09kB/s]"
          }
        },
        "62195acefa1f460899b99eec8fd64fd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a00b431cecd48bfb8f46c1bd38eb59a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff09175e7a3a4e35bb4358b0392cdcc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5983767d0d924377900fe6d6cfd421d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52518eb06fb24a4f8e17c12c7aa3256c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ebf582f7f1a047f4906a7c4f13870649": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "733cbef4849d4cc99569905541110c16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15318a207af743b694022a5f535a827d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10ba27367b5f4280b69526b14d0b6fc3",
              "IPY_MODEL_bd7b52fc0b374b67875001eb1711b97a",
              "IPY_MODEL_971cb32a8530400a926de1b19b339ea0"
            ],
            "layout": "IPY_MODEL_339e81e867c347858bec3b68ed1e9b20"
          }
        },
        "10ba27367b5f4280b69526b14d0b6fc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55da55a55f624f6084d632727c1b4ba6",
            "placeholder": "​",
            "style": "IPY_MODEL_03a5349779a74ef7a3fbdcb4ed373771",
            "value": "vocab.json: 100%"
          }
        },
        "bd7b52fc0b374b67875001eb1711b97a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1982b98b018049a9a090d89a81af754f",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_161bde2ea196459f8e70c37e011bd675",
            "value": 898823
          }
        },
        "971cb32a8530400a926de1b19b339ea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_622c28e17032499697370e08088b67a6",
            "placeholder": "​",
            "style": "IPY_MODEL_297f5ab924a24ff3a93c059ff5340302",
            "value": " 899k/899k [00:00&lt;00:00, 1.04MB/s]"
          }
        },
        "339e81e867c347858bec3b68ed1e9b20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55da55a55f624f6084d632727c1b4ba6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03a5349779a74ef7a3fbdcb4ed373771": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1982b98b018049a9a090d89a81af754f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "161bde2ea196459f8e70c37e011bd675": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "622c28e17032499697370e08088b67a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "297f5ab924a24ff3a93c059ff5340302": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26653a1478b344af9c7b4673a8d2f406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e8c03c5cff84635bebab030a50d29f0",
              "IPY_MODEL_0a1963b2f73941398136ee5fcd304b0c",
              "IPY_MODEL_f681554ba2894b53aeba107c82a83292"
            ],
            "layout": "IPY_MODEL_816614a185634e9395bdb4a7c7ac27ed"
          }
        },
        "9e8c03c5cff84635bebab030a50d29f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37df2d9206024afd9ec527e3202ca61f",
            "placeholder": "​",
            "style": "IPY_MODEL_e2621e8698e44c9f8b29d0bd4f27f942",
            "value": "merges.txt: 100%"
          }
        },
        "0a1963b2f73941398136ee5fcd304b0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9252b5fb792c44fdbac7085c95af8912",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c1cdb5b32a24f73bb9d4db8ce58c157",
            "value": 456318
          }
        },
        "f681554ba2894b53aeba107c82a83292": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fedc275e72b9401b9321464f13987b67",
            "placeholder": "​",
            "style": "IPY_MODEL_f5e27a9d9b34422fb15bbd542c983098",
            "value": " 456k/456k [00:00&lt;00:00, 1.06MB/s]"
          }
        },
        "816614a185634e9395bdb4a7c7ac27ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37df2d9206024afd9ec527e3202ca61f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2621e8698e44c9f8b29d0bd4f27f942": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9252b5fb792c44fdbac7085c95af8912": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c1cdb5b32a24f73bb9d4db8ce58c157": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fedc275e72b9401b9321464f13987b67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5e27a9d9b34422fb15bbd542c983098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed8af7c53f4c412d9b70cb8f0a074abe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dfcaf2cf411f447180b4a499d547d216",
              "IPY_MODEL_94810557722b4e71b8e782314905799a",
              "IPY_MODEL_ebd36555c4c548bda979c89f67d4c731"
            ],
            "layout": "IPY_MODEL_4c207b891dc44a7d8be46452b34a2de5"
          }
        },
        "dfcaf2cf411f447180b4a499d547d216": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ed057b8c6a3451c9880e92aa13be3d6",
            "placeholder": "​",
            "style": "IPY_MODEL_693912d97c84456d8d8f2c9bee684f37",
            "value": "tokenizer.json: 100%"
          }
        },
        "94810557722b4e71b8e782314905799a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca8f1ef6b1a34b3fb6725e767bee4215",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5748928ddc7648f2bde150300269ffd5",
            "value": 1355863
          }
        },
        "ebd36555c4c548bda979c89f67d4c731": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_891b38f2c22e4adbbd0fe40d43956685",
            "placeholder": "​",
            "style": "IPY_MODEL_790cbdeb9ebd4cdbb8eddcf52a916c5d",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 1.57MB/s]"
          }
        },
        "4c207b891dc44a7d8be46452b34a2de5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ed057b8c6a3451c9880e92aa13be3d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "693912d97c84456d8d8f2c9bee684f37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca8f1ef6b1a34b3fb6725e767bee4215": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5748928ddc7648f2bde150300269ffd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "891b38f2c22e4adbbd0fe40d43956685": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "790cbdeb9ebd4cdbb8eddcf52a916c5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b8ea24553414421b3da9fb97a8bf32a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5033c90522174d76bf1ed2009a974db3",
              "IPY_MODEL_3cd0d99fd965439989a28c64f8a77429",
              "IPY_MODEL_43a85ad2222449bb9dbbb6378708c4ee"
            ],
            "layout": "IPY_MODEL_772cc5dcd08c460c87f95d5a3d98da83"
          }
        },
        "5033c90522174d76bf1ed2009a974db3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49e75571413e47dabbdfae47f0d35596",
            "placeholder": "​",
            "style": "IPY_MODEL_e83951165bef4a068c2e18261f4adc34",
            "value": "config.json: 100%"
          }
        },
        "3cd0d99fd965439989a28c64f8a77429": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8131b3b978fc4eebafee0e255e3a7008",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e9b09faa34241f8a567d7f2967b433d",
            "value": 481
          }
        },
        "43a85ad2222449bb9dbbb6378708c4ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd901d61e18c44dfbeb2b826e913970c",
            "placeholder": "​",
            "style": "IPY_MODEL_16ac6be89d3444bb920cc78fe07275a4",
            "value": " 481/481 [00:00&lt;00:00, 44.4kB/s]"
          }
        },
        "772cc5dcd08c460c87f95d5a3d98da83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49e75571413e47dabbdfae47f0d35596": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e83951165bef4a068c2e18261f4adc34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8131b3b978fc4eebafee0e255e3a7008": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e9b09faa34241f8a567d7f2967b433d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd901d61e18c44dfbeb2b826e913970c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16ac6be89d3444bb920cc78fe07275a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7591abc281164081986d0d7086325ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf23e095f0774e8fa6e139f96e9069c3",
              "IPY_MODEL_df75aeb50ddd4eac908cc4e90d58e618",
              "IPY_MODEL_0f10a72f3c464a77b055f5c2e9eb71f4"
            ],
            "layout": "IPY_MODEL_68c97e0c5129463ca7f00fe171b259a3"
          }
        },
        "cf23e095f0774e8fa6e139f96e9069c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c685604062742d28a3ccad895f2a851",
            "placeholder": "​",
            "style": "IPY_MODEL_7f3be5b2b24642fe903eb443a7b6e025",
            "value": "model.safetensors: 100%"
          }
        },
        "df75aeb50ddd4eac908cc4e90d58e618": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dae1bc345ec4ad28d86452478899b38",
            "max": 498818054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12dc5199598748bd9bb337dd8d8546b5",
            "value": 498818054
          }
        },
        "0f10a72f3c464a77b055f5c2e9eb71f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3393bf775c04c6cbc7c4e3030b9c92d",
            "placeholder": "​",
            "style": "IPY_MODEL_ff4d8172c21c46c68bcd7afa1fcd830f",
            "value": " 499M/499M [00:01&lt;00:00, 507MB/s]"
          }
        },
        "68c97e0c5129463ca7f00fe171b259a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c685604062742d28a3ccad895f2a851": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f3be5b2b24642fe903eb443a7b6e025": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2dae1bc345ec4ad28d86452478899b38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12dc5199598748bd9bb337dd8d8546b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3393bf775c04c6cbc7c4e3030b9c92d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff4d8172c21c46c68bcd7afa1fcd830f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}